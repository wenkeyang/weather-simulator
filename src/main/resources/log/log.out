statis filename:Sydney, site_code:066062, start_date:2018-01-01, end_date:2018-12-31
Extracing statis for stn_num=066062&month=01&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=01
Extracing statis for stn_num=066062&month=01&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=02
Extracing statis for stn_num=066062&month=01&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=03
Extracing statis for stn_num=066062&month=01&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=04
Extracing statis for stn_num=066062&month=01&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=05
Extracing statis for stn_num=066062&month=01&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=06
Extracing statis for stn_num=066062&month=01&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=07
Extracing statis for stn_num=066062&month=01&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=08
Extracing statis for stn_num=066062&month=01&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=09
Extracing statis for stn_num=066062&month=01&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=10
Extracing statis for stn_num=066062&month=01&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=11
Extracing statis for stn_num=066062&month=01&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=12
Extracing statis for stn_num=066062&month=01&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=13
Extracing statis for stn_num=066062&month=01&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=14
Extracing statis for stn_num=066062&month=01&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=15
Extracing statis for stn_num=066062&month=01&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=16
Extracing statis for stn_num=066062&month=01&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=17
Extracing statis for stn_num=066062&month=01&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=18
Extracing statis for stn_num=066062&month=01&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=19
Extracing statis for stn_num=066062&month=01&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=20
Extracing statis for stn_num=066062&month=01&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=21
Extracing statis for stn_num=066062&month=01&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=22
Extracing statis for stn_num=066062&month=01&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=23
Extracing statis for stn_num=066062&month=01&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=24
Extracing statis for stn_num=066062&month=01&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=25
Extracing statis for stn_num=066062&month=01&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=26
Extracing statis for stn_num=066062&month=01&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=27
Extracing statis for stn_num=066062&month=01&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=28
Extracing statis for stn_num=066062&month=01&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=29
Extracing statis for stn_num=066062&month=01&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=30
Extracing statis for stn_num=066062&month=01&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=31
Extracing statis for stn_num=066062&month=02&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=01
Extracing statis for stn_num=066062&month=02&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=02
Extracing statis for stn_num=066062&month=02&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=03
Extracing statis for stn_num=066062&month=02&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=04
Extracing statis for stn_num=066062&month=02&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=05
Extracing statis for stn_num=066062&month=02&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=06
Extracing statis for stn_num=066062&month=02&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=07
Extracing statis for stn_num=066062&month=02&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=08
Extracing statis for stn_num=066062&month=02&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=09
Extracing statis for stn_num=066062&month=02&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=10
Extracing statis for stn_num=066062&month=02&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=11
Extracing statis for stn_num=066062&month=02&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=12
Extracing statis for stn_num=066062&month=02&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=13
Extracing statis for stn_num=066062&month=02&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=14
Extracing statis for stn_num=066062&month=02&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=15
Extracing statis for stn_num=066062&month=02&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=16
Extracing statis for stn_num=066062&month=02&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=17
Extracing statis for stn_num=066062&month=02&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=18
Extracing statis for stn_num=066062&month=02&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=19
Extracing statis for stn_num=066062&month=02&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=20
Extracing statis for stn_num=066062&month=02&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=21
Extracing statis for stn_num=066062&month=02&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=22
Extracing statis for stn_num=066062&month=02&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=23
Extracing statis for stn_num=066062&month=02&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=24
Extracing statis for stn_num=066062&month=02&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=25
Extracing statis for stn_num=066062&month=02&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=26
Extracing statis for stn_num=066062&month=02&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=27
Extracing statis for stn_num=066062&month=02&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=28
Extracing statis for stn_num=066062&month=03&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=01
Extracing statis for stn_num=066062&month=03&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=02
Extracing statis for stn_num=066062&month=03&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=03
Extracing statis for stn_num=066062&month=03&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=04
Extracing statis for stn_num=066062&month=03&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=05
Extracing statis for stn_num=066062&month=03&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=06
Extracing statis for stn_num=066062&month=03&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=07
Extracing statis for stn_num=066062&month=03&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=08
Extracing statis for stn_num=066062&month=03&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=09
Extracing statis for stn_num=066062&month=03&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=10
Extracing statis for stn_num=066062&month=03&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=11
Extracing statis for stn_num=066062&month=03&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=12
Extracing statis for stn_num=066062&month=03&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=13
Extracing statis for stn_num=066062&month=03&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=14
Extracing statis for stn_num=066062&month=03&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=15
Extracing statis for stn_num=066062&month=03&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=16
Extracing statis for stn_num=066062&month=03&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=17
Extracing statis for stn_num=066062&month=03&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=18
Extracing statis for stn_num=066062&month=03&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=19
Extracing statis for stn_num=066062&month=03&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=20
Extracing statis for stn_num=066062&month=03&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=21
Extracing statis for stn_num=066062&month=03&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=22
Extracing statis for stn_num=066062&month=03&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=23
Extracing statis for stn_num=066062&month=03&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=24
Extracing statis for stn_num=066062&month=03&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=25
Extracing statis for stn_num=066062&month=03&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=26
Extracing statis for stn_num=066062&month=03&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=27
Extracing statis for stn_num=066062&month=03&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=28
Extracing statis for stn_num=066062&month=03&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=29
Extracing statis for stn_num=066062&month=03&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=30
Extracing statis for stn_num=066062&month=03&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=31
Extracing statis for stn_num=066062&month=04&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=01
Extracing statis for stn_num=066062&month=04&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=02
Extracing statis for stn_num=066062&month=04&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=03
Extracing statis for stn_num=066062&month=04&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=04
Extracing statis for stn_num=066062&month=04&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=05
Extracing statis for stn_num=066062&month=04&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=06
Extracing statis for stn_num=066062&month=04&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=07
Extracing statis for stn_num=066062&month=04&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=08
Extracing statis for stn_num=066062&month=04&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=09
Extracing statis for stn_num=066062&month=04&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=10
Extracing statis for stn_num=066062&month=04&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=11
Extracing statis for stn_num=066062&month=04&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=12
Extracing statis for stn_num=066062&month=04&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=13
Extracing statis for stn_num=066062&month=04&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=14
Extracing statis for stn_num=066062&month=04&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=15
Extracing statis for stn_num=066062&month=04&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=16
Extracing statis for stn_num=066062&month=04&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=17
Extracing statis for stn_num=066062&month=04&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=18
Extracing statis for stn_num=066062&month=04&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=19
Extracing statis for stn_num=066062&month=04&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=20
Extracing statis for stn_num=066062&month=04&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=21
Extracing statis for stn_num=066062&month=04&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=22
Extracing statis for stn_num=066062&month=04&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=23
Extracing statis for stn_num=066062&month=04&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=24
Extracing statis for stn_num=066062&month=04&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=25
Extracing statis for stn_num=066062&month=04&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=26
Extracing statis for stn_num=066062&month=04&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=27
Extracing statis for stn_num=066062&month=04&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=28
Extracing statis for stn_num=066062&month=04&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=29
Extracing statis for stn_num=066062&month=04&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=30
Extracing statis for stn_num=066062&month=05&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=01
Extracing statis for stn_num=066062&month=05&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=02
Extracing statis for stn_num=066062&month=05&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=03
Extracing statis for stn_num=066062&month=05&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=04
Extracing statis for stn_num=066062&month=05&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=05
Extracing statis for stn_num=066062&month=05&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=06
Extracing statis for stn_num=066062&month=05&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=07
Extracing statis for stn_num=066062&month=05&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=08
Extracing statis for stn_num=066062&month=05&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=09
Extracing statis for stn_num=066062&month=05&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=10
Extracing statis for stn_num=066062&month=05&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=11
Extracing statis for stn_num=066062&month=05&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=12
Extracing statis for stn_num=066062&month=05&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=13
Extracing statis for stn_num=066062&month=05&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=14
Extracing statis for stn_num=066062&month=05&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=15
Extracing statis for stn_num=066062&month=05&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=16
Extracing statis for stn_num=066062&month=05&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=17
Extracing statis for stn_num=066062&month=05&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=18
Extracing statis for stn_num=066062&month=05&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=19
Extracing statis for stn_num=066062&month=05&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=20
Extracing statis for stn_num=066062&month=05&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=21
Extracing statis for stn_num=066062&month=05&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=22
Extracing statis for stn_num=066062&month=05&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=23
Extracing statis for stn_num=066062&month=05&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=24
Extracing statis for stn_num=066062&month=05&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=25
Extracing statis for stn_num=066062&month=05&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=26
Extracing statis for stn_num=066062&month=05&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=27
Extracing statis for stn_num=066062&month=05&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=28
Extracing statis for stn_num=066062&month=05&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=29
Extracing statis for stn_num=066062&month=05&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=30
Extracing statis for stn_num=066062&month=05&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=31
Extracing statis for stn_num=066062&month=06&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=01
Extracing statis for stn_num=066062&month=06&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=02
Extracing statis for stn_num=066062&month=06&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=03
Extracing statis for stn_num=066062&month=06&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=04
Extracing statis for stn_num=066062&month=06&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=05
Extracing statis for stn_num=066062&month=06&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=06
Extracing statis for stn_num=066062&month=06&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=07
Extracing statis for stn_num=066062&month=06&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=08
Extracing statis for stn_num=066062&month=06&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=09
Extracing statis for stn_num=066062&month=06&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=10
Extracing statis for stn_num=066062&month=06&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=11
Extracing statis for stn_num=066062&month=06&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=12
Extracing statis for stn_num=066062&month=06&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=13
Extracing statis for stn_num=066062&month=06&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=14
Extracing statis for stn_num=066062&month=06&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=15
Extracing statis for stn_num=066062&month=06&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=16
Extracing statis for stn_num=066062&month=06&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=17
Extracing statis for stn_num=066062&month=06&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=18
Extracing statis for stn_num=066062&month=06&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=19
Extracing statis for stn_num=066062&month=06&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=20
Extracing statis for stn_num=066062&month=06&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=21
Extracing statis for stn_num=066062&month=06&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=22
Extracing statis for stn_num=066062&month=06&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=23
Extracing statis for stn_num=066062&month=06&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=24
Extracing statis for stn_num=066062&month=06&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=25
Extracing statis for stn_num=066062&month=06&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=26
Extracing statis for stn_num=066062&month=06&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=27
Extracing statis for stn_num=066062&month=06&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=28
Extracing statis for stn_num=066062&month=06&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=29
Extracing statis for stn_num=066062&month=06&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=30
Extracing statis for stn_num=066062&month=07&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=01
Extracing statis for stn_num=066062&month=07&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=02
Extracing statis for stn_num=066062&month=07&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=03
Extracing statis for stn_num=066062&month=07&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=04
Extracing statis for stn_num=066062&month=07&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=05
Extracing statis for stn_num=066062&month=07&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=06
Extracing statis for stn_num=066062&month=07&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=07
Extracing statis for stn_num=066062&month=07&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=08
Extracing statis for stn_num=066062&month=07&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=09
Extracing statis for stn_num=066062&month=07&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=10
Extracing statis for stn_num=066062&month=07&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=11
Extracing statis for stn_num=066062&month=07&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=12
Extracing statis for stn_num=066062&month=07&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=13
Extracing statis for stn_num=066062&month=07&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=14
Extracing statis for stn_num=066062&month=07&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=15
Extracing statis for stn_num=066062&month=07&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=16
Extracing statis for stn_num=066062&month=07&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=17
Extracing statis for stn_num=066062&month=07&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=18
Extracing statis for stn_num=066062&month=07&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=19
Extracing statis for stn_num=066062&month=07&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=20
Extracing statis for stn_num=066062&month=07&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=21
Extracing statis for stn_num=066062&month=07&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=22
Extracing statis for stn_num=066062&month=07&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=23
Extracing statis for stn_num=066062&month=07&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=24
Extracing statis for stn_num=066062&month=07&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=25
Extracing statis for stn_num=066062&month=07&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=26
Extracing statis for stn_num=066062&month=07&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=27
Extracing statis for stn_num=066062&month=07&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=28
Extracing statis for stn_num=066062&month=07&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=29
Extracing statis for stn_num=066062&month=07&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=30
Extracing statis for stn_num=066062&month=07&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=31
Extracing statis for stn_num=066062&month=08&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=01
Extracing statis for stn_num=066062&month=08&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=02
Extracing statis for stn_num=066062&month=08&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=03
Extracing statis for stn_num=066062&month=08&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=04
Extracing statis for stn_num=066062&month=08&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=05
Extracing statis for stn_num=066062&month=08&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=06
Extracing statis for stn_num=066062&month=08&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=07
Extracing statis for stn_num=066062&month=08&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=08
Extracing statis for stn_num=066062&month=08&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=09
Extracing statis for stn_num=066062&month=08&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=10
Extracing statis for stn_num=066062&month=08&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=11
Extracing statis for stn_num=066062&month=08&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=12
Extracing statis for stn_num=066062&month=08&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=13
Extracing statis for stn_num=066062&month=08&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=14
Extracing statis for stn_num=066062&month=08&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=15
Extracing statis for stn_num=066062&month=08&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=16
Extracing statis for stn_num=066062&month=08&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=17
Extracing statis for stn_num=066062&month=08&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=18
Extracing statis for stn_num=066062&month=08&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=19
Extracing statis for stn_num=066062&month=08&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=20
Extracing statis for stn_num=066062&month=08&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=21
Extracing statis for stn_num=066062&month=08&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=22
Extracing statis for stn_num=066062&month=08&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=23
Extracing statis for stn_num=066062&month=08&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=24
Extracing statis for stn_num=066062&month=08&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=25
Extracing statis for stn_num=066062&month=08&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=26
Extracing statis for stn_num=066062&month=08&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=27
Extracing statis for stn_num=066062&month=08&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=28
Extracing statis for stn_num=066062&month=08&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=29
Extracing statis for stn_num=066062&month=08&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=30
Extracing statis for stn_num=066062&month=08&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=31
Extracing statis for stn_num=066062&month=09&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=01
Extracing statis for stn_num=066062&month=09&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=02
Extracing statis for stn_num=066062&month=09&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=03
Extracing statis for stn_num=066062&month=09&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=04
Extracing statis for stn_num=066062&month=09&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=05
Extracing statis for stn_num=066062&month=09&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=06
Extracing statis for stn_num=066062&month=09&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=07
Extracing statis for stn_num=066062&month=09&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=08
Extracing statis for stn_num=066062&month=09&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=09
Extracing statis for stn_num=066062&month=09&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=10
Extracing statis for stn_num=066062&month=09&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=11
Extracing statis for stn_num=066062&month=09&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=12
Extracing statis for stn_num=066062&month=09&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=13
Extracing statis for stn_num=066062&month=09&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=14
Extracing statis for stn_num=066062&month=09&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=15
Extracing statis for stn_num=066062&month=09&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=16
Extracing statis for stn_num=066062&month=09&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=17
Extracing statis for stn_num=066062&month=09&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=18
Extracing statis for stn_num=066062&month=09&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=19
Extracing statis for stn_num=066062&month=09&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=20
Extracing statis for stn_num=066062&month=09&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=21
Extracing statis for stn_num=066062&month=09&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=22
Extracing statis for stn_num=066062&month=09&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=23
Extracing statis for stn_num=066062&month=09&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=24
Extracing statis for stn_num=066062&month=09&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=25
Extracing statis for stn_num=066062&month=09&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=26
Extracing statis for stn_num=066062&month=09&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=27
Extracing statis for stn_num=066062&month=09&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=28
Extracing statis for stn_num=066062&month=09&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=29
Extracing statis for stn_num=066062&month=09&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=30
Extracing statis for stn_num=066062&month=10&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=01
Extracing statis for stn_num=066062&month=10&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=02
Extracing statis for stn_num=066062&month=10&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=03
Extracing statis for stn_num=066062&month=10&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=04
Extracing statis for stn_num=066062&month=10&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=05
Extracing statis for stn_num=066062&month=10&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=06
Extracing statis for stn_num=066062&month=10&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=07
Extracing statis for stn_num=066062&month=10&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=08
Extracing statis for stn_num=066062&month=10&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=09
Extracing statis for stn_num=066062&month=10&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=10
Extracing statis for stn_num=066062&month=10&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=11
Extracing statis for stn_num=066062&month=10&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=12
Extracing statis for stn_num=066062&month=10&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=13
Extracing statis for stn_num=066062&month=10&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=14
Extracing statis for stn_num=066062&month=10&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=15
Extracing statis for stn_num=066062&month=10&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=16
Extracing statis for stn_num=066062&month=10&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=17
Extracing statis for stn_num=066062&month=10&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=18
Extracing statis for stn_num=066062&month=10&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=19
Extracing statis for stn_num=066062&month=10&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=20
Extracing statis for stn_num=066062&month=10&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=21
Extracing statis for stn_num=066062&month=10&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=22
Extracing statis for stn_num=066062&month=10&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=23
Extracing statis for stn_num=066062&month=10&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=24
Extracing statis for stn_num=066062&month=10&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=25
Extracing statis for stn_num=066062&month=10&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=26
Extracing statis for stn_num=066062&month=10&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=27
Extracing statis for stn_num=066062&month=10&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=28
Extracing statis for stn_num=066062&month=10&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=29
Extracing statis for stn_num=066062&month=10&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=30
Extracing statis for stn_num=066062&month=10&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=31
Extracing statis for stn_num=066062&month=11&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=01
Extracing statis for stn_num=066062&month=11&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=02
Extracing statis for stn_num=066062&month=11&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=03
Extracing statis for stn_num=066062&month=11&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=04
Extracing statis for stn_num=066062&month=11&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=05
Extracing statis for stn_num=066062&month=11&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=06
Extracing statis for stn_num=066062&month=11&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=07
Extracing statis for stn_num=066062&month=11&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=08
Extracing statis for stn_num=066062&month=11&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=09
Extracing statis for stn_num=066062&month=11&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=10
Extracing statis for stn_num=066062&month=11&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=11
Extracing statis for stn_num=066062&month=11&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=12
Extracing statis for stn_num=066062&month=11&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=13
Extracing statis for stn_num=066062&month=11&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=14
Extracing statis for stn_num=066062&month=11&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=15
Extracing statis for stn_num=066062&month=11&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=16
Extracing statis for stn_num=066062&month=11&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=17
Extracing statis for stn_num=066062&month=11&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=18
Extracing statis for stn_num=066062&month=11&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=19
Extracing statis for stn_num=066062&month=11&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=20
Extracing statis for stn_num=066062&month=11&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=21
Extracing statis for stn_num=066062&month=11&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=22
Extracing statis for stn_num=066062&month=11&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=23
Extracing statis for stn_num=066062&month=11&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=24
Extracing statis for stn_num=066062&month=11&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=25
Extracing statis for stn_num=066062&month=11&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=26
Extracing statis for stn_num=066062&month=11&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=27
Extracing statis for stn_num=066062&month=11&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=28
Extracing statis for stn_num=066062&month=11&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=29
Extracing statis for stn_num=066062&month=11&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=30
Extracing statis for stn_num=066062&month=12&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=01
Extracing statis for stn_num=066062&month=12&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=02
Extracing statis for stn_num=066062&month=12&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=03
Extracing statis for stn_num=066062&month=12&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=04
Extracing statis for stn_num=066062&month=12&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=05
Extracing statis for stn_num=066062&month=12&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=06
Extracing statis for stn_num=066062&month=12&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=07
Extracing statis for stn_num=066062&month=12&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=08
Extracing statis for stn_num=066062&month=12&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=09
Extracing statis for stn_num=066062&month=12&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=10
Extracing statis for stn_num=066062&month=12&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=11
Extracing statis for stn_num=066062&month=12&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=12
Extracing statis for stn_num=066062&month=12&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=13
Extracing statis for stn_num=066062&month=12&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=14
Extracing statis for stn_num=066062&month=12&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=15
Extracing statis for stn_num=066062&month=12&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=16
Extracing statis for stn_num=066062&month=12&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=17
Extracing statis for stn_num=066062&month=12&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=18
Extracing statis for stn_num=066062&month=12&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=19
Extracing statis for stn_num=066062&month=12&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=20
Extracing statis for stn_num=066062&month=12&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=21
Extracing statis for stn_num=066062&month=12&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=22
Extracing statis for stn_num=066062&month=12&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=23
Extracing statis for stn_num=066062&month=12&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=24
Extracing statis for stn_num=066062&month=12&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=25
Extracing statis for stn_num=066062&month=12&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=26
Extracing statis for stn_num=066062&month=12&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=27
Extracing statis for stn_num=066062&month=12&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=28
Extracing statis for stn_num=066062&month=12&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=29
Extracing statis for stn_num=066062&month=12&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=30
Extracing statis for stn_num=066062&month=12&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=31
statis filename:Melbourne, site_code:086038, start_date:2018-01-01, end_date:2018-12-31
Extracing statis for stn_num=086038&month=01&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=01
Extracing statis for stn_num=086038&month=01&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=02
Extracing statis for stn_num=086038&month=01&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=03
Extracing statis for stn_num=086038&month=01&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=04
Extracing statis for stn_num=086038&month=01&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=05
Extracing statis for stn_num=086038&month=01&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=06
Extracing statis for stn_num=086038&month=01&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=07
Extracing statis for stn_num=086038&month=01&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=08
Extracing statis for stn_num=086038&month=01&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=09
Extracing statis for stn_num=086038&month=01&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=10
Extracing statis for stn_num=086038&month=01&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=11
Extracing statis for stn_num=086038&month=01&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=12
Extracing statis for stn_num=086038&month=01&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=13
Extracing statis for stn_num=086038&month=01&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=14
Extracing statis for stn_num=086038&month=01&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=15
Extracing statis for stn_num=086038&month=01&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=16
Extracing statis for stn_num=086038&month=01&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=17
Extracing statis for stn_num=086038&month=01&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=18
Extracing statis for stn_num=086038&month=01&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=19
Extracing statis for stn_num=086038&month=01&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=20
Extracing statis for stn_num=086038&month=01&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=21
Extracing statis for stn_num=086038&month=01&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=22
Extracing statis for stn_num=086038&month=01&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=23
Extracing statis for stn_num=086038&month=01&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=24
Extracing statis for stn_num=086038&month=01&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=25
Extracing statis for stn_num=086038&month=01&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=26
Extracing statis for stn_num=086038&month=01&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=27
Extracing statis for stn_num=086038&month=01&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=28
Extracing statis for stn_num=086038&month=01&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=29
Extracing statis for stn_num=086038&month=01&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=30
Extracing statis for stn_num=086038&month=01&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=31
Extracing statis for stn_num=086038&month=02&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=01
Extracing statis for stn_num=086038&month=02&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=02
Extracing statis for stn_num=086038&month=02&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=03
Extracing statis for stn_num=086038&month=02&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=04
Extracing statis for stn_num=086038&month=02&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=05
Extracing statis for stn_num=086038&month=02&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=06
Extracing statis for stn_num=086038&month=02&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=07
Extracing statis for stn_num=086038&month=02&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=08
Extracing statis for stn_num=086038&month=02&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=09
Extracing statis for stn_num=086038&month=02&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=10
Extracing statis for stn_num=086038&month=02&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=11
Extracing statis for stn_num=086038&month=02&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=12
Extracing statis for stn_num=086038&month=02&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=13
Extracing statis for stn_num=086038&month=02&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=14
Extracing statis for stn_num=086038&month=02&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=15
Extracing statis for stn_num=086038&month=02&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=16
Extracing statis for stn_num=086038&month=02&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=17
Extracing statis for stn_num=086038&month=02&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=18
Extracing statis for stn_num=086038&month=02&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=19
Extracing statis for stn_num=086038&month=02&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=20
Extracing statis for stn_num=086038&month=02&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=21
Extracing statis for stn_num=086038&month=02&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=22
Extracing statis for stn_num=086038&month=02&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=23
Extracing statis for stn_num=086038&month=02&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=24
Extracing statis for stn_num=086038&month=02&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=25
Extracing statis for stn_num=086038&month=02&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=26
Extracing statis for stn_num=086038&month=02&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=27
Extracing statis for stn_num=086038&month=02&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=28
Extracing statis for stn_num=086038&month=03&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=01
Extracing statis for stn_num=086038&month=03&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=02
Extracing statis for stn_num=086038&month=03&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=03
Extracing statis for stn_num=086038&month=03&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=04
Extracing statis for stn_num=086038&month=03&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=05
Extracing statis for stn_num=086038&month=03&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=06
Extracing statis for stn_num=086038&month=03&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=07
Extracing statis for stn_num=086038&month=03&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=08
Extracing statis for stn_num=086038&month=03&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=09
Extracing statis for stn_num=086038&month=03&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=10
Extracing statis for stn_num=086038&month=03&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=11
Extracing statis for stn_num=086038&month=03&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=12
Extracing statis for stn_num=086038&month=03&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=13
Extracing statis for stn_num=086038&month=03&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=14
Extracing statis for stn_num=086038&month=03&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=15
Extracing statis for stn_num=086038&month=03&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=16
Extracing statis for stn_num=086038&month=03&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=17
Extracing statis for stn_num=086038&month=03&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=18
Extracing statis for stn_num=086038&month=03&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=19
Extracing statis for stn_num=086038&month=03&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=20
Extracing statis for stn_num=086038&month=03&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=21
Extracing statis for stn_num=086038&month=03&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=22
Extracing statis for stn_num=086038&month=03&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=23
Extracing statis for stn_num=086038&month=03&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=24
Extracing statis for stn_num=086038&month=03&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=25
Extracing statis for stn_num=086038&month=03&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=26
Extracing statis for stn_num=086038&month=03&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=27
Extracing statis for stn_num=086038&month=03&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=28
Extracing statis for stn_num=086038&month=03&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=29
Extracing statis for stn_num=086038&month=03&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=30
Extracing statis for stn_num=086038&month=03&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=31
Extracing statis for stn_num=086038&month=04&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=01
Extracing statis for stn_num=086038&month=04&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=02
Extracing statis for stn_num=086038&month=04&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=03
Extracing statis for stn_num=086038&month=04&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=04
Extracing statis for stn_num=086038&month=04&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=05
Extracing statis for stn_num=086038&month=04&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=06
Extracing statis for stn_num=086038&month=04&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=07
Extracing statis for stn_num=086038&month=04&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=08
Extracing statis for stn_num=086038&month=04&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=09
Extracing statis for stn_num=086038&month=04&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=10
Extracing statis for stn_num=086038&month=04&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=11
Extracing statis for stn_num=086038&month=04&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=12
Extracing statis for stn_num=086038&month=04&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=13
Extracing statis for stn_num=086038&month=04&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=14
Extracing statis for stn_num=086038&month=04&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=15
Extracing statis for stn_num=086038&month=04&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=16
Extracing statis for stn_num=086038&month=04&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=17
Extracing statis for stn_num=086038&month=04&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=18
Extracing statis for stn_num=086038&month=04&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=19
Extracing statis for stn_num=086038&month=04&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=20
Extracing statis for stn_num=086038&month=04&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=21
Extracing statis for stn_num=086038&month=04&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=22
Extracing statis for stn_num=086038&month=04&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=23
Extracing statis for stn_num=086038&month=04&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=24
Extracing statis for stn_num=086038&month=04&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=25
Extracing statis for stn_num=086038&month=04&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=26
Extracing statis for stn_num=086038&month=04&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=27
Extracing statis for stn_num=086038&month=04&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=28
Extracing statis for stn_num=086038&month=04&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=29
Extracing statis for stn_num=086038&month=04&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=30
Extracing statis for stn_num=086038&month=05&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=01
Extracing statis for stn_num=086038&month=05&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=02
Extracing statis for stn_num=086038&month=05&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=03
Extracing statis for stn_num=086038&month=05&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=04
Extracing statis for stn_num=086038&month=05&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=05
Extracing statis for stn_num=086038&month=05&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=06
Extracing statis for stn_num=086038&month=05&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=07
Extracing statis for stn_num=086038&month=05&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=08
Extracing statis for stn_num=086038&month=05&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=09
Extracing statis for stn_num=086038&month=05&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=10
Extracing statis for stn_num=086038&month=05&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=11
Extracing statis for stn_num=086038&month=05&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=12
Extracing statis for stn_num=086038&month=05&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=13
Extracing statis for stn_num=086038&month=05&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=14
Extracing statis for stn_num=086038&month=05&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=15
Extracing statis for stn_num=086038&month=05&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=16
Extracing statis for stn_num=086038&month=05&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=17
Extracing statis for stn_num=086038&month=05&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=18
Extracing statis for stn_num=086038&month=05&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=19
Extracing statis for stn_num=086038&month=05&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=20
Extracing statis for stn_num=086038&month=05&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=21
Extracing statis for stn_num=086038&month=05&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=22
Extracing statis for stn_num=086038&month=05&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=23
Extracing statis for stn_num=086038&month=05&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=24
Extracing statis for stn_num=086038&month=05&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=25
Extracing statis for stn_num=086038&month=05&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=26
Extracing statis for stn_num=086038&month=05&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=27
Extracing statis for stn_num=086038&month=05&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=28
Extracing statis for stn_num=086038&month=05&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=29
Extracing statis for stn_num=086038&month=05&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=30
Extracing statis for stn_num=086038&month=05&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=31
Extracing statis for stn_num=086038&month=06&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=01
Extracing statis for stn_num=086038&month=06&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=02
Extracing statis for stn_num=086038&month=06&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=03
Extracing statis for stn_num=086038&month=06&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=04
Extracing statis for stn_num=086038&month=06&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=05
Extracing statis for stn_num=086038&month=06&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=06
Extracing statis for stn_num=086038&month=06&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=07
Extracing statis for stn_num=086038&month=06&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=08
Extracing statis for stn_num=086038&month=06&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=09
Extracing statis for stn_num=086038&month=06&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=10
Extracing statis for stn_num=086038&month=06&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=11
Extracing statis for stn_num=086038&month=06&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=12
Extracing statis for stn_num=086038&month=06&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=13
Extracing statis for stn_num=086038&month=06&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=14
Extracing statis for stn_num=086038&month=06&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=15
Extracing statis for stn_num=086038&month=06&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=16
Extracing statis for stn_num=086038&month=06&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=17
Extracing statis for stn_num=086038&month=06&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=18
Extracing statis for stn_num=086038&month=06&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=19
Extracing statis for stn_num=086038&month=06&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=20
Extracing statis for stn_num=086038&month=06&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=21
Extracing statis for stn_num=086038&month=06&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=22
Extracing statis for stn_num=086038&month=06&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=23
Extracing statis for stn_num=086038&month=06&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=24
Extracing statis for stn_num=086038&month=06&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=25
Extracing statis for stn_num=086038&month=06&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=26
Extracing statis for stn_num=086038&month=06&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=27
Extracing statis for stn_num=086038&month=06&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=28
Extracing statis for stn_num=086038&month=06&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=29
Extracing statis for stn_num=086038&month=06&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=30
Extracing statis for stn_num=086038&month=07&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=01
Extracing statis for stn_num=086038&month=07&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=02
Extracing statis for stn_num=086038&month=07&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=03
Extracing statis for stn_num=086038&month=07&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=04
Extracing statis for stn_num=086038&month=07&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=05
Extracing statis for stn_num=086038&month=07&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=06
Extracing statis for stn_num=086038&month=07&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=07
Extracing statis for stn_num=086038&month=07&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=08
Extracing statis for stn_num=086038&month=07&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=09
Extracing statis for stn_num=086038&month=07&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=10
Extracing statis for stn_num=086038&month=07&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=11
Extracing statis for stn_num=086038&month=07&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=12
Extracing statis for stn_num=086038&month=07&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=13
Extracing statis for stn_num=086038&month=07&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=14
Extracing statis for stn_num=086038&month=07&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=15
Extracing statis for stn_num=086038&month=07&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=16
Extracing statis for stn_num=086038&month=07&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=17
Extracing statis for stn_num=086038&month=07&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=18
Extracing statis for stn_num=086038&month=07&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=19
Extracing statis for stn_num=086038&month=07&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=20
Extracing statis for stn_num=086038&month=07&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=21
Extracing statis for stn_num=086038&month=07&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=22
Extracing statis for stn_num=086038&month=07&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=23
Extracing statis for stn_num=086038&month=07&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=24
Extracing statis for stn_num=086038&month=07&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=25
Extracing statis for stn_num=086038&month=07&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=26
Extracing statis for stn_num=086038&month=07&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=27
Extracing statis for stn_num=086038&month=07&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=28
Extracing statis for stn_num=086038&month=07&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=29
Extracing statis for stn_num=086038&month=07&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=30
Extracing statis for stn_num=086038&month=07&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=31
Extracing statis for stn_num=086038&month=08&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=01
Extracing statis for stn_num=086038&month=08&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=02
Extracing statis for stn_num=086038&month=08&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=03
Extracing statis for stn_num=086038&month=08&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=04
Extracing statis for stn_num=086038&month=08&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=05
Extracing statis for stn_num=086038&month=08&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=06
Extracing statis for stn_num=086038&month=08&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=07
Extracing statis for stn_num=086038&month=08&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=08
Extracing statis for stn_num=086038&month=08&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=09
Extracing statis for stn_num=086038&month=08&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=10
Extracing statis for stn_num=086038&month=08&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=11
Extracing statis for stn_num=086038&month=08&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=12
Extracing statis for stn_num=086038&month=08&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=13
Extracing statis for stn_num=086038&month=08&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=14
Extracing statis for stn_num=086038&month=08&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=15
Extracing statis for stn_num=086038&month=08&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=16
Extracing statis for stn_num=086038&month=08&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=17
Extracing statis for stn_num=086038&month=08&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=18
Extracing statis for stn_num=086038&month=08&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=19
Extracing statis for stn_num=086038&month=08&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=20
Extracing statis for stn_num=086038&month=08&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=21
Extracing statis for stn_num=086038&month=08&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=22
Extracing statis for stn_num=086038&month=08&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=23
Extracing statis for stn_num=086038&month=08&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=24
Extracing statis for stn_num=086038&month=08&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=25
Extracing statis for stn_num=086038&month=08&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=26
Extracing statis for stn_num=086038&month=08&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=27
Extracing statis for stn_num=086038&month=08&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=28
Extracing statis for stn_num=086038&month=08&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=29
Extracing statis for stn_num=086038&month=08&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=30
Extracing statis for stn_num=086038&month=08&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=31
Extracing statis for stn_num=086038&month=09&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=01
Extracing statis for stn_num=086038&month=09&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=02
Extracing statis for stn_num=086038&month=09&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=03
Extracing statis for stn_num=086038&month=09&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=04
Extracing statis for stn_num=086038&month=09&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=05
Extracing statis for stn_num=086038&month=09&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=06
Extracing statis for stn_num=086038&month=09&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=07
Extracing statis for stn_num=086038&month=09&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=08
Extracing statis for stn_num=086038&month=09&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=09
Extracing statis for stn_num=086038&month=09&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=10
Extracing statis for stn_num=086038&month=09&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=11
Extracing statis for stn_num=086038&month=09&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=12
Extracing statis for stn_num=086038&month=09&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=13
Extracing statis for stn_num=086038&month=09&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=14
Extracing statis for stn_num=086038&month=09&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=15
Extracing statis for stn_num=086038&month=09&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=16
Extracing statis for stn_num=086038&month=09&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=17
Extracing statis for stn_num=086038&month=09&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=18
Extracing statis for stn_num=086038&month=09&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=19
Extracing statis for stn_num=086038&month=09&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=20
Extracing statis for stn_num=086038&month=09&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=21
Extracing statis for stn_num=086038&month=09&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=22
Extracing statis for stn_num=086038&month=09&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=23
Extracing statis for stn_num=086038&month=09&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=24
Extracing statis for stn_num=086038&month=09&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=25
Extracing statis for stn_num=086038&month=09&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=26
Extracing statis for stn_num=086038&month=09&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=27
Extracing statis for stn_num=086038&month=09&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=28
Extracing statis for stn_num=086038&month=09&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=29
Extracing statis for stn_num=086038&month=09&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=30
Extracing statis for stn_num=086038&month=10&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=01
Extracing statis for stn_num=086038&month=10&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=02
Extracing statis for stn_num=086038&month=10&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=03
Extracing statis for stn_num=086038&month=10&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=04
Extracing statis for stn_num=086038&month=10&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=05
Extracing statis for stn_num=086038&month=10&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=06
Extracing statis for stn_num=086038&month=10&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=07
Extracing statis for stn_num=086038&month=10&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=08
Extracing statis for stn_num=086038&month=10&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=09
Extracing statis for stn_num=086038&month=10&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=10
Extracing statis for stn_num=086038&month=10&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=11
Extracing statis for stn_num=086038&month=10&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=12
Extracing statis for stn_num=086038&month=10&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=13
Extracing statis for stn_num=086038&month=10&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=14
Extracing statis for stn_num=086038&month=10&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=15
Extracing statis for stn_num=086038&month=10&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=16
Extracing statis for stn_num=086038&month=10&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=17
Extracing statis for stn_num=086038&month=10&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=18
Extracing statis for stn_num=086038&month=10&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=19
Extracing statis for stn_num=086038&month=10&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=20
Extracing statis for stn_num=086038&month=10&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=21
Extracing statis for stn_num=086038&month=10&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=22
Extracing statis for stn_num=086038&month=10&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=23
Extracing statis for stn_num=086038&month=10&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=24
Extracing statis for stn_num=086038&month=10&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=25
Extracing statis for stn_num=086038&month=10&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=26
Extracing statis for stn_num=086038&month=10&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=27
Extracing statis for stn_num=086038&month=10&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=28
Extracing statis for stn_num=086038&month=10&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=29
Extracing statis for stn_num=086038&month=10&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=30
Extracing statis for stn_num=086038&month=10&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=31
Extracing statis for stn_num=086038&month=11&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=01
Extracing statis for stn_num=086038&month=11&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=02
Extracing statis for stn_num=086038&month=11&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=03
Extracing statis for stn_num=086038&month=11&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=04
Extracing statis for stn_num=086038&month=11&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=05
Extracing statis for stn_num=086038&month=11&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=06
Extracing statis for stn_num=086038&month=11&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=07
Extracing statis for stn_num=086038&month=11&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=08
Extracing statis for stn_num=086038&month=11&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=09
Extracing statis for stn_num=086038&month=11&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=10
Extracing statis for stn_num=086038&month=11&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=11
Extracing statis for stn_num=086038&month=11&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=12
Extracing statis for stn_num=086038&month=11&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=13
Extracing statis for stn_num=086038&month=11&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=14
Extracing statis for stn_num=086038&month=11&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=15
Extracing statis for stn_num=086038&month=11&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=16
Extracing statis for stn_num=086038&month=11&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=17
Extracing statis for stn_num=086038&month=11&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=18
Extracing statis for stn_num=086038&month=11&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=19
Extracing statis for stn_num=086038&month=11&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=20
Extracing statis for stn_num=086038&month=11&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=21
Extracing statis for stn_num=086038&month=11&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=22
Extracing statis for stn_num=086038&month=11&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=23
Extracing statis for stn_num=086038&month=11&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=24
Extracing statis for stn_num=086038&month=11&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=25
Extracing statis for stn_num=086038&month=11&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=26
Extracing statis for stn_num=086038&month=11&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=27
Extracing statis for stn_num=086038&month=11&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=28
Extracing statis for stn_num=086038&month=11&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=29
Extracing statis for stn_num=086038&month=11&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=30
Extracing statis for stn_num=086038&month=12&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=01
Extracing statis for stn_num=086038&month=12&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=02
Extracing statis for stn_num=086038&month=12&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=03
Extracing statis for stn_num=086038&month=12&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=04
Extracing statis for stn_num=086038&month=12&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=05
Extracing statis for stn_num=086038&month=12&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=06
Extracing statis for stn_num=086038&month=12&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=07
Extracing statis for stn_num=086038&month=12&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=08
Extracing statis for stn_num=086038&month=12&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=09
Extracing statis for stn_num=086038&month=12&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=10
Extracing statis for stn_num=086038&month=12&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=11
Extracing statis for stn_num=086038&month=12&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=12
Extracing statis for stn_num=086038&month=12&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=13
Extracing statis for stn_num=086038&month=12&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=14
Extracing statis for stn_num=086038&month=12&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=15
Extracing statis for stn_num=086038&month=12&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=16
Extracing statis for stn_num=086038&month=12&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=17
Extracing statis for stn_num=086038&month=12&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=18
Extracing statis for stn_num=086038&month=12&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=19
Extracing statis for stn_num=086038&month=12&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=20
Extracing statis for stn_num=086038&month=12&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=21
Extracing statis for stn_num=086038&month=12&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=22
Extracing statis for stn_num=086038&month=12&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=23
Extracing statis for stn_num=086038&month=12&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=24
Extracing statis for stn_num=086038&month=12&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=25
Extracing statis for stn_num=086038&month=12&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=26
Extracing statis for stn_num=086038&month=12&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=27
Extracing statis for stn_num=086038&month=12&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=28
Extracing statis for stn_num=086038&month=12&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=29
Extracing statis for stn_num=086038&month=12&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=30
Extracing statis for stn_num=086038&month=12&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=31
statis filename:Adelaide, site_code:023000, start_date:2018-01-01, end_date:2018-12-31
Extracing statis for stn_num=023000&month=01&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=01
Extracing statis for stn_num=023000&month=01&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=02
Extracing statis for stn_num=023000&month=01&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=03
Extracing statis for stn_num=023000&month=01&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=04
Extracing statis for stn_num=023000&month=01&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=05
Extracing statis for stn_num=023000&month=01&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=06
Extracing statis for stn_num=023000&month=01&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=07
Extracing statis for stn_num=023000&month=01&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=08
Extracing statis for stn_num=023000&month=01&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=09
Extracing statis for stn_num=023000&month=01&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=10
Extracing statis for stn_num=023000&month=01&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=11
Extracing statis for stn_num=023000&month=01&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=12
Extracing statis for stn_num=023000&month=01&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=13
Extracing statis for stn_num=023000&month=01&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=14
Extracing statis for stn_num=023000&month=01&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=15
Extracing statis for stn_num=023000&month=01&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=16
Extracing statis for stn_num=023000&month=01&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=17
Extracing statis for stn_num=023000&month=01&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=18
Extracing statis for stn_num=023000&month=01&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=19
Extracing statis for stn_num=023000&month=01&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=20
Extracing statis for stn_num=023000&month=01&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=21
Extracing statis for stn_num=023000&month=01&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=22
Extracing statis for stn_num=023000&month=01&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=23
Extracing statis for stn_num=023000&month=01&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=24
Extracing statis for stn_num=023000&month=01&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=25
Extracing statis for stn_num=023000&month=01&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=26
Extracing statis for stn_num=023000&month=01&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=27
Extracing statis for stn_num=023000&month=01&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=28
Extracing statis for stn_num=023000&month=01&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=29
Extracing statis for stn_num=023000&month=01&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=30
Extracing statis for stn_num=023000&month=01&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=31
Extracing statis for stn_num=023000&month=02&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=01
Extracing statis for stn_num=023000&month=02&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=02
Extracing statis for stn_num=023000&month=02&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=03
Extracing statis for stn_num=023000&month=02&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=04
Extracing statis for stn_num=023000&month=02&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=05
Extracing statis for stn_num=023000&month=02&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=06
Extracing statis for stn_num=023000&month=02&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=07
Extracing statis for stn_num=023000&month=02&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=08
Extracing statis for stn_num=023000&month=02&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=09
Extracing statis for stn_num=023000&month=02&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=10
Extracing statis for stn_num=023000&month=02&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=11
Extracing statis for stn_num=023000&month=02&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=12
Extracing statis for stn_num=023000&month=02&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=13
Extracing statis for stn_num=023000&month=02&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=14
Extracing statis for stn_num=023000&month=02&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=15
Extracing statis for stn_num=023000&month=02&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=16
Extracing statis for stn_num=023000&month=02&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=17
Extracing statis for stn_num=023000&month=02&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=18
Extracing statis for stn_num=023000&month=02&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=19
Extracing statis for stn_num=023000&month=02&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=20
Extracing statis for stn_num=023000&month=02&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=21
Extracing statis for stn_num=023000&month=02&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=22
Extracing statis for stn_num=023000&month=02&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=23
Extracing statis for stn_num=023000&month=02&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=24
Extracing statis for stn_num=023000&month=02&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=25
Extracing statis for stn_num=023000&month=02&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=26
Extracing statis for stn_num=023000&month=02&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=27
Extracing statis for stn_num=023000&month=02&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=28
Extracing statis for stn_num=023000&month=03&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=01
Extracing statis for stn_num=023000&month=03&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=02
Extracing statis for stn_num=023000&month=03&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=03
Extracing statis for stn_num=023000&month=03&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=04
Extracing statis for stn_num=023000&month=03&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=05
Extracing statis for stn_num=023000&month=03&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=06
Extracing statis for stn_num=023000&month=03&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=07
Extracing statis for stn_num=023000&month=03&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=08
Extracing statis for stn_num=023000&month=03&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=09
Extracing statis for stn_num=023000&month=03&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=10
Extracing statis for stn_num=023000&month=03&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=11
Extracing statis for stn_num=023000&month=03&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=12
Extracing statis for stn_num=023000&month=03&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=13
Extracing statis for stn_num=023000&month=03&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=14
Extracing statis for stn_num=023000&month=03&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=15
Extracing statis for stn_num=023000&month=03&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=16
Extracing statis for stn_num=023000&month=03&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=17
Extracing statis for stn_num=023000&month=03&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=18
Extracing statis for stn_num=023000&month=03&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=19
Extracing statis for stn_num=023000&month=03&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=20
Extracing statis for stn_num=023000&month=03&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=21
Extracing statis for stn_num=023000&month=03&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=22
Extracing statis for stn_num=023000&month=03&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=23
Extracing statis for stn_num=023000&month=03&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=24
Extracing statis for stn_num=023000&month=03&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=25
Extracing statis for stn_num=023000&month=03&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=26
Extracing statis for stn_num=023000&month=03&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=27
Extracing statis for stn_num=023000&month=03&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=28
Extracing statis for stn_num=023000&month=03&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=29
Extracing statis for stn_num=023000&month=03&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=30
Extracing statis for stn_num=023000&month=03&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=31
Extracing statis for stn_num=023000&month=04&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=01
Extracing statis for stn_num=023000&month=04&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=02
Extracing statis for stn_num=023000&month=04&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=03
Extracing statis for stn_num=023000&month=04&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=04
Extracing statis for stn_num=023000&month=04&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=05
Extracing statis for stn_num=023000&month=04&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=06
Extracing statis for stn_num=023000&month=04&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=07
Extracing statis for stn_num=023000&month=04&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=08
Extracing statis for stn_num=023000&month=04&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=09
Extracing statis for stn_num=023000&month=04&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=10
Extracing statis for stn_num=023000&month=04&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=11
Extracing statis for stn_num=023000&month=04&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=12
Extracing statis for stn_num=023000&month=04&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=13
Extracing statis for stn_num=023000&month=04&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=14
Extracing statis for stn_num=023000&month=04&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=15
Extracing statis for stn_num=023000&month=04&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=16
Extracing statis for stn_num=023000&month=04&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=17
Extracing statis for stn_num=023000&month=04&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=18
Extracing statis for stn_num=023000&month=04&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=19
Extracing statis for stn_num=023000&month=04&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=20
Extracing statis for stn_num=023000&month=04&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=21
Extracing statis for stn_num=023000&month=04&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=22
Extracing statis for stn_num=023000&month=04&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=23
Extracing statis for stn_num=023000&month=04&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=24
Extracing statis for stn_num=023000&month=04&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=25
Extracing statis for stn_num=023000&month=04&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=26
Extracing statis for stn_num=023000&month=04&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=27
Extracing statis for stn_num=023000&month=04&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=28
Extracing statis for stn_num=023000&month=04&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=29
Extracing statis for stn_num=023000&month=04&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=30
Extracing statis for stn_num=023000&month=05&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=01
Extracing statis for stn_num=023000&month=05&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=02
Extracing statis for stn_num=023000&month=05&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=03
Extracing statis for stn_num=023000&month=05&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=04
Extracing statis for stn_num=023000&month=05&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=05
Extracing statis for stn_num=023000&month=05&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=06
Extracing statis for stn_num=023000&month=05&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=07
Extracing statis for stn_num=023000&month=05&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=08
Extracing statis for stn_num=023000&month=05&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=09
Extracing statis for stn_num=023000&month=05&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=10
Extracing statis for stn_num=023000&month=05&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=11
Extracing statis for stn_num=023000&month=05&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=12
Extracing statis for stn_num=023000&month=05&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=13
Extracing statis for stn_num=023000&month=05&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=14
Extracing statis for stn_num=023000&month=05&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=15
Extracing statis for stn_num=023000&month=05&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=16
Extracing statis for stn_num=023000&month=05&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=17
Extracing statis for stn_num=023000&month=05&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=18
Extracing statis for stn_num=023000&month=05&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=19
Extracing statis for stn_num=023000&month=05&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=20
Extracing statis for stn_num=023000&month=05&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=21
Extracing statis for stn_num=023000&month=05&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=22
Extracing statis for stn_num=023000&month=05&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=23
Extracing statis for stn_num=023000&month=05&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=24
Extracing statis for stn_num=023000&month=05&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=25
Extracing statis for stn_num=023000&month=05&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=26
Extracing statis for stn_num=023000&month=05&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=27
Extracing statis for stn_num=023000&month=05&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=28
Extracing statis for stn_num=023000&month=05&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=29
Extracing statis for stn_num=023000&month=05&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=30
Extracing statis for stn_num=023000&month=05&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=31
Extracing statis for stn_num=023000&month=06&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=01
Extracing statis for stn_num=023000&month=06&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=02
Extracing statis for stn_num=023000&month=06&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=03
Extracing statis for stn_num=023000&month=06&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=04
Extracing statis for stn_num=023000&month=06&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=05
Extracing statis for stn_num=023000&month=06&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=06
Extracing statis for stn_num=023000&month=06&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=07
Extracing statis for stn_num=023000&month=06&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=08
Extracing statis for stn_num=023000&month=06&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=09
Extracing statis for stn_num=023000&month=06&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=10
Extracing statis for stn_num=023000&month=06&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=11
Extracing statis for stn_num=023000&month=06&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=12
Extracing statis for stn_num=023000&month=06&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=13
Extracing statis for stn_num=023000&month=06&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=14
Extracing statis for stn_num=023000&month=06&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=15
Extracing statis for stn_num=023000&month=06&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=16
Extracing statis for stn_num=023000&month=06&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=17
Extracing statis for stn_num=023000&month=06&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=18
Extracing statis for stn_num=023000&month=06&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=19
Extracing statis for stn_num=023000&month=06&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=20
Extracing statis for stn_num=023000&month=06&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=21
Extracing statis for stn_num=023000&month=06&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=22
Extracing statis for stn_num=023000&month=06&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=23
Extracing statis for stn_num=023000&month=06&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=24
Extracing statis for stn_num=023000&month=06&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=25
Extracing statis for stn_num=023000&month=06&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=26
Extracing statis for stn_num=023000&month=06&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=27
Extracing statis for stn_num=023000&month=06&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=28
Extracing statis for stn_num=023000&month=06&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=29
Extracing statis for stn_num=023000&month=06&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=30
Extracing statis for stn_num=023000&month=07&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=01
Extracing statis for stn_num=023000&month=07&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=02
Extracing statis for stn_num=023000&month=07&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=03
Extracing statis for stn_num=023000&month=07&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=04
Extracing statis for stn_num=023000&month=07&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=05
Extracing statis for stn_num=023000&month=07&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=06
Extracing statis for stn_num=023000&month=07&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=07
Extracing statis for stn_num=023000&month=07&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=08
Extracing statis for stn_num=023000&month=07&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=09
Extracing statis for stn_num=023000&month=07&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=10
Extracing statis for stn_num=023000&month=07&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=11
Extracing statis for stn_num=023000&month=07&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=12
Extracing statis for stn_num=023000&month=07&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=13
Extracing statis for stn_num=023000&month=07&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=14
Extracing statis for stn_num=023000&month=07&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=15
Extracing statis for stn_num=023000&month=07&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=16
Extracing statis for stn_num=023000&month=07&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=17
Extracing statis for stn_num=023000&month=07&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=18
Extracing statis for stn_num=023000&month=07&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=19
Extracing statis for stn_num=023000&month=07&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=20
Extracing statis for stn_num=023000&month=07&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=21
Extracing statis for stn_num=023000&month=07&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=22
Extracing statis for stn_num=023000&month=07&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=23
Extracing statis for stn_num=023000&month=07&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=24
Extracing statis for stn_num=023000&month=07&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=25
Extracing statis for stn_num=023000&month=07&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=26
Extracing statis for stn_num=023000&month=07&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=27
Extracing statis for stn_num=023000&month=07&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=28
Extracing statis for stn_num=023000&month=07&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=29
Extracing statis for stn_num=023000&month=07&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=30
Extracing statis for stn_num=023000&month=07&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=31
Extracing statis for stn_num=023000&month=08&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=01
Extracing statis for stn_num=023000&month=08&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=02
Extracing statis for stn_num=023000&month=08&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=03
Extracing statis for stn_num=023000&month=08&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=04
Extracing statis for stn_num=023000&month=08&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=05
Extracing statis for stn_num=023000&month=08&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=06
Extracing statis for stn_num=023000&month=08&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=07
Extracing statis for stn_num=023000&month=08&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=08
Extracing statis for stn_num=023000&month=08&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=09
Extracing statis for stn_num=023000&month=08&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=10
Extracing statis for stn_num=023000&month=08&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=11
Extracing statis for stn_num=023000&month=08&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=12
Extracing statis for stn_num=023000&month=08&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=13
Extracing statis for stn_num=023000&month=08&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=14
Extracing statis for stn_num=023000&month=08&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=15
Extracing statis for stn_num=023000&month=08&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=16
Extracing statis for stn_num=023000&month=08&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=17
Extracing statis for stn_num=023000&month=08&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=18
Extracing statis for stn_num=023000&month=08&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=19
Extracing statis for stn_num=023000&month=08&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=20
Extracing statis for stn_num=023000&month=08&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=21
Extracing statis for stn_num=023000&month=08&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=22
Extracing statis for stn_num=023000&month=08&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=23
Extracing statis for stn_num=023000&month=08&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=24
Extracing statis for stn_num=023000&month=08&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=25
Extracing statis for stn_num=023000&month=08&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=26
Extracing statis for stn_num=023000&month=08&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=27
Extracing statis for stn_num=023000&month=08&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=28
Extracing statis for stn_num=023000&month=08&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=29
Extracing statis for stn_num=023000&month=08&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=30
Extracing statis for stn_num=023000&month=08&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=31
Extracing statis for stn_num=023000&month=09&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=01
Extracing statis for stn_num=023000&month=09&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=02
Extracing statis for stn_num=023000&month=09&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=03
Extracing statis for stn_num=023000&month=09&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=04
Extracing statis for stn_num=023000&month=09&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=05
Extracing statis for stn_num=023000&month=09&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=06
Extracing statis for stn_num=023000&month=09&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=07
Extracing statis for stn_num=023000&month=09&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=08
Extracing statis for stn_num=023000&month=09&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=09
Extracing statis for stn_num=023000&month=09&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=10
Extracing statis for stn_num=023000&month=09&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=11
Extracing statis for stn_num=023000&month=09&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=12
Extracing statis for stn_num=023000&month=09&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=13
Extracing statis for stn_num=023000&month=09&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=14
Extracing statis for stn_num=023000&month=09&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=15
Extracing statis for stn_num=023000&month=09&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=16
Extracing statis for stn_num=023000&month=09&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=17
Extracing statis for stn_num=023000&month=09&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=18
Extracing statis for stn_num=023000&month=09&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=19
Extracing statis for stn_num=023000&month=09&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=20
Extracing statis for stn_num=023000&month=09&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=21
Extracing statis for stn_num=023000&month=09&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=22
Extracing statis for stn_num=023000&month=09&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=23
Extracing statis for stn_num=023000&month=09&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=24
Extracing statis for stn_num=023000&month=09&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=25
Extracing statis for stn_num=023000&month=09&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=26
Extracing statis for stn_num=023000&month=09&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=27
Extracing statis for stn_num=023000&month=09&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=28
Extracing statis for stn_num=023000&month=09&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=29
Extracing statis for stn_num=023000&month=09&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=30
Extracing statis for stn_num=023000&month=10&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=01
Extracing statis for stn_num=023000&month=10&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=02
Extracing statis for stn_num=023000&month=10&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=03
Extracing statis for stn_num=023000&month=10&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=04
Extracing statis for stn_num=023000&month=10&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=05
Extracing statis for stn_num=023000&month=10&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=06
Extracing statis for stn_num=023000&month=10&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=07
Extracing statis for stn_num=023000&month=10&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=08
Extracing statis for stn_num=023000&month=10&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=09
Extracing statis for stn_num=023000&month=10&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=10
Extracing statis for stn_num=023000&month=10&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=11
Extracing statis for stn_num=023000&month=10&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=12
Extracing statis for stn_num=023000&month=10&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=13
Extracing statis for stn_num=023000&month=10&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=14
Extracing statis for stn_num=023000&month=10&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=15
Extracing statis for stn_num=023000&month=10&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=16
Extracing statis for stn_num=023000&month=10&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=17
Extracing statis for stn_num=023000&month=10&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=18
Extracing statis for stn_num=023000&month=10&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=19
Extracing statis for stn_num=023000&month=10&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=20
Extracing statis for stn_num=023000&month=10&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=21
Extracing statis for stn_num=023000&month=10&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=22
Extracing statis for stn_num=023000&month=10&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=23
Extracing statis for stn_num=023000&month=10&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=24
Extracing statis for stn_num=023000&month=10&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=25
Extracing statis for stn_num=023000&month=10&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=26
Extracing statis for stn_num=023000&month=10&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=27
Extracing statis for stn_num=023000&month=10&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=28
Extracing statis for stn_num=023000&month=10&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=29
Extracing statis for stn_num=023000&month=10&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=30
Extracing statis for stn_num=023000&month=10&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=31
Extracing statis for stn_num=023000&month=11&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=01
Extracing statis for stn_num=023000&month=11&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=02
Extracing statis for stn_num=023000&month=11&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=03
Extracing statis for stn_num=023000&month=11&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=04
Extracing statis for stn_num=023000&month=11&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=05
Extracing statis for stn_num=023000&month=11&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=06
Extracing statis for stn_num=023000&month=11&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=07
Extracing statis for stn_num=023000&month=11&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=08
Extracing statis for stn_num=023000&month=11&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=09
Extracing statis for stn_num=023000&month=11&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=10
Extracing statis for stn_num=023000&month=11&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=11
Extracing statis for stn_num=023000&month=11&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=12
Extracing statis for stn_num=023000&month=11&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=13
Extracing statis for stn_num=023000&month=11&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=14
Extracing statis for stn_num=023000&month=11&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=15
Extracing statis for stn_num=023000&month=11&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=16
Extracing statis for stn_num=023000&month=11&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=17
Extracing statis for stn_num=023000&month=11&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=18
Extracing statis for stn_num=023000&month=11&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=19
Extracing statis for stn_num=023000&month=11&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=20
Extracing statis for stn_num=023000&month=11&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=21
Extracing statis for stn_num=023000&month=11&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=22
Extracing statis for stn_num=023000&month=11&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=23
Extracing statis for stn_num=023000&month=11&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=24
Extracing statis for stn_num=023000&month=11&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=25
Extracing statis for stn_num=023000&month=11&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=26
Extracing statis for stn_num=023000&month=11&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=27
Extracing statis for stn_num=023000&month=11&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=28
Extracing statis for stn_num=023000&month=11&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=29
Extracing statis for stn_num=023000&month=11&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=30
Extracing statis for stn_num=023000&month=12&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=01
Extracing statis for stn_num=023000&month=12&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=02
Extracing statis for stn_num=023000&month=12&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=03
Extracing statis for stn_num=023000&month=12&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=04
Extracing statis for stn_num=023000&month=12&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=05
Extracing statis for stn_num=023000&month=12&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=06
Extracing statis for stn_num=023000&month=12&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=07
Extracing statis for stn_num=023000&month=12&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=08
Extracing statis for stn_num=023000&month=12&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=09
Extracing statis for stn_num=023000&month=12&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=10
Extracing statis for stn_num=023000&month=12&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=11
Extracing statis for stn_num=023000&month=12&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=12
Extracing statis for stn_num=023000&month=12&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=13
Extracing statis for stn_num=023000&month=12&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=14
Extracing statis for stn_num=023000&month=12&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=15
Extracing statis for stn_num=023000&month=12&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=16
Extracing statis for stn_num=023000&month=12&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=17
Extracing statis for stn_num=023000&month=12&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=18
Extracing statis for stn_num=023000&month=12&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=19
Extracing statis for stn_num=023000&month=12&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=20
Extracing statis for stn_num=023000&month=12&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=21
Extracing statis for stn_num=023000&month=12&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=22
Extracing statis for stn_num=023000&month=12&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=23
Extracing statis for stn_num=023000&month=12&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=24
Extracing statis for stn_num=023000&month=12&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=25
Extracing statis for stn_num=023000&month=12&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=26
Extracing statis for stn_num=023000&month=12&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=27
Extracing statis for stn_num=023000&month=12&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=28
Extracing statis for stn_num=023000&month=12&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=29
Extracing statis for stn_num=023000&month=12&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=30
Extracing statis for stn_num=023000&month=12&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=31
Running Spark version 2.4.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Loaded the native-hadoop library
Using JniBasedUnixGroupsMapping for Group resolution
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:NTUserPrincipal: ywksu
Using user: "NTUserPrincipal: ywksu" with name ywksu
User entry: "ywksu"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:ywksu (auth:SIMPLE)
Submitted application: au.com.weather_simulator.utiles.SparkUtiles$
Changing view acls to: ywksu
Changing modify acls to: ywksu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ywksu); groups with view permissions: Set(); users  with modify permissions: Set(ywksu); groups with modify permissions: Set()
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 16
Platform: Windows
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: C:\Users\ywksu\AppData\Local\Temp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 3787980800 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 16
-Dio.netty.allocator.numDirectArenas: 16
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 12792 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
-Dio.netty.machineId: 9c:b6:d0:ff:fe:00:23:81 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 20530
Successfully started service 'sparkDriver' on port 20530.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\ywksu\AppData\Local\Temp\blockmgr-92f143dd-5221-4bad-962b-a2a5700985a5
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1987.5 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @2683477ms
o.s.j.s.ServletContextHandler@4795ded0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dacd14,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dacd14 added {org.apache.spark.ui.JettyUtils$$anon$3-25bc0606@6b57dc3c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dacd14 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-25bc0606,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4ba302e0
o.s.j.s.ServletContextHandler@e98770d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1ae67cad,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1ae67cad added {org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc@40711dd6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1ae67cad added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@13f17eb4
o.s.j.s.ServletContextHandler@1d0d6318{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4bc28c33,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4bc28c33 added {org.apache.spark.ui.JettyUtils$$anon$3-4409e975@aea9f447==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4bc28c33 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4409e975,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5c153b9e
o.s.j.s.ServletContextHandler@2a7686a7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@758a34ce,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@758a34ce added {org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b@5cfab23e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@758a34ce added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@aeab9a1
o.s.j.s.ServletContextHandler@40f70521{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@774698ab,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@774698ab added {org.apache.spark.ui.JettyUtils$$anon$3-55342f40@5032ea5d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@774698ab added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-55342f40,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@a4ca3f6
o.s.j.s.ServletContextHandler@72ea6193{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@31aa3ca5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@31aa3ca5 added {org.apache.spark.ui.JettyUtils$$anon$3-45905bff@f257c791==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@31aa3ca5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-45905bff,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@b6b1987
o.s.j.s.ServletContextHandler@6b44435b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2ccca26f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2ccca26f added {org.apache.spark.ui.JettyUtils$$anon$3-66b7550d@3d590315==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2ccca26f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-66b7550d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3543df7d
o.s.j.s.ServletContextHandler@7c541c15{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3542162a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3542162a added {org.apache.spark.ui.JettyUtils$$anon$3-698122b2@940a3b38==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3542162a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-698122b2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1e7aa82b
o.s.j.s.ServletContextHandler@3b2c0e88{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5bd82fed,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5bd82fed added {org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be@a917fa17==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5bd82fed added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@476b0ae6
o.s.j.s.ServletContextHandler@1c6804cd{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@655f7ea,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@655f7ea added {org.apache.spark.ui.JettyUtils$$anon$3-549949be@25d07df3==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@655f7ea added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-549949be,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6da00fb9
o.s.j.s.ServletContextHandler@a202ccb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@20f12539,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@20f12539 added {org.apache.spark.ui.JettyUtils$$anon$3-75b25825@700d8a80==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@20f12539 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-75b25825,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@18025ced
o.s.j.s.ServletContextHandler@13cf7d52{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3a3e4aff,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3a3e4aff added {org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed@73dff7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3a3e4aff added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3f0846c6
o.s.j.s.ServletContextHandler@77a98a6a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@78fbff54,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@78fbff54 added {org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6@13df7e5a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@78fbff54 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e22550a
o.s.j.s.ServletContextHandler@45e37a7e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62452cc9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@62452cc9 added {org.apache.spark.ui.JettyUtils$$anon$3-6941827a@8d398df0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@62452cc9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6941827a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7516e4e5
o.s.j.s.ServletContextHandler@488eb7f2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5e81e5ac,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5e81e5ac added {org.apache.spark.ui.JettyUtils$$anon$3-4189d70b@1d9d8aef==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5e81e5ac added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4189d70b,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3fa2213
o.s.j.s.ServletContextHandler@3e7634b9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6f0b0a5e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6f0b0a5e added {org.apache.spark.ui.JettyUtils$$anon$3-6035b93b@afb82f6e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6f0b0a5e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6035b93b,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2974f221
o.s.j.s.ServletContextHandler@58fe0499{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@686449f9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@686449f9 added {org.apache.spark.ui.JettyUtils$$anon$3-665df3c6@f31f557b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@686449f9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-665df3c6,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@68b6f0d6
o.s.j.s.ServletContextHandler@4044fb95{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@aa549e5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {org.apache.spark.ui.JettyUtils$$anon$3-36f48b4@c697c30d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@aa549e5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-36f48b4,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3b7ff809
o.s.j.s.ServletContextHandler@1bb564e2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62e6b5c8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@62e6b5c8 added {org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b@a79bb1da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@62e6b5c8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b8233cd
o.s.j.s.ServletContextHandler@4b20ca2b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1cbf6e72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1cbf6e72 added {org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d@27a4a9a1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1cbf6e72 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4da602fc
o.s.j.s.ServletContextHandler@2a8d39c4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@25b2cfcb,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@25b2cfcb added {org.spark_project.jetty.servlet.DefaultServlet-26425897@ea698fd2==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@25b2cfcb added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-26425897,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58c34bb3
o.s.j.s.ServletContextHandler@56a4479a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@62163b39,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@62163b39 added {org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e@5325a0a6==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@62163b39 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4504d271
o.s.j.s.ServletContextHandler@207b8649{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@65b3a85a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@65b3a85a added {org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@65b3a85a added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-328cf0e1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@183e8023
o.s.j.s.ServletContextHandler@45efc20d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3e5499cc,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3e5499cc added {org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47@6730a502==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3e5499cc added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2a3c96e3
o.s.j.s.ServletContextHandler@15cafec7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5b444398,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5b444398 added {org.apache.spark.ui.JettyUtils$$anon$4-cb191ca@8e33d7bd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5b444398 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-cb191ca,POJO}
org.spark_project.jetty.server.Server@422c3c7a added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@422c3c7a added {org.spark_project.jetty.server.handler.ErrorHandler@56bca85b,AUTO}
org.spark_project.jetty.server.Server@422c3c7a added {org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[],MANAGED}
starting org.spark_project.jetty.server.Server@422c3c7a
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
starting org.spark_project.jetty.server.Server@422c3c7a
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @2683570ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@56bca85b
starting org.spark_project.jetty.server.handler.ErrorHandler@56bca85b
STARTED @2683570ms org.spark_project.jetty.server.handler.ErrorHandler@56bca85b
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[]
STARTED @2683570ms org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[]
Started @2683570ms
STARTED @2683570ms org.spark_project.jetty.server.Server@422c3c7a
HttpConnectionFactory@1e63ec0b[HTTP/1.1] added {HttpConfiguration@3b956878{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@1b065145{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@422c3c7a,UNMANAGED}
ServerConnector@1b065145{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@1b065145{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@45cff11c,AUTO}
ServerConnector@1b065145{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@207ea13,POJO}
ServerConnector@1b065145{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@1e63ec0b[HTTP/1.1],AUTO}
ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@1e63ec0b[HTTP/1.1]
ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d,MANAGED}
starting ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4263],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@45cff11c
STARTED @2683589ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@45cff11c
starting HttpConnectionFactory@1e63ec0b[HTTP/1.1]
STARTED @2683589ms HttpConnectionFactory@1e63ec0b[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d added {org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=-1 selected=-1,AUTO}
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d added {org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=-1 selected=-1,AUTO}
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d added {org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=-1 selected=-1,AUTO}
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d added {org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
STARTED @2683596ms org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
starting org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=-1 selected=-1
run org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4101ae38 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4101ae38 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4101ae38 producing
Selector loop waiting on select
queue org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
STARTED @2683597ms org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
starting org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@42657f2d execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@42657f2d produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@42657f2d producing
Selector loop waiting on select
queue org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
STARTED @2683599ms org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@30457a4c execute
starting org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=-1 selected=-1
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@30457a4c produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@30457a4c producing
Selector loop waiting on select
queue org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
STARTED @2683600ms org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
STARTED @2683600ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d
run org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1f03a118 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1f03a118 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1f03a118 producing
Selector loop waiting on select
ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263} added {acceptor-0@50fe837a,POJO}
queue acceptor-0@50fe837a
Started ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
run acceptor-0@50fe837a
STARTED @2683601ms ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
Successfully started service 'SparkUI' on port 4263.
org.spark_project.jetty.server.Server@422c3c7a added {Spark@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70 mime types IncludeExclude@339bf286{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@38be305c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@269f4bad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70 added {o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70
starting o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dacd14
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-25bc0606 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-25bc0606@6b57dc3c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-25bc0606=org.apache.spark.ui.JettyUtils$$anon$3-25bc0606@6b57dc3c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dacd14
STARTED @2683625ms org.spark_project.jetty.servlet.ServletHandler@53dacd14
starting org.apache.spark.ui.JettyUtils$$anon$3-25bc0606@6b57dc3c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683627ms org.apache.spark.ui.JettyUtils$$anon$3-25bc0606@6b57dc3c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5b64c4b7 for org.apache.spark.ui.JettyUtils$$anon$3-25bc0606
Started o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}
STARTED @2683629ms o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}
STARTED @2683629ms org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70
org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727 mime types IncludeExclude@72445aba{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61bcd567,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1c80e49b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727 added {o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727
starting o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1ae67cad
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc@40711dd6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc=org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc@40711dd6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1ae67cad
STARTED @2683630ms org.spark_project.jetty.servlet.ServletHandler@1ae67cad
starting org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc@40711dd6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683630ms org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc@40711dd6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@458342d3 for org.apache.spark.ui.JettyUtils$$anon$3-2f6e28bc
Started o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @2683631ms o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @2683631ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727
org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153 mime types IncludeExclude@1252b961{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@9ed238c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@56276db8}
org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153 added {o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153
starting o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4bc28c33
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4409e975 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4409e975@aea9f447==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4409e975=org.apache.spark.ui.JettyUtils$$anon$3-4409e975@aea9f447==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4bc28c33
STARTED @2683631ms org.spark_project.jetty.servlet.ServletHandler@4bc28c33
starting org.apache.spark.ui.JettyUtils$$anon$3-4409e975@aea9f447==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683631ms org.apache.spark.ui.JettyUtils$$anon$3-4409e975@aea9f447==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51e8e6e6 for org.apache.spark.ui.JettyUtils$$anon$3-4409e975
Started o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}
STARTED @2683632ms o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}
STARTED @2683632ms org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153
org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a mime types IncludeExclude@5b408dc3{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d098f9b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2dbf4cbd}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a added {o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a
starting o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@758a34ce
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b@5cfab23e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b=org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b@5cfab23e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@758a34ce
STARTED @2683633ms org.spark_project.jetty.servlet.ServletHandler@758a34ce
starting org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b@5cfab23e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683633ms org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b@5cfab23e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@20b5f2ac for org.apache.spark.ui.JettyUtils$$anon$3-7ec3394b
Started o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @2683633ms o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @2683633ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a
org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec mime types IncludeExclude@7e3060d8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@293d0107,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2692b61e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec added {o.s.j.s.ServletContextHandler@40f70521{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec
starting o.s.j.s.ServletContextHandler@40f70521{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@40f70521{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@774698ab
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-55342f40 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-55342f40@5032ea5d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-55342f40=org.apache.spark.ui.JettyUtils$$anon$3-55342f40@5032ea5d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@774698ab
STARTED @2683635ms org.spark_project.jetty.servlet.ServletHandler@774698ab
starting org.apache.spark.ui.JettyUtils$$anon$3-55342f40@5032ea5d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683635ms org.apache.spark.ui.JettyUtils$$anon$3-55342f40@5032ea5d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7b64240d for org.apache.spark.ui.JettyUtils$$anon$3-55342f40
Started o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}
STARTED @2683635ms o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}
STARTED @2683635ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec
org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19 mime types IncludeExclude@47dbb1e2{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@74cadd41,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2e54db99}
org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19 added {o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19
starting o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@31aa3ca5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-45905bff from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-45905bff@f257c791==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-45905bff=org.apache.spark.ui.JettyUtils$$anon$3-45905bff@f257c791==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@31aa3ca5
STARTED @2683636ms org.spark_project.jetty.servlet.ServletHandler@31aa3ca5
starting org.apache.spark.ui.JettyUtils$$anon$3-45905bff@f257c791==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683636ms org.apache.spark.ui.JettyUtils$$anon$3-45905bff@f257c791==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@55e8ec2f for org.apache.spark.ui.JettyUtils$$anon$3-45905bff
Started o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}
STARTED @2683636ms o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}
STARTED @2683636ms org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19
org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1 mime types IncludeExclude@6d24ffa1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@65a4798f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@773f7880}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1 added {o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1
starting o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2ccca26f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-66b7550d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-66b7550d@3d590315==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-66b7550d=org.apache.spark.ui.JettyUtils$$anon$3-66b7550d@3d590315==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2ccca26f
STARTED @2683638ms org.spark_project.jetty.servlet.ServletHandler@2ccca26f
starting org.apache.spark.ui.JettyUtils$$anon$3-66b7550d@3d590315==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683638ms org.apache.spark.ui.JettyUtils$$anon$3-66b7550d@3d590315==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@878452d for org.apache.spark.ui.JettyUtils$$anon$3-66b7550d
Started o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}
STARTED @2683638ms o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}
STARTED @2683638ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1
org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7 mime types IncludeExclude@42a9e5d1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5b080f3a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@773cbf4f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7 added {o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7
starting o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3542162a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-698122b2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-698122b2@940a3b38==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-698122b2=org.apache.spark.ui.JettyUtils$$anon$3-698122b2@940a3b38==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3542162a
STARTED @2683640ms org.spark_project.jetty.servlet.ServletHandler@3542162a
starting org.apache.spark.ui.JettyUtils$$anon$3-698122b2@940a3b38==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683640ms org.apache.spark.ui.JettyUtils$$anon$3-698122b2@940a3b38==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6b54655f for org.apache.spark.ui.JettyUtils$$anon$3-698122b2
Started o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @2683640ms o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @2683640ms org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7
org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289 mime types IncludeExclude@7d3430a7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6f603e89,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2756c0a7}
org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289 added {o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289
starting o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5bd82fed
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be@a917fa17==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be=org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be@a917fa17==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5bd82fed
STARTED @2683642ms org.spark_project.jetty.servlet.ServletHandler@5bd82fed
starting org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be@a917fa17==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683642ms org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be@a917fa17==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@350ec41e for org.apache.spark.ui.JettyUtils$$anon$3-c1bd0be
Started o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}
STARTED @2683642ms o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}
STARTED @2683642ms org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289
org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10 mime types IncludeExclude@71984c3{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165b2f7f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5536379e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10 added {o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10
starting o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@655f7ea
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-549949be from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-549949be@25d07df3==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-549949be=org.apache.spark.ui.JettyUtils$$anon$3-549949be@25d07df3==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@655f7ea
STARTED @2683643ms org.spark_project.jetty.servlet.ServletHandler@655f7ea
starting org.apache.spark.ui.JettyUtils$$anon$3-549949be@25d07df3==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683643ms org.apache.spark.ui.JettyUtils$$anon$3-549949be@25d07df3==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@277f7dd3 for org.apache.spark.ui.JettyUtils$$anon$3-549949be
Started o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @2683643ms o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @2683643ms org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10
org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63 mime types IncludeExclude@2364305a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@470a696f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1bc715b8}
org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63 added {o.s.j.s.ServletContextHandler@a202ccb{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63
starting o.s.j.s.ServletContextHandler@a202ccb{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@a202ccb{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@20f12539
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-75b25825 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-75b25825@700d8a80==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-75b25825=org.apache.spark.ui.JettyUtils$$anon$3-75b25825@700d8a80==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@20f12539
STARTED @2683645ms org.spark_project.jetty.servlet.ServletHandler@20f12539
starting org.apache.spark.ui.JettyUtils$$anon$3-75b25825@700d8a80==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683645ms org.apache.spark.ui.JettyUtils$$anon$3-75b25825@700d8a80==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@292d1c71 for org.apache.spark.ui.JettyUtils$$anon$3-75b25825
Started o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}
STARTED @2683645ms o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}
STARTED @2683645ms org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63
org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee mime types IncludeExclude@3f1c5af9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1c55f277,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ddabb18}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee added {o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee
starting o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3a3e4aff
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed@73dff7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed=org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed@73dff7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3a3e4aff
STARTED @2683646ms org.spark_project.jetty.servlet.ServletHandler@3a3e4aff
starting org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed@73dff7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683646ms org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed@73dff7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3e8f7922 for org.apache.spark.ui.JettyUtils$$anon$3-5d2a4eed
Started o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}
STARTED @2683646ms o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}
STARTED @2683646ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee
org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798 mime types IncludeExclude@50eca7c6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@58e6d4b8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1de5f0ef}
org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798 added {o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798
starting o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@78fbff54
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6@13df7e5a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6=org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6@13df7e5a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@78fbff54
STARTED @2683648ms org.spark_project.jetty.servlet.ServletHandler@78fbff54
starting org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6@13df7e5a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683648ms org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6@13df7e5a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@376a312c for org.apache.spark.ui.JettyUtils$$anon$3-3e10dc6
Started o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @2683648ms o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @2683648ms org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798
org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290 mime types IncludeExclude@6ca0256d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ef0d29e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@38f57b3d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290 added {o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290
starting o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@62452cc9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6941827a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6941827a@8d398df0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6941827a=org.apache.spark.ui.JettyUtils$$anon$3-6941827a@8d398df0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@62452cc9
STARTED @2683649ms org.spark_project.jetty.servlet.ServletHandler@62452cc9
starting org.apache.spark.ui.JettyUtils$$anon$3-6941827a@8d398df0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683649ms org.apache.spark.ui.JettyUtils$$anon$3-6941827a@8d398df0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51850751 for org.apache.spark.ui.JettyUtils$$anon$3-6941827a
Started o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @2683649ms o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @2683649ms org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290
org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41 mime types IncludeExclude@64df9a61{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@77602954,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e260766}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41 added {o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41
starting o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5e81e5ac
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4189d70b from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4189d70b@1d9d8aef==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4189d70b=org.apache.spark.ui.JettyUtils$$anon$3-4189d70b@1d9d8aef==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5e81e5ac
STARTED @2683651ms org.spark_project.jetty.servlet.ServletHandler@5e81e5ac
starting org.apache.spark.ui.JettyUtils$$anon$3-4189d70b@1d9d8aef==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683651ms org.apache.spark.ui.JettyUtils$$anon$3-4189d70b@1d9d8aef==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c3dec30 for org.apache.spark.ui.JettyUtils$$anon$3-4189d70b
Started o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}
STARTED @2683651ms o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}
STARTED @2683651ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41
org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744 mime types IncludeExclude@4275c20c{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7c56e013,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3fc9dfc5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744 added {o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744
starting o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6f0b0a5e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6035b93b from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6035b93b@afb82f6e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6035b93b=org.apache.spark.ui.JettyUtils$$anon$3-6035b93b@afb82f6e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6f0b0a5e
STARTED @2683653ms org.spark_project.jetty.servlet.ServletHandler@6f0b0a5e
starting org.apache.spark.ui.JettyUtils$$anon$3-6035b93b@afb82f6e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683653ms org.apache.spark.ui.JettyUtils$$anon$3-6035b93b@afb82f6e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@40258c2f for org.apache.spark.ui.JettyUtils$$anon$3-6035b93b
Started o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}
STARTED @2683653ms o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}
STARTED @2683653ms org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744
org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385 mime types IncludeExclude@6731787b{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@16f7b4af,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7adf16aa}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385 added {o.s.j.s.ServletContextHandler@58fe0499{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385
starting o.s.j.s.ServletContextHandler@58fe0499{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@58fe0499{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@686449f9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-665df3c6 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-665df3c6@f31f557b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-665df3c6=org.apache.spark.ui.JettyUtils$$anon$3-665df3c6@f31f557b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@686449f9
STARTED @2683654ms org.spark_project.jetty.servlet.ServletHandler@686449f9
starting org.apache.spark.ui.JettyUtils$$anon$3-665df3c6@f31f557b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683654ms org.apache.spark.ui.JettyUtils$$anon$3-665df3c6@f31f557b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@34a1d21f for org.apache.spark.ui.JettyUtils$$anon$3-665df3c6
Started o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}
STARTED @2683655ms o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}
STARTED @2683655ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385
org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650 mime types IncludeExclude@73c60324{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@71ae31b0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4ba534b0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650 added {o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650
starting o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-36f48b4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-36f48b4@c697c30d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-36f48b4=org.apache.spark.ui.JettyUtils$$anon$3-36f48b4@c697c30d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@aa549e5
STARTED @2683656ms org.spark_project.jetty.servlet.ServletHandler@aa549e5
starting org.apache.spark.ui.JettyUtils$$anon$3-36f48b4@c697c30d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683656ms org.apache.spark.ui.JettyUtils$$anon$3-36f48b4@c697c30d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6f0ca692 for org.apache.spark.ui.JettyUtils$$anon$3-36f48b4
Started o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}
STARTED @2683656ms o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}
STARTED @2683656ms org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650
org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774 mime types IncludeExclude@2cb3d0f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4e517165,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@44e3760b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774 added {o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774
starting o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@62e6b5c8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b@a79bb1da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b=org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b@a79bb1da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@62e6b5c8
STARTED @2683658ms org.spark_project.jetty.servlet.ServletHandler@62e6b5c8
starting org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b@a79bb1da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683658ms org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b@a79bb1da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6a66a204 for org.apache.spark.ui.JettyUtils$$anon$3-3f792b9b
Started o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @2683658ms o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @2683658ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774
org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7 mime types IncludeExclude@1d7f7be7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@42f3156d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1ddae9b5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7 added {o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7
starting o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1cbf6e72
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d@27a4a9a1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d=org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d@27a4a9a1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1cbf6e72
STARTED @2683659ms org.spark_project.jetty.servlet.ServletHandler@1cbf6e72
starting org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d@27a4a9a1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2683660ms org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d@27a4a9a1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@427b5f92 for org.apache.spark.ui.JettyUtils$$anon$3-6aecbb8d
Started o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @2683660ms o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @2683660ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7
org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479 mime types IncludeExclude@7e3f95fe{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@34625ccd,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2c7d121c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479 added {o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479
starting o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@25b2cfcb
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-26425897 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-26425897@ea698fd2==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-26425897=org.spark_project.jetty.servlet.DefaultServlet-26425897@ea698fd2==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@25b2cfcb
STARTED @2683661ms org.spark_project.jetty.servlet.ServletHandler@25b2cfcb
starting org.spark_project.jetty.servlet.DefaultServlet-26425897@ea698fd2==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @2683661ms org.spark_project.jetty.servlet.DefaultServlet-26425897@ea698fd2==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@65aa6596 for org.spark_project.jetty.servlet.DefaultServlet-26425897
resource base = jar:file:/C:/Users/ywksu/.ivy2/cache/org.apache.spark/spark-core_2.12/jars/spark-core_2.12-2.4.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}
STARTED @2683668ms o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}
STARTED @2683668ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479
org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767 mime types IncludeExclude@768ccdc5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4c6daf0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@10650953}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767 added {o.s.j.s.ServletContextHandler@56a4479a{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767
starting o.s.j.s.ServletContextHandler@56a4479a{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@56a4479a{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@62163b39
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e@5325a0a6==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e=org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e@5325a0a6==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@62163b39
STARTED @2683670ms org.spark_project.jetty.servlet.ServletHandler@62163b39
starting org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e@5325a0a6==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @2683670ms org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e@5325a0a6==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@659eef7 for org.apache.spark.ui.JettyUtils$$anon$4-20a8a64e
Started o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}
STARTED @2683670ms o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}
STARTED @2683670ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767
org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c mime types IncludeExclude@2488b073{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1c9f0a20,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@55787112}
org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c added {o.s.j.s.ServletContextHandler@207b8649{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c
starting o.s.j.s.ServletContextHandler@207b8649{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@207b8649{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@65b3a85a
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-328cf0e1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-328cf0e1=org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@65b3a85a
org.spark_project.jetty.servlet.ServletHandler@65b3a85a added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4@a10ddf6f==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@65b3a85a added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-328cf0e1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4@a10ddf6f==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-328cf0e1=org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4@a10ddf6f==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@65b3a85a
STARTED @2683677ms org.spark_project.jetty.servlet.ServletHandler@65b3a85a
starting org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @2683677ms org.glassfish.jersey.servlet.ServletContainer-328cf0e1@44ffa7ce==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4@a10ddf6f==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @2683677ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1992eaf4@a10ddf6f==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}
STARTED @2683677ms o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}
STARTED @2683677ms org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c
org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835 mime types IncludeExclude@3276732{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f28bd56,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31e3250d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835 added {o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835
starting o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3e5499cc
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47@6730a502==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47=org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47@6730a502==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3e5499cc
STARTED @2683679ms org.spark_project.jetty.servlet.ServletHandler@3e5499cc
starting org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47@6730a502==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @2683679ms org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47@6730a502==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@19fe4644 for org.apache.spark.ui.JettyUtils$$anon$4-67ab1c47
Started o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @2683679ms o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @2683679ms org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835
org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe mime types IncludeExclude@5be067de{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7383eae2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@18245eb0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe added {o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe
starting o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5b444398
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-cb191ca from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-cb191ca@8e33d7bd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-cb191ca=org.apache.spark.ui.JettyUtils$$anon$4-cb191ca@8e33d7bd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5b444398
STARTED @2683680ms org.spark_project.jetty.servlet.ServletHandler@5b444398
starting org.apache.spark.ui.JettyUtils$$anon$4-cb191ca@8e33d7bd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @2683681ms org.apache.spark.ui.JettyUtils$$anon$4-cb191ca@8e33d7bd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@7c7d3c46 for org.apache.spark.ui.JettyUtils$$anon$4-cb191ca
Started o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @2683681ms o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @2683681ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe
Bound SparkUI to 0.0.0.0, and started at http://192.168.1.13:4263
Starting executor ID driver on host localhost
Shuffle server started on port: 20571
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 20571.
Server created on 192.168.1.13:20571
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, 192.168.1.13, 20571, None)
Got a request for 192.168.1.13
Registering block manager 192.168.1.13:20571 with 1987.5 MB RAM, BlockManagerId(driver, 192.168.1.13, 20571, None)
Registered BlockManager BlockManagerId(driver, 192.168.1.13, 20571, None)
Initialized BlockManager: BlockManagerId(driver, 192.168.1.13, 20571, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@282308c3
o.s.j.s.ServletContextHandler@5dda14d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1db0ec27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1db0ec27 added {org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a@43c8ab46==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1db0ec27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1db0ec27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a@43c8ab46==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a=org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a@43c8ab46==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1db0ec27
STARTED @2684089ms org.spark_project.jetty.servlet.ServletHandler@1db0ec27
starting org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a@43c8ab46==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2684089ms org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a@43c8ab46==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5987e932 for org.apache.spark.ui.JettyUtils$$anon$3-3d9fc57a
Started o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}
STARTED @2684089ms o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/p1/weather-simulator/spark-warehouse/').
Warehouse path is 'file:/D:/p1/weather-simulator/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4a325eb9
o.s.j.s.ServletContextHandler@3dedb4a6{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@57f64f5e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@57f64f5e added {org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb@1ad40f8a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@57f64f5e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@194152cf
o.s.j.s.ServletContextHandler@49d98dc5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2c30b71f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2c30b71f added {org.apache.spark.ui.JettyUtils$$anon$3-1d81e101@6f6773e5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2c30b71f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1d81e101,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@57f64f5e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb@1ad40f8a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb=org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb@1ad40f8a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@57f64f5e
STARTED @2684203ms org.spark_project.jetty.servlet.ServletHandler@57f64f5e
starting org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb@1ad40f8a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2684203ms org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb@1ad40f8a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ec50f54 for org.apache.spark.ui.JettyUtils$$anon$3-415e0bcb
Started o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}
STARTED @2684203ms o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2c30b71f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1d81e101 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1d81e101@6f6773e5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1d81e101=org.apache.spark.ui.JettyUtils$$anon$3-1d81e101@6f6773e5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2c30b71f
STARTED @2684204ms org.spark_project.jetty.servlet.ServletHandler@2c30b71f
starting org.apache.spark.ui.JettyUtils$$anon$3-1d81e101@6f6773e5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2684204ms org.apache.spark.ui.JettyUtils$$anon$3-1d81e101@6f6773e5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@bf71cec for org.apache.spark.ui.JettyUtils$$anon$3-1d81e101
Started o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}
STARTED @2684204ms o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@30cdae70
o.s.j.s.ServletContextHandler@1654a892{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2577d6c8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2577d6c8 added {org.apache.spark.ui.JettyUtils$$anon$3-3163987e@b1ea9874==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2577d6c8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3163987e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6c000e0c
o.s.j.s.ServletContextHandler@5f233b26{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@44f9779c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@44f9779c added {org.apache.spark.ui.JettyUtils$$anon$3-6974a715@92951366==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@44f9779c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6974a715,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2577d6c8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3163987e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3163987e@b1ea9874==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3163987e=org.apache.spark.ui.JettyUtils$$anon$3-3163987e@b1ea9874==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2577d6c8
STARTED @2684206ms org.spark_project.jetty.servlet.ServletHandler@2577d6c8
starting org.apache.spark.ui.JettyUtils$$anon$3-3163987e@b1ea9874==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2684206ms org.apache.spark.ui.JettyUtils$$anon$3-3163987e@b1ea9874==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5e8a459 for org.apache.spark.ui.JettyUtils$$anon$3-3163987e
Started o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @2684206ms o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@44f9779c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6974a715 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6974a715@92951366==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6974a715=org.apache.spark.ui.JettyUtils$$anon$3-6974a715@92951366==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@44f9779c
STARTED @2684207ms org.spark_project.jetty.servlet.ServletHandler@44f9779c
starting org.apache.spark.ui.JettyUtils$$anon$3-6974a715@92951366==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2684207ms org.apache.spark.ui.JettyUtils$$anon$3-6974a715@92951366==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@43d455c9 for org.apache.spark.ui.JettyUtils$$anon$3-6974a715
Started o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @2684207ms o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@210f0cc1
o.s.j.s.ServletContextHandler@19542407{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6f95cd51,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6f95cd51 added {org.spark_project.jetty.servlet.DefaultServlet-c7a977f@8eec18eb==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6f95cd51 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-c7a977f,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@19542407{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@19542407{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767,[o.s.j.s.ServletContextHandler@56a4479a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798,[o.s.j.s.ServletContextHandler@77a98a6a{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63,[o.s.j.s.ServletContextHandler@a202ccb{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290,[o.s.j.s.ServletContextHandler@45e37a7e{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c,[o.s.j.s.ServletContextHandler@207b8649{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10,[o.s.j.s.ServletContextHandler@1c6804cd{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289,[o.s.j.s.ServletContextHandler@3b2c0e88{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727,[o.s.j.s.ServletContextHandler@e98770d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479,[o.s.j.s.ServletContextHandler@2a8d39c4{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650,[o.s.j.s.ServletContextHandler@4044fb95{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7,[o.s.j.s.ServletContextHandler@7c541c15{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7,[o.s.j.s.ServletContextHandler@4b20ca2b{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744,[o.s.j.s.ServletContextHandler@3e7634b9{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a,[o.s.j.s.ServletContextHandler@2a7686a7{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70,[o.s.j.s.ServletContextHandler@4795ded0{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19,[o.s.j.s.ServletContextHandler@72ea6193{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1,[o.s.j.s.ServletContextHandler@6b44435b{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee,[o.s.j.s.ServletContextHandler@13cf7d52{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@19542407{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@19542407{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe,[o.s.j.s.ServletContextHandler@15cafec7{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153,[o.s.j.s.ServletContextHandler@1d0d6318{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41,[o.s.j.s.ServletContextHandler@488eb7f2{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec,[o.s.j.s.ServletContextHandler@40f70521{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385,[o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835,[o.s.j.s.ServletContextHandler@45efc20d{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774,[o.s.j.s.ServletContextHandler@1bb564e2{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@19542407{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@19542407{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6f95cd51
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-c7a977f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-c7a977f@8eec18eb==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-c7a977f=org.spark_project.jetty.servlet.DefaultServlet-c7a977f@8eec18eb==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6f95cd51
STARTED @2684209ms org.spark_project.jetty.servlet.ServletHandler@6f95cd51
starting org.spark_project.jetty.servlet.DefaultServlet-c7a977f@8eec18eb==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @2684209ms org.spark_project.jetty.servlet.DefaultServlet-c7a977f@8eec18eb==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@55caeb35 for org.spark_project.jetty.servlet.DefaultServlet-c7a977f
resource base = jar:file:/C:/Users/ywksu/.ivy2/cache/org.apache.spark/spark-sql_2.12/jars/spark-sql_2.12-2.4.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@19542407{/static/sql,null,AVAILABLE,@Spark}
STARTED @2684209ms o.s.j.s.ServletContextHandler@19542407{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Reading files from src/main/resources/bomstatis/
sampler.classes = ; loaded no samplers
span.receiver.classes = ; loaded no span receivers
Resolving 'value to value#0

=== Result of Batch Resolution ===
!'Project [unresolvedalias('value, None)]   Project [value#0]
 +- Relation[value#0] text                  +- Relation[value#0] text
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#4: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#4: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          
Resolving 'value to value#0

=== Result of Batch Resolution ===
!'Filter (length(trim('value, None)) > 0)   Filter (length(trim(value#0, None)) > 0)
 +- Project [value#0]                       +- Project [value#0]
    +- Relation[value#0] text                  +- Relation[value#0] text
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#5: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#5: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#6: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#6: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 1                                    GlobalLimit 1
 +- LocalLimit 1                                  +- LocalLimit 1
    +- Filter (length(trim(value#0, None)) > 0)      +- Filter (length(trim(value#0, None)) > 0)
!      +- Project [value#0]                             +- Relation[value#0] text
!         +- Relation[value#0] text               
          
Pruning directories with: 
Post-Scan Filters: (length(trim(value#0, None)) > 0)
Output Data Schema: struct<value: string>
Pushed Filters: 
code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

Code generated in 216.533248 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

Code generated in 20.934313 ms
Block broadcast_0 stored as values in memory (estimated size 243.0 KB, free 1987.3 MB)
Put block broadcast_0 locally took  62 ms
Putting block broadcast_0 without replication took  62 ms
Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.2 MB)
Added broadcast_0_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  0 ms
Putting block broadcast_0_piece0 without replication took  0 ms
Created broadcast 0 from csv at SparkUtiles.scala:21
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$1
 +++ Lambda closure ($anonfun$executeTake$1) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$2
 +++ Lambda closure ($anonfun$executeTake$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: csv at SparkUtiles.scala:21
Got job 0 (csv at SparkUtiles.scala:21) with 1 output partitions
Final stage: ResultStage 0 (csv at SparkUtiles.scala:21)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 0)
missing: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at SparkUtiles.scala:21), which has no missing parents
submitMissingTasks(ResultStage 0)
Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 1987.2 MB)
Put block broadcast_1 locally took  0 ms
Putting block broadcast_1 without replication took  0 ms
Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 1987.2 MB)
Added broadcast_1_piece0 in memory on 192.168.1.13:20571 (size: 5.0 KB, free: 1987.5 MB)
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Put block broadcast_1_piece0 locally took  15 ms
Putting block broadcast_1_piece0 without replication took  15 ms
Created broadcast 1 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at SparkUtiles.scala:21) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
parentName: , name: TaskSet_0.0, runningTasks: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 0.0 (TID 0)
Getting local block broadcast_1
Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

Code generated in 10.539452 ms
Getting local block broadcast_0
Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 0.0 in stage 0.0 (TID 0). 1316 bytes result sent to driver
parentName: , name: TaskSet_0.0, runningTasks: 0
Finished task 0.0 in stage 0.0 (TID 0) in 344 ms on localhost (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (csv at SparkUtiles.scala:21) finished in 0.469 s
After removal of stage 0, remaining stages = 0
Job 0 finished: csv at SparkUtiles.scala:21, took 0.507203 s

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#8: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#8: java.lang.String
 +- Project [value#0]                                                                                                                                                     +- Project [value#0]
    +- Relation[value#0] text                                                                                                                                                +- Relation[value#0] text
          

=== Result of Batch Operator Optimization before Inferring Filters ===
!DeserializeToObject cast(value#0 as string).toString, obj#8: java.lang.String   DeserializeToObject value#0.toString, obj#8: java.lang.String
!+- Project [value#0]                                                            +- Relation[value#0] text
!   +- Relation[value#0] text                                                    
          
Pruning directories with: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Pushed Filters: 

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }

Code generated in 6.373528 ms
Block broadcast_2 stored as values in memory (estimated size 243.0 KB, free 1987.0 MB)
Put block broadcast_2 locally took  0 ms
Putting block broadcast_2 without replication took  0 ms
Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.0 MB)
Added broadcast_2_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Put block broadcast_2_piece0 locally took  0 ms
Putting block broadcast_2_piece0 without replication took  0 ms
Created broadcast 2 from csv at SparkUtiles.scala:21
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$rdd$1
 +++ Lambda closure ($anonfun$rdd$1) is now cleaned +++
Cleaning lambda: $anonfun$inferFromDataset$2
 +++ Lambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
Parsing command: bomstatis
Parsing command: 
WITH outtab AS
(
       SELECT Get_station(location)            AS station,
              Get_timestamp(monthday,location) AS whole_time ,
              Get_temp(mintemp,maxtemp)        AS temprature,
              Get_pressure()                   AS pressure,
              Get_humidity()                   AS humidy
       FROM   bomstatis)
SELECT Split(station, "[|]")[0]                                                         as location,
       split(station, "[|]")[1]                                                         AS position,
       whole_time                                                                       AS local_time,
       get_condition (cast(replace(temprature,'+','') AS DOUBLE), cast(humidy AS int) ) AS conditions,
       temprature                                                                       AS temperature,
       pressure                                                                         AS pressure,
       humidy                                                                           AS humidity
FROM   outtab
        
Got cleaning task CleanAccum(4)
Cleaning accumulator 4
Cleaned accumulator 4
Got cleaning task CleanAccum(13)
Cleaning accumulator 13
Cleaned accumulator 13
Got cleaning task CleanAccum(29)
Cleaning accumulator 29
Cleaned accumulator 29
Got cleaning task CleanAccum(33)
Cleaning accumulator 33
Cleaned accumulator 33
Got cleaning task CleanAccum(24)
Cleaning accumulator 24
Cleaned accumulator 24
Got cleaning task CleanAccum(6)
Cleaning accumulator 6
Cleaned accumulator 6
Got cleaning task CleanAccum(12)
Cleaning accumulator 12
Cleaned accumulator 12
Got cleaning task CleanAccum(21)
Cleaning accumulator 21
Cleaned accumulator 21
Got cleaning task CleanAccum(1)
Cleaning accumulator 1
Cleaned accumulator 1
Got cleaning task CleanBroadcast(1)
Cleaning broadcast 1
Unpersisting TorrentBroadcast 1
Resolving 'location to location#10
Resolving 'monthday to monthday#11
Resolving 'location to location#10
Resolving 'mintemp to mintemp#13
Resolving 'maxtemp to maxtemp#12
removing broadcast 1
Removing broadcast 1
Removing block broadcast_1
Block broadcast_1 of size 10464 dropped from memory (free 2083501056)
Removing block broadcast_1_piece0
Block broadcast_1_piece0 of size 5148 dropped from memory (free 2083506204)
Removed broadcast_1_piece0 on 192.168.1.13:20571 in memory (size: 5.0 KB, free: 1987.5 MB)
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Done removing broadcast 1, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 1
Got cleaning task CleanAccum(28)
Cleaning accumulator 28
Cleaned accumulator 28
Got cleaning task CleanAccum(14)
Cleaning accumulator 14
Cleaned accumulator 14
Got cleaning task CleanAccum(20)
Cleaning accumulator 20
Cleaned accumulator 20
Got cleaning task CleanAccum(27)
Cleaning accumulator 27
Cleaned accumulator 27
Got cleaning task CleanAccum(16)
Cleaning accumulator 16
Cleaned accumulator 16
Got cleaning task CleanAccum(31)
Cleaning accumulator 31
Cleaned accumulator 31
Got cleaning task CleanAccum(19)
Cleaning accumulator 19
Cleaned accumulator 19
Got cleaning task CleanAccum(30)
Cleaning accumulator 30
Cleaned accumulator 30
Got cleaning task CleanAccum(11)
Cleaning accumulator 11
Cleaned accumulator 11
Got cleaning task CleanAccum(34)
Cleaning accumulator 34
Cleaned accumulator 34
Got cleaning task CleanAccum(35)
Cleaning accumulator 35
Cleaned accumulator 35
Got cleaning task CleanAccum(23)
Cleaning accumulator 23
Cleaned accumulator 23
Got cleaning task CleanAccum(32)
Cleaning accumulator 32
Cleaned accumulator 32
Got cleaning task CleanAccum(9)
Cleaning accumulator 9
Cleaned accumulator 9
Got cleaning task CleanAccum(3)
Cleaning accumulator 3
Cleaned accumulator 3
Got cleaning task CleanBroadcast(2)
Cleaning broadcast 2
Unpersisting TorrentBroadcast 2
removing broadcast 2
Removing broadcast 2
Removing block broadcast_2
Block broadcast_2 of size 248816 dropped from memory (free 2083755020)
Removing block broadcast_2_piece0
Block broadcast_2_piece0 of size 20482 dropped from memory (free 2083775502)
Removed broadcast_2_piece0 on 192.168.1.13:20571 in memory (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Done removing broadcast 2, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 2
Got cleaning task CleanAccum(22)
Cleaning accumulator 22
Cleaned accumulator 22
Got cleaning task CleanAccum(25)
Cleaning accumulator 25
Cleaned accumulator 25
Got cleaning task CleanAccum(5)
Cleaning accumulator 5
Cleaned accumulator 5
Got cleaning task CleanBroadcast(0)
Cleaning broadcast 0
Unpersisting TorrentBroadcast 0
removing broadcast 0
Removing broadcast 0
Removing block broadcast_0_piece0
Block broadcast_0_piece0 of size 20482 dropped from memory (free 2083795984)
Removed broadcast_0_piece0 on 192.168.1.13:20571 in memory (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Removing block broadcast_0
Block broadcast_0 of size 248816 dropped from memory (free 2084044800)
Done removing broadcast 0, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 0
Got cleaning task CleanAccum(17)
Cleaning accumulator 17
Cleaned accumulator 17
Got cleaning task CleanAccum(7)
Cleaning accumulator 7
Cleaned accumulator 7
Got cleaning task CleanAccum(8)
Cleaning accumulator 8
Cleaned accumulator 8
Got cleaning task CleanAccum(26)
Cleaning accumulator 26
Cleaned accumulator 26
Got cleaning task CleanAccum(18)
Cleaning accumulator 18
Cleaned accumulator 18
Got cleaning task CleanAccum(2)
Cleaning accumulator 2
Cleaned accumulator 2
Got cleaning task CleanAccum(15)
Cleaning accumulator 15
Cleaned accumulator 15
Got cleaning task CleanAccum(0)
Cleaning accumulator 0
Cleaned accumulator 0
Got cleaning task CleanAccum(10)
Cleaning accumulator 10
Cleaned accumulator 10

=== Result of Batch Resolution ===
!'SubqueryAlias `outtab`                                                                                                                                                                                                    SubqueryAlias `outtab`
!+- 'Project ['Get_station('location) AS station#27, 'Get_timestamp('monthday, 'location) AS whole_time#28, 'Get_temp('mintemp, 'maxtemp) AS temprature#29, 'Get_pressure() AS pressure#30, 'Get_humidity() AS humidy#31]   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!   +- 'UnresolvedRelation `bomstatis`                                                                                                                                                                                         +- SubqueryAlias `bomstatis`
!                                                                                                                                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch UDF ===
 SubqueryAlias `outtab`                                                                                                                                                                                                SubqueryAlias `outtab`
!+- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
    +- SubqueryAlias `bomstatis`                                                                                                                                                                                          +- SubqueryAlias `bomstatis`
       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                          SubqueryAlias `outtab`
 +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
    +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                    +- SubqueryAlias `bomstatis`
       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                      +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Substitution ===
!CTE [outtab]                                                                                                                                                                                                                                                                                                       'Project ['Split('station, [|])[0] AS location#20, 'split('station, [|])[1] AS position#21, 'whole_time AS local_time#22, 'get_condition(cast('replace('temprature, +, ) as double), cast('humidy as int)) AS conditions#23, 'temprature AS temperature#24, 'pressure AS pressure#25, 'humidy AS humidity#26]
!:  +- 'SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                      +- SubqueryAlias `outtab`
!:     +- 'Project ['Get_station('location) AS station#27, 'Get_timestamp('monthday, 'location) AS whole_time#28, 'Get_temp('mintemp, 'maxtemp) AS temprature#29, 'Get_pressure() AS pressure#30, 'Get_humidity() AS humidy#31]                                                                                        +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!:        +- 'UnresolvedRelation `bomstatis`                                                                                                                                                                                                                                                                              +- SubqueryAlias `bomstatis`
!+- 'Project ['Split('station, [|])[0] AS location#20, 'split('station, [|])[1] AS position#21, 'whole_time AS local_time#22, 'get_condition(cast('replace('temprature, +, ) as double), cast('humidy as int)) AS conditions#23, 'temprature AS temperature#24, 'pressure AS pressure#25, 'humidy AS humidity#26]            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!   +- 'UnresolvedRelation `outtab`                                                                                                                                                                                                                                                                                 
          
Resolving 'station to station#27
Resolving 'station to station#27
Resolving 'whole_time to whole_time#28
Resolving 'temprature to temprature#29
Resolving 'humidy to humidy#31
Resolving 'temprature to temprature#29
Resolving 'pressure to pressure#30
Resolving 'humidy to humidy#31

=== Result of Batch Resolution ===
!'Project ['Split('station, [|])[0] AS location#20, 'split('station, [|])[1] AS position#21, 'whole_time AS local_time#22, 'get_condition(cast('replace('temprature, +, ) as double), cast('humidy as int)) AS conditions#23, 'temprature AS temperature#24, 'pressure AS pressure#25, 'humidy AS humidity#26]      Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
 +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                          +- SubqueryAlias `outtab`
    +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]      +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
       +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                       +- SubqueryAlias `bomstatis`
          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch UDF ===
!Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]     Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
 +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                          +- SubqueryAlias `outtab`
    +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]      +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
       +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                       +- SubqueryAlias `bomstatis`
          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
 +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `outtab`
    +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                           +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
       +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                            +- SubqueryAlias `bomstatis`
          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                              +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast(location#20 as string), None), unresolvedalias(cast(position#21 as string), None), unresolvedalias(cast(local_time#22 as string), None), unresolvedalias(cast(conditions#23 as string), None), unresolvedalias(cast(temperature#24 as string), None), unresolvedalias(cast(pressure#25 as string), None), unresolvedalias(cast(humidity#26 as string), None)]                               Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]
 +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
    +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `outtab`
       +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                              +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
          +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `bomstatis`
             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]                                                                                 Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]
 +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
    +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `outtab`
       +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                              +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
          +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `bomstatis`
             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Finish Analysis ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                   GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                 +- LocalLimit 21
    +- Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]                                                                                    +- Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]
       +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]         +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!         +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                        +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!            +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                    +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!               +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!                  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                   GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                 +- LocalLimit 21
!   +- Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]                                                                                    +- Project [split(UDF(location#10), [|])[0] AS location#46, split(UDF(location#10), [|])[1] AS position#47, UDF(monthday#11, location#10) AS local_time#48, if ((isnull(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double)) || isnull(cast(UDF() as int)))) null else UDF(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double), cast(UDF() as int)) AS conditions#49, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#50, UDF() AS pressure#51, UDF() AS humidity#52]
!      +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                           
!            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                           
          
Pruning directories with: 
Post-Scan Filters: 
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, getcolumnbyordinal(3, StringType).toString, getcolumnbyordinal(4, StringType).toString, getcolumnbyordinal(5, StringType).toString, getcolumnbyordinal(6, StringType).toString, StructField(location,StringType,true), StructField(position,StringType,true), StructField(local_time,StringType,true), StructField(conditions,StringType,true), StructField(temperature,StringType,true), StructField(pressure,StringType,true), StructField(humidity,StringType,true))), obj#60: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(location#46.toString, position#47.toString, local_time#48.toString, conditions#49.toString, temperature#50.toString, pressure#51.toString, humidity#52.toString, StructField(location,StringType,true), StructField(position,StringType,true), StructField(local_time,StringType,true), StructField(conditions,StringType,true), StructField(temperature,StringType,true), StructField(pressure,StringType,true), StructField(humidity,StringType,true)), obj#60: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [location#46, position#47, local_time#48, conditions#49, temperature#50, pressure#51, humidity#52]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   +- LocalRelation <empty>, [location#46, position#47, local_time#48, conditions#49, temperature#50, pressure#51, humidity#52]
          
code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, input[3, string, true].toString, input[4, string, true].toString, input[5, string, true].toString, input[6, string, true].toString, StructField(location,StringType,true), StructField(position,StringType,true), StructField(local_time,StringType,true), StructField(conditions,StringType,true), StructField(temperature,StringType,true), StructField(pressure,StringType,true), StructField(humidity,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[7];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     createExternalRow_0_2(i, values_0);
/* 027 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 028 */     if (false) {
/* 029 */       mutableRow.setNullAt(0);
/* 030 */     } else {
/* 031 */
/* 032 */       mutableRow.update(0, value_0);
/* 033 */     }
/* 034 */
/* 035 */     return mutableRow;
/* 036 */   }
/* 037 */
/* 038 */
/* 039 */   private void createExternalRow_0_2(InternalRow i, Object[] values_0) {
/* 040 */
/* 041 */     boolean isNull_14 = i.isNullAt(6);
/* 042 */     UTF8String value_14 = isNull_14 ?
/* 043 */     null : (i.getUTF8String(6));
/* 044 */     boolean isNull_13 = true;
/* 045 */     java.lang.String value_13 = null;
/* 046 */     if (!isNull_14) {
/* 047 */
/* 048 */       isNull_13 = false;
/* 049 */       if (!isNull_13) {
/* 050 */
/* 051 */         Object funcResult_6 = null;
/* 052 */         funcResult_6 = value_14.toString();
/* 053 */         value_13 = (java.lang.String) funcResult_6;
/* 054 */
/* 055 */       }
/* 056 */     }
/* 057 */     if (isNull_13) {
/* 058 */       values_0[6] = null;
/* 059 */     } else {
/* 060 */       values_0[6] = value_13;
/* 061 */     }
/* 062 */
/* 063 */   }
/* 064 */
/* 065 */
/* 066 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 067 */
/* 068 */     boolean isNull_8 = i.isNullAt(3);
/* 069 */     UTF8String value_8 = isNull_8 ?
/* 070 */     null : (i.getUTF8String(3));
/* 071 */     boolean isNull_7 = true;
/* 072 */     java.lang.String value_7 = null;
/* 073 */     if (!isNull_8) {
/* 074 */
/* 075 */       isNull_7 = false;
/* 076 */       if (!isNull_7) {
/* 077 */
/* 078 */         Object funcResult_3 = null;
/* 079 */         funcResult_3 = value_8.toString();
/* 080 */         value_7 = (java.lang.String) funcResult_3;
/* 081 */
/* 082 */       }
/* 083 */     }
/* 084 */     if (isNull_7) {
/* 085 */       values_0[3] = null;
/* 086 */     } else {
/* 087 */       values_0[3] = value_7;
/* 088 */     }
/* 089 */
/* 090 */     boolean isNull_10 = i.isNullAt(4);
/* 091 */     UTF8String value_10 = isNull_10 ?
/* 092 */     null : (i.getUTF8String(4));
/* 093 */     boolean isNull_9 = true;
/* 094 */     java.lang.String value_9 = null;
/* 095 */     if (!isNull_10) {
/* 096 */
/* 097 */       isNull_9 = false;
/* 098 */       if (!isNull_9) {
/* 099 */
/* 100 */         Object funcResult_4 = null;
/* 101 */         funcResult_4 = value_10.toString();
/* 102 */         value_9 = (java.lang.String) funcResult_4;
/* 103 */
/* 104 */       }
/* 105 */     }
/* 106 */     if (isNull_9) {
/* 107 */       values_0[4] = null;
/* 108 */     } else {
/* 109 */       values_0[4] = value_9;
/* 110 */     }
/* 111 */
/* 112 */     boolean isNull_12 = i.isNullAt(5);
/* 113 */     UTF8String value_12 = isNull_12 ?
/* 114 */     null : (i.getUTF8String(5));
/* 115 */     boolean isNull_11 = true;
/* 116 */     java.lang.String value_11 = null;
/* 117 */     if (!isNull_12) {
/* 118 */
/* 119 */       isNull_11 = false;
/* 120 */       if (!isNull_11) {
/* 121 */
/* 122 */         Object funcResult_5 = null;
/* 123 */         funcResult_5 = value_12.toString();
/* 124 */         value_11 = (java.lang.String) funcResult_5;
/* 125 */
/* 126 */       }
/* 127 */     }
/* 128 */     if (isNull_11) {
/* 129 */       values_0[5] = null;
/* 130 */     } else {
/* 131 */       values_0[5] = value_11;
/* 132 */     }
/* 133 */
/* 134 */   }
/* 135 */
/* 136 */
/* 137 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 138 */
/* 139 */     boolean isNull_2 = i.isNullAt(0);
/* 140 */     UTF8String value_2 = isNull_2 ?
/* 141 */     null : (i.getUTF8String(0));
/* 142 */     boolean isNull_1 = true;
/* 143 */     java.lang.String value_1 = null;
/* 144 */     if (!isNull_2) {
/* 145 */
/* 146 */       isNull_1 = false;
/* 147 */       if (!isNull_1) {
/* 148 */
/* 149 */         Object funcResult_0 = null;
/* 150 */         funcResult_0 = value_2.toString();
/* 151 */         value_1 = (java.lang.String) funcResult_0;
/* 152 */
/* 153 */       }
/* 154 */     }
/* 155 */     if (isNull_1) {
/* 156 */       values_0[0] = null;
/* 157 */     } else {
/* 158 */       values_0[0] = value_1;
/* 159 */     }
/* 160 */
/* 161 */     boolean isNull_4 = i.isNullAt(1);
/* 162 */     UTF8String value_4 = isNull_4 ?
/* 163 */     null : (i.getUTF8String(1));
/* 164 */     boolean isNull_3 = true;
/* 165 */     java.lang.String value_3 = null;
/* 166 */     if (!isNull_4) {
/* 167 */
/* 168 */       isNull_3 = false;
/* 169 */       if (!isNull_3) {
/* 170 */
/* 171 */         Object funcResult_1 = null;
/* 172 */         funcResult_1 = value_4.toString();
/* 173 */         value_3 = (java.lang.String) funcResult_1;
/* 174 */
/* 175 */       }
/* 176 */     }
/* 177 */     if (isNull_3) {
/* 178 */       values_0[1] = null;
/* 179 */     } else {
/* 180 */       values_0[1] = value_3;
/* 181 */     }
/* 182 */
/* 183 */     boolean isNull_6 = i.isNullAt(2);
/* 184 */     UTF8String value_6 = isNull_6 ?
/* 185 */     null : (i.getUTF8String(2));
/* 186 */     boolean isNull_5 = true;
/* 187 */     java.lang.String value_5 = null;
/* 188 */     if (!isNull_6) {
/* 189 */
/* 190 */       isNull_5 = false;
/* 191 */       if (!isNull_5) {
/* 192 */
/* 193 */         Object funcResult_2 = null;
/* 194 */         funcResult_2 = value_6.toString();
/* 195 */         value_5 = (java.lang.String) funcResult_2;
/* 196 */
/* 197 */       }
/* 198 */     }
/* 199 */     if (isNull_5) {
/* 200 */       values_0[2] = null;
/* 201 */     } else {
/* 202 */       values_0[2] = value_5;
/* 203 */     }
/* 204 */
/* 205 */   }
/* 206 */
/* 207 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[7];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     createExternalRow_0_2(i, values_0);
/* 027 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 028 */     if (false) {
/* 029 */       mutableRow.setNullAt(0);
/* 030 */     } else {
/* 031 */
/* 032 */       mutableRow.update(0, value_0);
/* 033 */     }
/* 034 */
/* 035 */     return mutableRow;
/* 036 */   }
/* 037 */
/* 038 */
/* 039 */   private void createExternalRow_0_2(InternalRow i, Object[] values_0) {
/* 040 */
/* 041 */     boolean isNull_14 = i.isNullAt(6);
/* 042 */     UTF8String value_14 = isNull_14 ?
/* 043 */     null : (i.getUTF8String(6));
/* 044 */     boolean isNull_13 = true;
/* 045 */     java.lang.String value_13 = null;
/* 046 */     if (!isNull_14) {
/* 047 */
/* 048 */       isNull_13 = false;
/* 049 */       if (!isNull_13) {
/* 050 */
/* 051 */         Object funcResult_6 = null;
/* 052 */         funcResult_6 = value_14.toString();
/* 053 */         value_13 = (java.lang.String) funcResult_6;
/* 054 */
/* 055 */       }
/* 056 */     }
/* 057 */     if (isNull_13) {
/* 058 */       values_0[6] = null;
/* 059 */     } else {
/* 060 */       values_0[6] = value_13;
/* 061 */     }
/* 062 */
/* 063 */   }
/* 064 */
/* 065 */
/* 066 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 067 */
/* 068 */     boolean isNull_8 = i.isNullAt(3);
/* 069 */     UTF8String value_8 = isNull_8 ?
/* 070 */     null : (i.getUTF8String(3));
/* 071 */     boolean isNull_7 = true;
/* 072 */     java.lang.String value_7 = null;
/* 073 */     if (!isNull_8) {
/* 074 */
/* 075 */       isNull_7 = false;
/* 076 */       if (!isNull_7) {
/* 077 */
/* 078 */         Object funcResult_3 = null;
/* 079 */         funcResult_3 = value_8.toString();
/* 080 */         value_7 = (java.lang.String) funcResult_3;
/* 081 */
/* 082 */       }
/* 083 */     }
/* 084 */     if (isNull_7) {
/* 085 */       values_0[3] = null;
/* 086 */     } else {
/* 087 */       values_0[3] = value_7;
/* 088 */     }
/* 089 */
/* 090 */     boolean isNull_10 = i.isNullAt(4);
/* 091 */     UTF8String value_10 = isNull_10 ?
/* 092 */     null : (i.getUTF8String(4));
/* 093 */     boolean isNull_9 = true;
/* 094 */     java.lang.String value_9 = null;
/* 095 */     if (!isNull_10) {
/* 096 */
/* 097 */       isNull_9 = false;
/* 098 */       if (!isNull_9) {
/* 099 */
/* 100 */         Object funcResult_4 = null;
/* 101 */         funcResult_4 = value_10.toString();
/* 102 */         value_9 = (java.lang.String) funcResult_4;
/* 103 */
/* 104 */       }
/* 105 */     }
/* 106 */     if (isNull_9) {
/* 107 */       values_0[4] = null;
/* 108 */     } else {
/* 109 */       values_0[4] = value_9;
/* 110 */     }
/* 111 */
/* 112 */     boolean isNull_12 = i.isNullAt(5);
/* 113 */     UTF8String value_12 = isNull_12 ?
/* 114 */     null : (i.getUTF8String(5));
/* 115 */     boolean isNull_11 = true;
/* 116 */     java.lang.String value_11 = null;
/* 117 */     if (!isNull_12) {
/* 118 */
/* 119 */       isNull_11 = false;
/* 120 */       if (!isNull_11) {
/* 121 */
/* 122 */         Object funcResult_5 = null;
/* 123 */         funcResult_5 = value_12.toString();
/* 124 */         value_11 = (java.lang.String) funcResult_5;
/* 125 */
/* 126 */       }
/* 127 */     }
/* 128 */     if (isNull_11) {
/* 129 */       values_0[5] = null;
/* 130 */     } else {
/* 131 */       values_0[5] = value_11;
/* 132 */     }
/* 133 */
/* 134 */   }
/* 135 */
/* 136 */
/* 137 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 138 */
/* 139 */     boolean isNull_2 = i.isNullAt(0);
/* 140 */     UTF8String value_2 = isNull_2 ?
/* 141 */     null : (i.getUTF8String(0));
/* 142 */     boolean isNull_1 = true;
/* 143 */     java.lang.String value_1 = null;
/* 144 */     if (!isNull_2) {
/* 145 */
/* 146 */       isNull_1 = false;
/* 147 */       if (!isNull_1) {
/* 148 */
/* 149 */         Object funcResult_0 = null;
/* 150 */         funcResult_0 = value_2.toString();
/* 151 */         value_1 = (java.lang.String) funcResult_0;
/* 152 */
/* 153 */       }
/* 154 */     }
/* 155 */     if (isNull_1) {
/* 156 */       values_0[0] = null;
/* 157 */     } else {
/* 158 */       values_0[0] = value_1;
/* 159 */     }
/* 160 */
/* 161 */     boolean isNull_4 = i.isNullAt(1);
/* 162 */     UTF8String value_4 = isNull_4 ?
/* 163 */     null : (i.getUTF8String(1));
/* 164 */     boolean isNull_3 = true;
/* 165 */     java.lang.String value_3 = null;
/* 166 */     if (!isNull_4) {
/* 167 */
/* 168 */       isNull_3 = false;
/* 169 */       if (!isNull_3) {
/* 170 */
/* 171 */         Object funcResult_1 = null;
/* 172 */         funcResult_1 = value_4.toString();
/* 173 */         value_3 = (java.lang.String) funcResult_1;
/* 174 */
/* 175 */       }
/* 176 */     }
/* 177 */     if (isNull_3) {
/* 178 */       values_0[1] = null;
/* 179 */     } else {
/* 180 */       values_0[1] = value_3;
/* 181 */     }
/* 182 */
/* 183 */     boolean isNull_6 = i.isNullAt(2);
/* 184 */     UTF8String value_6 = isNull_6 ?
/* 185 */     null : (i.getUTF8String(2));
/* 186 */     boolean isNull_5 = true;
/* 187 */     java.lang.String value_5 = null;
/* 188 */     if (!isNull_6) {
/* 189 */
/* 190 */       isNull_5 = false;
/* 191 */       if (!isNull_5) {
/* 192 */
/* 193 */         Object funcResult_2 = null;
/* 194 */         funcResult_2 = value_6.toString();
/* 195 */         value_5 = (java.lang.String) funcResult_2;
/* 196 */
/* 197 */       }
/* 198 */     }
/* 199 */     if (isNull_5) {
/* 200 */       values_0[2] = null;
/* 201 */     } else {
/* 202 */       values_0[2] = value_5;
/* 203 */     }
/* 204 */
/* 205 */   }
/* 206 */
/* 207 */ }

Code generated in 22.550905 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 029 */       UTF8String scan_value_0 = scan_isNull_0 ?
/* 030 */       null : (scan_row_0.getUTF8String(0));
/* 031 */       boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 032 */       UTF8String scan_value_2 = scan_isNull_2 ?
/* 033 */       null : (scan_row_0.getUTF8String(2));
/* 034 */       boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 035 */       UTF8String scan_value_3 = scan_isNull_3 ?
/* 036 */       null : (scan_row_0.getUTF8String(3));
/* 037 */
/* 038 */       boolean project_isNull_0 = true;
/* 039 */       UTF8String project_value_0 = null;
/* 040 */       boolean project_isNull_1 = true;
/* 041 */       ArrayData project_value_1 = null;
/* 042 */       Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[1] /* converters */)[0].apply(scan_value_0);
/* 043 */
/* 044 */       UTF8String project_result_0 = null;
/* 045 */       try {
/* 046 */         project_result_0 = (UTF8String)((scala.Function1[]) references[1] /* converters */)[1].apply(((scala.Function1) references[3] /* udf */).apply(project_arg_0));
/* 047 */       } catch (Exception e) {
/* 048 */         throw new org.apache.spark.SparkException(((java.lang.String) references[2] /* errMsg */), e);
/* 049 */       }
/* 050 */
/* 051 */       boolean project_isNull_2 = project_result_0 == null;
/* 052 */       UTF8String project_value_2 = null;
/* 053 */       if (!project_isNull_2) {
/* 054 */         project_value_2 = project_result_0;
/* 055 */       }
/* 056 */       if (!project_isNull_2) {
/* 057 */         project_isNull_1 = false; // resultCode could change nullability.
/* 058 */         project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[4] /* literal */), -1));
/* 059 */
/* 060 */       }
/* 061 */       if (!project_isNull_1) {
/* 062 */         project_isNull_0 = false; // resultCode could change nullability.
/* 063 */
/* 064 */         final int project_index_0 = (int) 0;
/* 065 */         if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 066 */           project_isNull_0 = true;
/* 067 */         } else {
/* 068 */           project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 069 */         }
/* 070 */
/* 071 */       }
/* 072 */       boolean project_isNull_6 = true;
/* 073 */       UTF8String project_value_6 = null;
/* 074 */       boolean project_isNull_7 = true;
/* 075 */       ArrayData project_value_7 = null;
/* 076 */       Object project_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 077 */
/* 078 */       UTF8String project_result_1 = null;
/* 079 */       try {
/* 080 */         project_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(project_arg_1));
/* 081 */       } catch (Exception e) {
/* 082 */         throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 083 */       }
/* 084 */
/* 085 */       boolean project_isNull_8 = project_result_1 == null;
/* 086 */       UTF8String project_value_8 = null;
/* 087 */       if (!project_isNull_8) {
/* 088 */         project_value_8 = project_result_1;
/* 089 */       }
/* 090 */       if (!project_isNull_8) {
/* 091 */         project_isNull_7 = false; // resultCode could change nullability.
/* 092 */         project_value_7 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_8.split(((UTF8String) references[8] /* literal */), -1));
/* 093 */
/* 094 */       }
/* 095 */       if (!project_isNull_7) {
/* 096 */         project_isNull_6 = false; // resultCode could change nullability.
/* 097 */
/* 098 */         final int project_index_1 = (int) 1;
/* 099 */         if (project_index_1 >= project_value_7.numElements() || project_index_1 < 0 || project_value_7.isNullAt(project_index_1)) {
/* 100 */           project_isNull_6 = true;
/* 101 */         } else {
/* 102 */           project_value_6 = project_value_7.getUTF8String(project_index_1);
/* 103 */         }
/* 104 */
/* 105 */       }
/* 106 */       boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 107 */       UTF8String scan_value_1 = scan_isNull_1 ?
/* 108 */       null : (scan_row_0.getUTF8String(1));
/* 109 */
/* 110 */       Object project_arg_2 = scan_isNull_1 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_1);
/* 111 */       Object project_arg_3 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[1].apply(scan_value_0);
/* 112 */
/* 113 */       UTF8String project_result_2 = null;
/* 114 */       try {
/* 115 */         project_result_2 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[2].apply(((scala.Function2) references[11] /* udf */).apply(project_arg_2, project_arg_3));
/* 116 */       } catch (Exception e) {
/* 117 */         throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 118 */       }
/* 119 */
/* 120 */       boolean project_isNull_12 = project_result_2 == null;
/* 121 */       UTF8String project_value_12 = null;
/* 122 */       if (!project_isNull_12) {
/* 123 */         project_value_12 = project_result_2;
/* 124 */       }
/* 125 */       boolean project_isNull_19 = true;
/* 126 */       UTF8String project_value_19 = null;
/* 127 */       boolean project_isNull_23 = scan_isNull_3;
/* 128 */       double project_value_23 = -1.0;
/* 129 */       if (!scan_isNull_3) {
/* 130 */         try {
/* 131 */           project_value_23 = Double.valueOf(scan_value_3.toString());
/* 132 */         } catch (java.lang.NumberFormatException e) {
/* 133 */           project_isNull_23 = true;
/* 134 */         }
/* 135 */       }
/* 136 */       boolean project_value_21 = true;
/* 137 */
/* 138 */       if (!project_isNull_23) {
/* 139 */         boolean project_isNull_26 = scan_isNull_2;
/* 140 */         double project_value_26 = -1.0;
/* 141 */         if (!scan_isNull_2) {
/* 142 */           try {
/* 143 */             project_value_26 = Double.valueOf(scan_value_2.toString());
/* 144 */           } catch (java.lang.NumberFormatException e) {
/* 145 */             project_isNull_26 = true;
/* 146 */           }
/* 147 */         }
/* 148 */         project_value_21 = project_isNull_26;
/* 149 */       }
/* 150 */       boolean project_isNull_20 = false;
/* 151 */       UTF8String project_value_20 = null;
/* 152 */       if (!false && project_value_21) {
/* 153 */         project_isNull_20 = true;
/* 154 */         project_value_20 = ((UTF8String)null);
/* 155 */       } else {
/* 156 */         boolean project_isNull_30 = scan_isNull_3;
/* 157 */         double project_value_30 = -1.0;
/* 158 */         if (!scan_isNull_3) {
/* 159 */           try {
/* 160 */             project_value_30 = Double.valueOf(scan_value_3.toString());
/* 161 */           } catch (java.lang.NumberFormatException e) {
/* 162 */             project_isNull_30 = true;
/* 163 */           }
/* 164 */         }
/* 165 */         boolean project_isNull_32 = scan_isNull_2;
/* 166 */         double project_value_32 = -1.0;
/* 167 */         if (!scan_isNull_2) {
/* 168 */           try {
/* 169 */             project_value_32 = Double.valueOf(scan_value_2.toString());
/* 170 */           } catch (java.lang.NumberFormatException e) {
/* 171 */             project_isNull_32 = true;
/* 172 */           }
/* 173 */         }
/* 174 */         Object project_arg_4 = project_isNull_30 ? null : ((scala.Function1[]) references[12] /* converters */)[0].apply(project_value_30);
/* 175 */         Object project_arg_5 = project_isNull_32 ? null : ((scala.Function1[]) references[12] /* converters */)[1].apply(project_value_32);
/* 176 */
/* 177 */         UTF8String project_result_3 = null;
/* 178 */         try {
/* 179 */           project_result_3 = (UTF8String)((scala.Function1[]) references[12] /* converters */)[2].apply(((scala.Function2) references[14] /* udf */).apply(project_arg_4, project_arg_5));
/* 180 */         } catch (Exception e) {
/* 181 */           throw new org.apache.spark.SparkException(((java.lang.String) references[13] /* errMsg */), e);
/* 182 */         }
/* 183 */
/* 184 */         boolean project_isNull_29 = project_result_3 == null;
/* 185 */         UTF8String project_value_29 = null;
/* 186 */         if (!project_isNull_29) {
/* 187 */           project_value_29 = project_result_3;
/* 188 */         }
/* 189 */         project_isNull_20 = project_isNull_29;
/* 190 */         project_value_20 = project_value_29;
/* 191 */       }
/* 192 */       if (!project_isNull_20) {
/* 193 */         project_isNull_19 = false; // resultCode could change nullability.
/* 194 */         project_value_19 = project_value_20.replace(((UTF8String) references[15] /* literal */), ((UTF8String) references[16] /* literal */));
/* 195 */
/* 196 */       }
/* 197 */       boolean project_isNull_18 = project_isNull_19;
/* 198 */       double project_value_18 = -1.0;
/* 199 */       if (!project_isNull_19) {
/* 200 */         try {
/* 201 */           project_value_18 = Double.valueOf(project_value_19.toString());
/* 202 */         } catch (java.lang.NumberFormatException e) {
/* 203 */           project_isNull_18 = true;
/* 204 */         }
/* 205 */       }
/* 206 */       boolean project_value_16 = true;
/* 207 */
/* 208 */       if (!project_isNull_18) {
/* 209 */         UTF8String project_result_4 = null;
/* 210 */         try {
/* 211 */           project_result_4 = (UTF8String)((scala.Function1[]) references[17] /* converters */)[0].apply(((scala.Function0) references[19] /* udf */).apply());
/* 212 */         } catch (Exception e) {
/* 213 */           throw new org.apache.spark.SparkException(((java.lang.String) references[18] /* errMsg */), e);
/* 214 */         }
/* 215 */
/* 216 */         boolean project_isNull_38 = project_result_4 == null;
/* 217 */         UTF8String project_value_38 = null;
/* 218 */         if (!project_isNull_38) {
/* 219 */           project_value_38 = project_result_4;
/* 220 */         }
/* 221 */         boolean project_isNull_37 = project_isNull_38;
/* 222 */         int project_value_37 = -1;
/* 223 */         if (!project_isNull_38) {
/* 224 */           UTF8String.IntWrapper project_intWrapper_0 = new UTF8String.IntWrapper();
/* 225 */           if (project_value_38.toInt(project_intWrapper_0)) {
/* 226 */             project_value_37 = project_intWrapper_0.value;
/* 227 */           } else {
/* 228 */             project_isNull_37 = true;
/* 229 */           }
/* 230 */           project_intWrapper_0 = null;
/* 231 */         }
/* 232 */         project_value_16 = project_isNull_37;
/* 233 */       }
/* 234 */       boolean project_isNull_15 = false;
/* 235 */       UTF8String project_value_15 = null;
/* 236 */       if (!false && project_value_16) {
/* 237 */         project_isNull_15 = true;
/* 238 */         project_value_15 = ((UTF8String)null);
/* 239 */       } else {
/* 240 */         boolean project_isNull_42 = true;
/* 241 */         UTF8String project_value_42 = null;
/* 242 */         boolean project_isNull_46 = scan_isNull_3;
/* 243 */         double project_value_46 = -1.0;
/* 244 */         if (!scan_isNull_3) {
/* 245 */           try {
/* 246 */             project_value_46 = Double.valueOf(scan_value_3.toString());
/* 247 */           } catch (java.lang.NumberFormatException e) {
/* 248 */             project_isNull_46 = true;
/* 249 */           }
/* 250 */         }
/* 251 */         boolean project_value_44 = true;
/* 252 */
/* 253 */         if (!project_isNull_46) {
/* 254 */           boolean project_isNull_49 = scan_isNull_2;
/* 255 */           double project_value_49 = -1.0;
/* 256 */           if (!scan_isNull_2) {
/* 257 */             try {
/* 258 */               project_value_49 = Double.valueOf(scan_value_2.toString());
/* 259 */             } catch (java.lang.NumberFormatException e) {
/* 260 */               project_isNull_49 = true;
/* 261 */             }
/* 262 */           }
/* 263 */           project_value_44 = project_isNull_49;
/* 264 */         }
/* 265 */         boolean project_isNull_43 = false;
/* 266 */         UTF8String project_value_43 = null;
/* 267 */         if (!false && project_value_44) {
/* 268 */           project_isNull_43 = true;
/* 269 */           project_value_43 = ((UTF8String)null);
/* 270 */         } else {
/* 271 */           boolean project_isNull_53 = scan_isNull_3;
/* 272 */           double project_value_53 = -1.0;
/* 273 */           if (!scan_isNull_3) {
/* 274 */             try {
/* 275 */               project_value_53 = Double.valueOf(scan_value_3.toString());
/* 276 */             } catch (java.lang.NumberFormatException e) {
/* 277 */               project_isNull_53 = true;
/* 278 */             }
/* 279 */           }
/* 280 */           boolean project_isNull_55 = scan_isNull_2;
/* 281 */           double project_value_55 = -1.0;
/* 282 */           if (!scan_isNull_2) {
/* 283 */             try {
/* 284 */               project_value_55 = Double.valueOf(scan_value_2.toString());
/* 285 */             } catch (java.lang.NumberFormatException e) {
/* 286 */               project_isNull_55 = true;
/* 287 */             }
/* 288 */           }
/* 289 */           Object project_arg_6 = project_isNull_53 ? null : ((scala.Function1[]) references[22] /* converters */)[0].apply(project_value_53);
/* 290 */           Object project_arg_7 = project_isNull_55 ? null : ((scala.Function1[]) references[22] /* converters */)[1].apply(project_value_55);
/* 291 */
/* 292 */           UTF8String project_result_6 = null;
/* 293 */           try {
/* 294 */             project_result_6 = (UTF8String)((scala.Function1[]) references[22] /* converters */)[2].apply(((scala.Function2) references[24] /* udf */).apply(project_arg_6, project_arg_7));
/* 295 */           } catch (Exception e) {
/* 296 */             throw new org.apache.spark.SparkException(((java.lang.String) references[23] /* errMsg */), e);
/* 297 */           }
/* 298 */
/* 299 */           boolean project_isNull_52 = project_result_6 == null;
/* 300 */           UTF8String project_value_52 = null;
/* 301 */           if (!project_isNull_52) {
/* 302 */             project_value_52 = project_result_6;
/* 303 */           }
/* 304 */           project_isNull_43 = project_isNull_52;
/* 305 */           project_value_43 = project_value_52;
/* 306 */         }
/* 307 */         if (!project_isNull_43) {
/* 308 */           project_isNull_42 = false; // resultCode could change nullability.
/* 309 */           project_value_42 = project_value_43.replace(((UTF8String) references[25] /* literal */), ((UTF8String) references[26] /* literal */));
/* 310 */
/* 311 */         }
/* 312 */         boolean project_isNull_41 = project_isNull_42;
/* 313 */         double project_value_41 = -1.0;
/* 314 */         if (!project_isNull_42) {
/* 315 */           try {
/* 316 */             project_value_41 = Double.valueOf(project_value_42.toString());
/* 317 */           } catch (java.lang.NumberFormatException e) {
/* 318 */             project_isNull_41 = true;
/* 319 */           }
/* 320 */         }
/* 321 */         UTF8String project_result_7 = null;
/* 322 */         try {
/* 323 */           project_result_7 = (UTF8String)((scala.Function1[]) references[27] /* converters */)[0].apply(((scala.Function0) references[29] /* udf */).apply());
/* 324 */         } catch (Exception e) {
/* 325 */           throw new org.apache.spark.SparkException(((java.lang.String) references[28] /* errMsg */), e);
/* 326 */         }
/* 327 */
/* 328 */         boolean project_isNull_60 = project_result_7 == null;
/* 329 */         UTF8String project_value_60 = null;
/* 330 */         if (!project_isNull_60) {
/* 331 */           project_value_60 = project_result_7;
/* 332 */         }
/* 333 */         boolean project_isNull_59 = project_isNull_60;
/* 334 */         int project_value_59 = -1;
/* 335 */         if (!project_isNull_60) {
/* 336 */           UTF8String.IntWrapper project_intWrapper_1 = new UTF8String.IntWrapper();
/* 337 */           if (project_value_60.toInt(project_intWrapper_1)) {
/* 338 */             project_value_59 = project_intWrapper_1.value;
/* 339 */           } else {
/* 340 */             project_isNull_59 = true;
/* 341 */           }
/* 342 */           project_intWrapper_1 = null;
/* 343 */         }
/* 344 */         Object project_arg_8 = project_isNull_41 ? null : ((scala.Function1[]) references[20] /* converters */)[0].apply(project_value_41);
/* 345 */         Object project_arg_9 = project_isNull_59 ? null : ((scala.Function1[]) references[20] /* converters */)[1].apply(project_value_59);
/* 346 */
/* 347 */         UTF8String project_result_5 = null;
/* 348 */         try {
/* 349 */           project_result_5 = (UTF8String)((scala.Function1[]) references[20] /* converters */)[2].apply(((scala.Function2) references[30] /* udf */).apply(project_arg_8, project_arg_9));
/* 350 */         } catch (Exception e) {
/* 351 */           throw new org.apache.spark.SparkException(((java.lang.String) references[21] /* errMsg */), e);
/* 352 */         }
/* 353 */
/* 354 */         boolean project_isNull_40 = project_result_5 == null;
/* 355 */         UTF8String project_value_40 = null;
/* 356 */         if (!project_isNull_40) {
/* 357 */           project_value_40 = project_result_5;
/* 358 */         }
/* 359 */         project_isNull_15 = project_isNull_40;
/* 360 */         project_value_15 = project_value_40;
/* 361 */       }
/* 362 */       boolean project_isNull_64 = scan_isNull_3;
/* 363 */       double project_value_64 = -1.0;
/* 364 */       if (!scan_isNull_3) {
/* 365 */         try {
/* 366 */           project_value_64 = Double.valueOf(scan_value_3.toString());
/* 367 */         } catch (java.lang.NumberFormatException e) {
/* 368 */           project_isNull_64 = true;
/* 369 */         }
/* 370 */       }
/* 371 */       boolean project_value_62 = true;
/* 372 */
/* 373 */       if (!project_isNull_64) {
/* 374 */         boolean project_isNull_67 = scan_isNull_2;
/* 375 */         double project_value_67 = -1.0;
/* 376 */         if (!scan_isNull_2) {
/* 377 */           try {
/* 378 */             project_value_67 = Double.valueOf(scan_value_2.toString());
/* 379 */           } catch (java.lang.NumberFormatException e) {
/* 380 */             project_isNull_67 = true;
/* 381 */           }
/* 382 */         }
/* 383 */         project_value_62 = project_isNull_67;
/* 384 */       }
/* 385 */       boolean project_isNull_61 = false;
/* 386 */       UTF8String project_value_61 = null;
/* 387 */       if (!false && project_value_62) {
/* 388 */         project_isNull_61 = true;
/* 389 */         project_value_61 = ((UTF8String)null);
/* 390 */       } else {
/* 391 */         boolean project_isNull_71 = scan_isNull_3;
/* 392 */         double project_value_71 = -1.0;
/* 393 */         if (!scan_isNull_3) {
/* 394 */           try {
/* 395 */             project_value_71 = Double.valueOf(scan_value_3.toString());
/* 396 */           } catch (java.lang.NumberFormatException e) {
/* 397 */             project_isNull_71 = true;
/* 398 */           }
/* 399 */         }
/* 400 */         boolean project_isNull_73 = scan_isNull_2;
/* 401 */         double project_value_73 = -1.0;
/* 402 */         if (!scan_isNull_2) {
/* 403 */           try {
/* 404 */             project_value_73 = Double.valueOf(scan_value_2.toString());
/* 405 */           } catch (java.lang.NumberFormatException e) {
/* 406 */             project_isNull_73 = true;
/* 407 */           }
/* 408 */         }
/* 409 */         Object project_arg_10 = project_isNull_71 ? null : ((scala.Function1[]) references[31] /* converters */)[0].apply(project_value_71);
/* 410 */         Object project_arg_11 = project_isNull_73 ? null : ((scala.Function1[]) references[31] /* converters */)[1].apply(project_value_73);
/* 411 */
/* 412 */         UTF8String project_result_8 = null;
/* 413 */         try {
/* 414 */           project_result_8 = (UTF8String)((scala.Function1[]) references[31] /* converters */)[2].apply(((scala.Function2) references[33] /* udf */).apply(project_arg_10, project_arg_11));
/* 415 */         } catch (Exception e) {
/* 416 */           throw new org.apache.spark.SparkException(((java.lang.String) references[32] /* errMsg */), e);
/* 417 */         }
/* 418 */
/* 419 */         boolean project_isNull_70 = project_result_8 == null;
/* 420 */         UTF8String project_value_70 = null;
/* 421 */         if (!project_isNull_70) {
/* 422 */           project_value_70 = project_result_8;
/* 423 */         }
/* 424 */         project_isNull_61 = project_isNull_70;
/* 425 */         project_value_61 = project_value_70;
/* 426 */       }
/* 427 */       UTF8String project_result_9 = null;
/* 428 */       try {
/* 429 */         project_result_9 = (UTF8String)((scala.Function1[]) references[34] /* converters */)[0].apply(((scala.Function0) references[36] /* udf */).apply());
/* 430 */       } catch (Exception e) {
/* 431 */         throw new org.apache.spark.SparkException(((java.lang.String) references[35] /* errMsg */), e);
/* 432 */       }
/* 433 */
/* 434 */       boolean project_isNull_75 = project_result_9 == null;
/* 435 */       UTF8String project_value_75 = null;
/* 436 */       if (!project_isNull_75) {
/* 437 */         project_value_75 = project_result_9;
/* 438 */       }
/* 439 */       UTF8String project_result_10 = null;
/* 440 */       try {
/* 441 */         project_result_10 = (UTF8String)((scala.Function1[]) references[37] /* converters */)[0].apply(((scala.Function0) references[39] /* udf */).apply());
/* 442 */       } catch (Exception e) {
/* 443 */         throw new org.apache.spark.SparkException(((java.lang.String) references[38] /* errMsg */), e);
/* 444 */       }
/* 445 */
/* 446 */       boolean project_isNull_76 = project_result_10 == null;
/* 447 */       UTF8String project_value_76 = null;
/* 448 */       if (!project_isNull_76) {
/* 449 */         project_value_76 = project_result_10;
/* 450 */       }
/* 451 */       project_mutableStateArray_0[0].reset();
/* 452 */
/* 453 */       project_mutableStateArray_0[0].zeroOutNullBytes();
/* 454 */
/* 455 */       if (project_isNull_0) {
/* 456 */         project_mutableStateArray_0[0].setNullAt(0);
/* 457 */       } else {
/* 458 */         project_mutableStateArray_0[0].write(0, project_value_0);
/* 459 */       }
/* 460 */
/* 461 */       if (project_isNull_6) {
/* 462 */         project_mutableStateArray_0[0].setNullAt(1);
/* 463 */       } else {
/* 464 */         project_mutableStateArray_0[0].write(1, project_value_6);
/* 465 */       }
/* 466 */
/* 467 */       if (project_isNull_12) {
/* 468 */         project_mutableStateArray_0[0].setNullAt(2);
/* 469 */       } else {
/* 470 */         project_mutableStateArray_0[0].write(2, project_value_12);
/* 471 */       }
/* 472 */
/* 473 */       if (project_isNull_15) {
/* 474 */         project_mutableStateArray_0[0].setNullAt(3);
/* 475 */       } else {
/* 476 */         project_mutableStateArray_0[0].write(3, project_value_15);
/* 477 */       }
/* 478 */
/* 479 */       if (project_isNull_61) {
/* 480 */         project_mutableStateArray_0[0].setNullAt(4);
/* 481 */       } else {
/* 482 */         project_mutableStateArray_0[0].write(4, project_value_61);
/* 483 */       }
/* 484 */
/* 485 */       if (project_isNull_75) {
/* 486 */         project_mutableStateArray_0[0].setNullAt(5);
/* 487 */       } else {
/* 488 */         project_mutableStateArray_0[0].write(5, project_value_75);
/* 489 */       }
/* 490 */
/* 491 */       if (project_isNull_76) {
/* 492 */         project_mutableStateArray_0[0].setNullAt(6);
/* 493 */       } else {
/* 494 */         project_mutableStateArray_0[0].write(6, project_value_76);
/* 495 */       }
/* 496 */       append((project_mutableStateArray_0[0].getRow()));
/* 497 */       if (shouldStop()) return;
/* 498 */     }
/* 499 */   }
/* 500 */
/* 501 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 029 */       UTF8String scan_value_0 = scan_isNull_0 ?
/* 030 */       null : (scan_row_0.getUTF8String(0));
/* 031 */       boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 032 */       UTF8String scan_value_2 = scan_isNull_2 ?
/* 033 */       null : (scan_row_0.getUTF8String(2));
/* 034 */       boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 035 */       UTF8String scan_value_3 = scan_isNull_3 ?
/* 036 */       null : (scan_row_0.getUTF8String(3));
/* 037 */
/* 038 */       boolean project_isNull_0 = true;
/* 039 */       UTF8String project_value_0 = null;
/* 040 */       boolean project_isNull_1 = true;
/* 041 */       ArrayData project_value_1 = null;
/* 042 */       Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[1] /* converters */)[0].apply(scan_value_0);
/* 043 */
/* 044 */       UTF8String project_result_0 = null;
/* 045 */       try {
/* 046 */         project_result_0 = (UTF8String)((scala.Function1[]) references[1] /* converters */)[1].apply(((scala.Function1) references[3] /* udf */).apply(project_arg_0));
/* 047 */       } catch (Exception e) {
/* 048 */         throw new org.apache.spark.SparkException(((java.lang.String) references[2] /* errMsg */), e);
/* 049 */       }
/* 050 */
/* 051 */       boolean project_isNull_2 = project_result_0 == null;
/* 052 */       UTF8String project_value_2 = null;
/* 053 */       if (!project_isNull_2) {
/* 054 */         project_value_2 = project_result_0;
/* 055 */       }
/* 056 */       if (!project_isNull_2) {
/* 057 */         project_isNull_1 = false; // resultCode could change nullability.
/* 058 */         project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[4] /* literal */), -1));
/* 059 */
/* 060 */       }
/* 061 */       if (!project_isNull_1) {
/* 062 */         project_isNull_0 = false; // resultCode could change nullability.
/* 063 */
/* 064 */         final int project_index_0 = (int) 0;
/* 065 */         if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 066 */           project_isNull_0 = true;
/* 067 */         } else {
/* 068 */           project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 069 */         }
/* 070 */
/* 071 */       }
/* 072 */       boolean project_isNull_6 = true;
/* 073 */       UTF8String project_value_6 = null;
/* 074 */       boolean project_isNull_7 = true;
/* 075 */       ArrayData project_value_7 = null;
/* 076 */       Object project_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 077 */
/* 078 */       UTF8String project_result_1 = null;
/* 079 */       try {
/* 080 */         project_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(project_arg_1));
/* 081 */       } catch (Exception e) {
/* 082 */         throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 083 */       }
/* 084 */
/* 085 */       boolean project_isNull_8 = project_result_1 == null;
/* 086 */       UTF8String project_value_8 = null;
/* 087 */       if (!project_isNull_8) {
/* 088 */         project_value_8 = project_result_1;
/* 089 */       }
/* 090 */       if (!project_isNull_8) {
/* 091 */         project_isNull_7 = false; // resultCode could change nullability.
/* 092 */         project_value_7 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_8.split(((UTF8String) references[8] /* literal */), -1));
/* 093 */
/* 094 */       }
/* 095 */       if (!project_isNull_7) {
/* 096 */         project_isNull_6 = false; // resultCode could change nullability.
/* 097 */
/* 098 */         final int project_index_1 = (int) 1;
/* 099 */         if (project_index_1 >= project_value_7.numElements() || project_index_1 < 0 || project_value_7.isNullAt(project_index_1)) {
/* 100 */           project_isNull_6 = true;
/* 101 */         } else {
/* 102 */           project_value_6 = project_value_7.getUTF8String(project_index_1);
/* 103 */         }
/* 104 */
/* 105 */       }
/* 106 */       boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 107 */       UTF8String scan_value_1 = scan_isNull_1 ?
/* 108 */       null : (scan_row_0.getUTF8String(1));
/* 109 */
/* 110 */       Object project_arg_2 = scan_isNull_1 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_1);
/* 111 */       Object project_arg_3 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[1].apply(scan_value_0);
/* 112 */
/* 113 */       UTF8String project_result_2 = null;
/* 114 */       try {
/* 115 */         project_result_2 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[2].apply(((scala.Function2) references[11] /* udf */).apply(project_arg_2, project_arg_3));
/* 116 */       } catch (Exception e) {
/* 117 */         throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 118 */       }
/* 119 */
/* 120 */       boolean project_isNull_12 = project_result_2 == null;
/* 121 */       UTF8String project_value_12 = null;
/* 122 */       if (!project_isNull_12) {
/* 123 */         project_value_12 = project_result_2;
/* 124 */       }
/* 125 */       boolean project_isNull_19 = true;
/* 126 */       UTF8String project_value_19 = null;
/* 127 */       boolean project_isNull_23 = scan_isNull_3;
/* 128 */       double project_value_23 = -1.0;
/* 129 */       if (!scan_isNull_3) {
/* 130 */         try {
/* 131 */           project_value_23 = Double.valueOf(scan_value_3.toString());
/* 132 */         } catch (java.lang.NumberFormatException e) {
/* 133 */           project_isNull_23 = true;
/* 134 */         }
/* 135 */       }
/* 136 */       boolean project_value_21 = true;
/* 137 */
/* 138 */       if (!project_isNull_23) {
/* 139 */         boolean project_isNull_26 = scan_isNull_2;
/* 140 */         double project_value_26 = -1.0;
/* 141 */         if (!scan_isNull_2) {
/* 142 */           try {
/* 143 */             project_value_26 = Double.valueOf(scan_value_2.toString());
/* 144 */           } catch (java.lang.NumberFormatException e) {
/* 145 */             project_isNull_26 = true;
/* 146 */           }
/* 147 */         }
/* 148 */         project_value_21 = project_isNull_26;
/* 149 */       }
/* 150 */       boolean project_isNull_20 = false;
/* 151 */       UTF8String project_value_20 = null;
/* 152 */       if (!false && project_value_21) {
/* 153 */         project_isNull_20 = true;
/* 154 */         project_value_20 = ((UTF8String)null);
/* 155 */       } else {
/* 156 */         boolean project_isNull_30 = scan_isNull_3;
/* 157 */         double project_value_30 = -1.0;
/* 158 */         if (!scan_isNull_3) {
/* 159 */           try {
/* 160 */             project_value_30 = Double.valueOf(scan_value_3.toString());
/* 161 */           } catch (java.lang.NumberFormatException e) {
/* 162 */             project_isNull_30 = true;
/* 163 */           }
/* 164 */         }
/* 165 */         boolean project_isNull_32 = scan_isNull_2;
/* 166 */         double project_value_32 = -1.0;
/* 167 */         if (!scan_isNull_2) {
/* 168 */           try {
/* 169 */             project_value_32 = Double.valueOf(scan_value_2.toString());
/* 170 */           } catch (java.lang.NumberFormatException e) {
/* 171 */             project_isNull_32 = true;
/* 172 */           }
/* 173 */         }
/* 174 */         Object project_arg_4 = project_isNull_30 ? null : ((scala.Function1[]) references[12] /* converters */)[0].apply(project_value_30);
/* 175 */         Object project_arg_5 = project_isNull_32 ? null : ((scala.Function1[]) references[12] /* converters */)[1].apply(project_value_32);
/* 176 */
/* 177 */         UTF8String project_result_3 = null;
/* 178 */         try {
/* 179 */           project_result_3 = (UTF8String)((scala.Function1[]) references[12] /* converters */)[2].apply(((scala.Function2) references[14] /* udf */).apply(project_arg_4, project_arg_5));
/* 180 */         } catch (Exception e) {
/* 181 */           throw new org.apache.spark.SparkException(((java.lang.String) references[13] /* errMsg */), e);
/* 182 */         }
/* 183 */
/* 184 */         boolean project_isNull_29 = project_result_3 == null;
/* 185 */         UTF8String project_value_29 = null;
/* 186 */         if (!project_isNull_29) {
/* 187 */           project_value_29 = project_result_3;
/* 188 */         }
/* 189 */         project_isNull_20 = project_isNull_29;
/* 190 */         project_value_20 = project_value_29;
/* 191 */       }
/* 192 */       if (!project_isNull_20) {
/* 193 */         project_isNull_19 = false; // resultCode could change nullability.
/* 194 */         project_value_19 = project_value_20.replace(((UTF8String) references[15] /* literal */), ((UTF8String) references[16] /* literal */));
/* 195 */
/* 196 */       }
/* 197 */       boolean project_isNull_18 = project_isNull_19;
/* 198 */       double project_value_18 = -1.0;
/* 199 */       if (!project_isNull_19) {
/* 200 */         try {
/* 201 */           project_value_18 = Double.valueOf(project_value_19.toString());
/* 202 */         } catch (java.lang.NumberFormatException e) {
/* 203 */           project_isNull_18 = true;
/* 204 */         }
/* 205 */       }
/* 206 */       boolean project_value_16 = true;
/* 207 */
/* 208 */       if (!project_isNull_18) {
/* 209 */         UTF8String project_result_4 = null;
/* 210 */         try {
/* 211 */           project_result_4 = (UTF8String)((scala.Function1[]) references[17] /* converters */)[0].apply(((scala.Function0) references[19] /* udf */).apply());
/* 212 */         } catch (Exception e) {
/* 213 */           throw new org.apache.spark.SparkException(((java.lang.String) references[18] /* errMsg */), e);
/* 214 */         }
/* 215 */
/* 216 */         boolean project_isNull_38 = project_result_4 == null;
/* 217 */         UTF8String project_value_38 = null;
/* 218 */         if (!project_isNull_38) {
/* 219 */           project_value_38 = project_result_4;
/* 220 */         }
/* 221 */         boolean project_isNull_37 = project_isNull_38;
/* 222 */         int project_value_37 = -1;
/* 223 */         if (!project_isNull_38) {
/* 224 */           UTF8String.IntWrapper project_intWrapper_0 = new UTF8String.IntWrapper();
/* 225 */           if (project_value_38.toInt(project_intWrapper_0)) {
/* 226 */             project_value_37 = project_intWrapper_0.value;
/* 227 */           } else {
/* 228 */             project_isNull_37 = true;
/* 229 */           }
/* 230 */           project_intWrapper_0 = null;
/* 231 */         }
/* 232 */         project_value_16 = project_isNull_37;
/* 233 */       }
/* 234 */       boolean project_isNull_15 = false;
/* 235 */       UTF8String project_value_15 = null;
/* 236 */       if (!false && project_value_16) {
/* 237 */         project_isNull_15 = true;
/* 238 */         project_value_15 = ((UTF8String)null);
/* 239 */       } else {
/* 240 */         boolean project_isNull_42 = true;
/* 241 */         UTF8String project_value_42 = null;
/* 242 */         boolean project_isNull_46 = scan_isNull_3;
/* 243 */         double project_value_46 = -1.0;
/* 244 */         if (!scan_isNull_3) {
/* 245 */           try {
/* 246 */             project_value_46 = Double.valueOf(scan_value_3.toString());
/* 247 */           } catch (java.lang.NumberFormatException e) {
/* 248 */             project_isNull_46 = true;
/* 249 */           }
/* 250 */         }
/* 251 */         boolean project_value_44 = true;
/* 252 */
/* 253 */         if (!project_isNull_46) {
/* 254 */           boolean project_isNull_49 = scan_isNull_2;
/* 255 */           double project_value_49 = -1.0;
/* 256 */           if (!scan_isNull_2) {
/* 257 */             try {
/* 258 */               project_value_49 = Double.valueOf(scan_value_2.toString());
/* 259 */             } catch (java.lang.NumberFormatException e) {
/* 260 */               project_isNull_49 = true;
/* 261 */             }
/* 262 */           }
/* 263 */           project_value_44 = project_isNull_49;
/* 264 */         }
/* 265 */         boolean project_isNull_43 = false;
/* 266 */         UTF8String project_value_43 = null;
/* 267 */         if (!false && project_value_44) {
/* 268 */           project_isNull_43 = true;
/* 269 */           project_value_43 = ((UTF8String)null);
/* 270 */         } else {
/* 271 */           boolean project_isNull_53 = scan_isNull_3;
/* 272 */           double project_value_53 = -1.0;
/* 273 */           if (!scan_isNull_3) {
/* 274 */             try {
/* 275 */               project_value_53 = Double.valueOf(scan_value_3.toString());
/* 276 */             } catch (java.lang.NumberFormatException e) {
/* 277 */               project_isNull_53 = true;
/* 278 */             }
/* 279 */           }
/* 280 */           boolean project_isNull_55 = scan_isNull_2;
/* 281 */           double project_value_55 = -1.0;
/* 282 */           if (!scan_isNull_2) {
/* 283 */             try {
/* 284 */               project_value_55 = Double.valueOf(scan_value_2.toString());
/* 285 */             } catch (java.lang.NumberFormatException e) {
/* 286 */               project_isNull_55 = true;
/* 287 */             }
/* 288 */           }
/* 289 */           Object project_arg_6 = project_isNull_53 ? null : ((scala.Function1[]) references[22] /* converters */)[0].apply(project_value_53);
/* 290 */           Object project_arg_7 = project_isNull_55 ? null : ((scala.Function1[]) references[22] /* converters */)[1].apply(project_value_55);
/* 291 */
/* 292 */           UTF8String project_result_6 = null;
/* 293 */           try {
/* 294 */             project_result_6 = (UTF8String)((scala.Function1[]) references[22] /* converters */)[2].apply(((scala.Function2) references[24] /* udf */).apply(project_arg_6, project_arg_7));
/* 295 */           } catch (Exception e) {
/* 296 */             throw new org.apache.spark.SparkException(((java.lang.String) references[23] /* errMsg */), e);
/* 297 */           }
/* 298 */
/* 299 */           boolean project_isNull_52 = project_result_6 == null;
/* 300 */           UTF8String project_value_52 = null;
/* 301 */           if (!project_isNull_52) {
/* 302 */             project_value_52 = project_result_6;
/* 303 */           }
/* 304 */           project_isNull_43 = project_isNull_52;
/* 305 */           project_value_43 = project_value_52;
/* 306 */         }
/* 307 */         if (!project_isNull_43) {
/* 308 */           project_isNull_42 = false; // resultCode could change nullability.
/* 309 */           project_value_42 = project_value_43.replace(((UTF8String) references[25] /* literal */), ((UTF8String) references[26] /* literal */));
/* 310 */
/* 311 */         }
/* 312 */         boolean project_isNull_41 = project_isNull_42;
/* 313 */         double project_value_41 = -1.0;
/* 314 */         if (!project_isNull_42) {
/* 315 */           try {
/* 316 */             project_value_41 = Double.valueOf(project_value_42.toString());
/* 317 */           } catch (java.lang.NumberFormatException e) {
/* 318 */             project_isNull_41 = true;
/* 319 */           }
/* 320 */         }
/* 321 */         UTF8String project_result_7 = null;
/* 322 */         try {
/* 323 */           project_result_7 = (UTF8String)((scala.Function1[]) references[27] /* converters */)[0].apply(((scala.Function0) references[29] /* udf */).apply());
/* 324 */         } catch (Exception e) {
/* 325 */           throw new org.apache.spark.SparkException(((java.lang.String) references[28] /* errMsg */), e);
/* 326 */         }
/* 327 */
/* 328 */         boolean project_isNull_60 = project_result_7 == null;
/* 329 */         UTF8String project_value_60 = null;
/* 330 */         if (!project_isNull_60) {
/* 331 */           project_value_60 = project_result_7;
/* 332 */         }
/* 333 */         boolean project_isNull_59 = project_isNull_60;
/* 334 */         int project_value_59 = -1;
/* 335 */         if (!project_isNull_60) {
/* 336 */           UTF8String.IntWrapper project_intWrapper_1 = new UTF8String.IntWrapper();
/* 337 */           if (project_value_60.toInt(project_intWrapper_1)) {
/* 338 */             project_value_59 = project_intWrapper_1.value;
/* 339 */           } else {
/* 340 */             project_isNull_59 = true;
/* 341 */           }
/* 342 */           project_intWrapper_1 = null;
/* 343 */         }
/* 344 */         Object project_arg_8 = project_isNull_41 ? null : ((scala.Function1[]) references[20] /* converters */)[0].apply(project_value_41);
/* 345 */         Object project_arg_9 = project_isNull_59 ? null : ((scala.Function1[]) references[20] /* converters */)[1].apply(project_value_59);
/* 346 */
/* 347 */         UTF8String project_result_5 = null;
/* 348 */         try {
/* 349 */           project_result_5 = (UTF8String)((scala.Function1[]) references[20] /* converters */)[2].apply(((scala.Function2) references[30] /* udf */).apply(project_arg_8, project_arg_9));
/* 350 */         } catch (Exception e) {
/* 351 */           throw new org.apache.spark.SparkException(((java.lang.String) references[21] /* errMsg */), e);
/* 352 */         }
/* 353 */
/* 354 */         boolean project_isNull_40 = project_result_5 == null;
/* 355 */         UTF8String project_value_40 = null;
/* 356 */         if (!project_isNull_40) {
/* 357 */           project_value_40 = project_result_5;
/* 358 */         }
/* 359 */         project_isNull_15 = project_isNull_40;
/* 360 */         project_value_15 = project_value_40;
/* 361 */       }
/* 362 */       boolean project_isNull_64 = scan_isNull_3;
/* 363 */       double project_value_64 = -1.0;
/* 364 */       if (!scan_isNull_3) {
/* 365 */         try {
/* 366 */           project_value_64 = Double.valueOf(scan_value_3.toString());
/* 367 */         } catch (java.lang.NumberFormatException e) {
/* 368 */           project_isNull_64 = true;
/* 369 */         }
/* 370 */       }
/* 371 */       boolean project_value_62 = true;
/* 372 */
/* 373 */       if (!project_isNull_64) {
/* 374 */         boolean project_isNull_67 = scan_isNull_2;
/* 375 */         double project_value_67 = -1.0;
/* 376 */         if (!scan_isNull_2) {
/* 377 */           try {
/* 378 */             project_value_67 = Double.valueOf(scan_value_2.toString());
/* 379 */           } catch (java.lang.NumberFormatException e) {
/* 380 */             project_isNull_67 = true;
/* 381 */           }
/* 382 */         }
/* 383 */         project_value_62 = project_isNull_67;
/* 384 */       }
/* 385 */       boolean project_isNull_61 = false;
/* 386 */       UTF8String project_value_61 = null;
/* 387 */       if (!false && project_value_62) {
/* 388 */         project_isNull_61 = true;
/* 389 */         project_value_61 = ((UTF8String)null);
/* 390 */       } else {
/* 391 */         boolean project_isNull_71 = scan_isNull_3;
/* 392 */         double project_value_71 = -1.0;
/* 393 */         if (!scan_isNull_3) {
/* 394 */           try {
/* 395 */             project_value_71 = Double.valueOf(scan_value_3.toString());
/* 396 */           } catch (java.lang.NumberFormatException e) {
/* 397 */             project_isNull_71 = true;
/* 398 */           }
/* 399 */         }
/* 400 */         boolean project_isNull_73 = scan_isNull_2;
/* 401 */         double project_value_73 = -1.0;
/* 402 */         if (!scan_isNull_2) {
/* 403 */           try {
/* 404 */             project_value_73 = Double.valueOf(scan_value_2.toString());
/* 405 */           } catch (java.lang.NumberFormatException e) {
/* 406 */             project_isNull_73 = true;
/* 407 */           }
/* 408 */         }
/* 409 */         Object project_arg_10 = project_isNull_71 ? null : ((scala.Function1[]) references[31] /* converters */)[0].apply(project_value_71);
/* 410 */         Object project_arg_11 = project_isNull_73 ? null : ((scala.Function1[]) references[31] /* converters */)[1].apply(project_value_73);
/* 411 */
/* 412 */         UTF8String project_result_8 = null;
/* 413 */         try {
/* 414 */           project_result_8 = (UTF8String)((scala.Function1[]) references[31] /* converters */)[2].apply(((scala.Function2) references[33] /* udf */).apply(project_arg_10, project_arg_11));
/* 415 */         } catch (Exception e) {
/* 416 */           throw new org.apache.spark.SparkException(((java.lang.String) references[32] /* errMsg */), e);
/* 417 */         }
/* 418 */
/* 419 */         boolean project_isNull_70 = project_result_8 == null;
/* 420 */         UTF8String project_value_70 = null;
/* 421 */         if (!project_isNull_70) {
/* 422 */           project_value_70 = project_result_8;
/* 423 */         }
/* 424 */         project_isNull_61 = project_isNull_70;
/* 425 */         project_value_61 = project_value_70;
/* 426 */       }
/* 427 */       UTF8String project_result_9 = null;
/* 428 */       try {
/* 429 */         project_result_9 = (UTF8String)((scala.Function1[]) references[34] /* converters */)[0].apply(((scala.Function0) references[36] /* udf */).apply());
/* 430 */       } catch (Exception e) {
/* 431 */         throw new org.apache.spark.SparkException(((java.lang.String) references[35] /* errMsg */), e);
/* 432 */       }
/* 433 */
/* 434 */       boolean project_isNull_75 = project_result_9 == null;
/* 435 */       UTF8String project_value_75 = null;
/* 436 */       if (!project_isNull_75) {
/* 437 */         project_value_75 = project_result_9;
/* 438 */       }
/* 439 */       UTF8String project_result_10 = null;
/* 440 */       try {
/* 441 */         project_result_10 = (UTF8String)((scala.Function1[]) references[37] /* converters */)[0].apply(((scala.Function0) references[39] /* udf */).apply());
/* 442 */       } catch (Exception e) {
/* 443 */         throw new org.apache.spark.SparkException(((java.lang.String) references[38] /* errMsg */), e);
/* 444 */       }
/* 445 */
/* 446 */       boolean project_isNull_76 = project_result_10 == null;
/* 447 */       UTF8String project_value_76 = null;
/* 448 */       if (!project_isNull_76) {
/* 449 */         project_value_76 = project_result_10;
/* 450 */       }
/* 451 */       project_mutableStateArray_0[0].reset();
/* 452 */
/* 453 */       project_mutableStateArray_0[0].zeroOutNullBytes();
/* 454 */
/* 455 */       if (project_isNull_0) {
/* 456 */         project_mutableStateArray_0[0].setNullAt(0);
/* 457 */       } else {
/* 458 */         project_mutableStateArray_0[0].write(0, project_value_0);
/* 459 */       }
/* 460 */
/* 461 */       if (project_isNull_6) {
/* 462 */         project_mutableStateArray_0[0].setNullAt(1);
/* 463 */       } else {
/* 464 */         project_mutableStateArray_0[0].write(1, project_value_6);
/* 465 */       }
/* 466 */
/* 467 */       if (project_isNull_12) {
/* 468 */         project_mutableStateArray_0[0].setNullAt(2);
/* 469 */       } else {
/* 470 */         project_mutableStateArray_0[0].write(2, project_value_12);
/* 471 */       }
/* 472 */
/* 473 */       if (project_isNull_15) {
/* 474 */         project_mutableStateArray_0[0].setNullAt(3);
/* 475 */       } else {
/* 476 */         project_mutableStateArray_0[0].write(3, project_value_15);
/* 477 */       }
/* 478 */
/* 479 */       if (project_isNull_61) {
/* 480 */         project_mutableStateArray_0[0].setNullAt(4);
/* 481 */       } else {
/* 482 */         project_mutableStateArray_0[0].write(4, project_value_61);
/* 483 */       }
/* 484 */
/* 485 */       if (project_isNull_75) {
/* 486 */         project_mutableStateArray_0[0].setNullAt(5);
/* 487 */       } else {
/* 488 */         project_mutableStateArray_0[0].write(5, project_value_75);
/* 489 */       }
/* 490 */
/* 491 */       if (project_isNull_76) {
/* 492 */         project_mutableStateArray_0[0].setNullAt(6);
/* 493 */       } else {
/* 494 */         project_mutableStateArray_0[0].write(6, project_value_76);
/* 495 */       }
/* 496 */       append((project_mutableStateArray_0[0].getRow()));
/* 497 */       if (shouldStop()) return;
/* 498 */     }
/* 499 */   }
/* 500 */
/* 501 */ }

Code generated in 68.091628 ms
Block broadcast_3 stored as values in memory (estimated size 242.9 KB, free 1987.3 MB)
Put block broadcast_3 locally took  0 ms
Putting block broadcast_3 without replication took  0 ms
Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.2 MB)
Added broadcast_3_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_3_piece0
Told master about block broadcast_3_piece0
Put block broadcast_3_piece0 locally took  0 ms
Putting block broadcast_3_piece0 without replication took  0 ms
Created broadcast 3 from show at Run.scala:48
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$1
 +++ Lambda closure ($anonfun$executeTake$1) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$2
 +++ Lambda closure ($anonfun$executeTake$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: show at Run.scala:48
Got job 1 (show at Run.scala:48) with 1 output partitions
Final stage: ResultStage 1 (show at Run.scala:48)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 1)
missing: List()
Submitting ResultStage 1 (MapPartitionsRDD[12] at show at Run.scala:48), which has no missing parents
submitMissingTasks(ResultStage 1)
Block broadcast_4 stored as values in memory (estimated size 32.0 KB, free 1987.2 MB)
Put block broadcast_4 locally took  0 ms
Putting block broadcast_4 without replication took  0 ms
Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.0 KB, free 1987.2 MB)
Added broadcast_4_piece0 in memory on 192.168.1.13:20571 (size: 12.0 KB, free: 1987.5 MB)
Updated info of block broadcast_4_piece0
Told master about block broadcast_4_piece0
Put block broadcast_4_piece0 locally took  0 ms
Putting block broadcast_4_piece0 without replication took  0 ms
Created broadcast 4 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at show at Run.scala:48) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks
Epoch for TaskSet 1.0: 0
Valid locality levels for TaskSet 1.0: NO_PREF, ANY
parentName: , name: TaskSet_1.0, runningTasks: 0
Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 1.0 (TID 1)
Getting local block broadcast_4
Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Code generated in 9.256293 ms
Getting local block broadcast_3
Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 0.0 in stage 1.0 (TID 1). 1967 bytes result sent to driver
parentName: , name: TaskSet_1.0, runningTasks: 0
Finished task 0.0 in stage 1.0 (TID 1) in 110 ms on localhost (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at Run.scala:48) finished in 0.141 s
After removal of stage 1, remaining stages = 0
Job 1 finished: show at Run.scala:48, took 0.132749 s
Writing CSV files at src/main/resources/emulatedData with saveMode=Overwrite

=== Result of Batch Finish Analysis ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]                                                                                                                                InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                        +- Repartition 1, true
    +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]      +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!      +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                     +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!         +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]                                                                                                                                InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                        +- Repartition 1, true
!   +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]      +- Project [split(UDF(location#10), [|])[0] AS location#20, split(UDF(location#10), [|])[1] AS position#21, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double)) || isnull(cast(UDF() as int)))) null else UDF(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double), cast(UDF() as int)) AS conditions#23, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24, UDF() AS pressure#25, UDF() AS humidity#26]
!      +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                           
          
Pruning directories with: 
Post-Scan Filters: 
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 
Creating committer org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol; job da5dc44b-a67c-4cd3-8338-8f501bae5938; output=file:/D:/p1/weather-simulator/src/main/resources/emulatedData; dynamic=false
Using (String, String, Boolean) constructor
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 029 */       UTF8String scan_value_0 = scan_isNull_0 ?
/* 030 */       null : (scan_row_0.getUTF8String(0));
/* 031 */       boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 032 */       UTF8String scan_value_2 = scan_isNull_2 ?
/* 033 */       null : (scan_row_0.getUTF8String(2));
/* 034 */       boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 035 */       UTF8String scan_value_3 = scan_isNull_3 ?
/* 036 */       null : (scan_row_0.getUTF8String(3));
/* 037 */
/* 038 */       boolean project_isNull_0 = true;
/* 039 */       UTF8String project_value_0 = null;
/* 040 */       boolean project_isNull_1 = true;
/* 041 */       ArrayData project_value_1 = null;
/* 042 */       Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[1] /* converters */)[0].apply(scan_value_0);
/* 043 */
/* 044 */       UTF8String project_result_0 = null;
/* 045 */       try {
/* 046 */         project_result_0 = (UTF8String)((scala.Function1[]) references[1] /* converters */)[1].apply(((scala.Function1) references[3] /* udf */).apply(project_arg_0));
/* 047 */       } catch (Exception e) {
/* 048 */         throw new org.apache.spark.SparkException(((java.lang.String) references[2] /* errMsg */), e);
/* 049 */       }
/* 050 */
/* 051 */       boolean project_isNull_2 = project_result_0 == null;
/* 052 */       UTF8String project_value_2 = null;
/* 053 */       if (!project_isNull_2) {
/* 054 */         project_value_2 = project_result_0;
/* 055 */       }
/* 056 */       if (!project_isNull_2) {
/* 057 */         project_isNull_1 = false; // resultCode could change nullability.
/* 058 */         project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[4] /* literal */), -1));
/* 059 */
/* 060 */       }
/* 061 */       if (!project_isNull_1) {
/* 062 */         project_isNull_0 = false; // resultCode could change nullability.
/* 063 */
/* 064 */         final int project_index_0 = (int) 0;
/* 065 */         if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 066 */           project_isNull_0 = true;
/* 067 */         } else {
/* 068 */           project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 069 */         }
/* 070 */
/* 071 */       }
/* 072 */       boolean project_isNull_6 = true;
/* 073 */       UTF8String project_value_6 = null;
/* 074 */       boolean project_isNull_7 = true;
/* 075 */       ArrayData project_value_7 = null;
/* 076 */       Object project_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 077 */
/* 078 */       UTF8String project_result_1 = null;
/* 079 */       try {
/* 080 */         project_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(project_arg_1));
/* 081 */       } catch (Exception e) {
/* 082 */         throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 083 */       }
/* 084 */
/* 085 */       boolean project_isNull_8 = project_result_1 == null;
/* 086 */       UTF8String project_value_8 = null;
/* 087 */       if (!project_isNull_8) {
/* 088 */         project_value_8 = project_result_1;
/* 089 */       }
/* 090 */       if (!project_isNull_8) {
/* 091 */         project_isNull_7 = false; // resultCode could change nullability.
/* 092 */         project_value_7 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_8.split(((UTF8String) references[8] /* literal */), -1));
/* 093 */
/* 094 */       }
/* 095 */       if (!project_isNull_7) {
/* 096 */         project_isNull_6 = false; // resultCode could change nullability.
/* 097 */
/* 098 */         final int project_index_1 = (int) 1;
/* 099 */         if (project_index_1 >= project_value_7.numElements() || project_index_1 < 0 || project_value_7.isNullAt(project_index_1)) {
/* 100 */           project_isNull_6 = true;
/* 101 */         } else {
/* 102 */           project_value_6 = project_value_7.getUTF8String(project_index_1);
/* 103 */         }
/* 104 */
/* 105 */       }
/* 106 */       boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 107 */       UTF8String scan_value_1 = scan_isNull_1 ?
/* 108 */       null : (scan_row_0.getUTF8String(1));
/* 109 */
/* 110 */       Object project_arg_2 = scan_isNull_1 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_1);
/* 111 */       Object project_arg_3 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[1].apply(scan_value_0);
/* 112 */
/* 113 */       UTF8String project_result_2 = null;
/* 114 */       try {
/* 115 */         project_result_2 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[2].apply(((scala.Function2) references[11] /* udf */).apply(project_arg_2, project_arg_3));
/* 116 */       } catch (Exception e) {
/* 117 */         throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 118 */       }
/* 119 */
/* 120 */       boolean project_isNull_12 = project_result_2 == null;
/* 121 */       UTF8String project_value_12 = null;
/* 122 */       if (!project_isNull_12) {
/* 123 */         project_value_12 = project_result_2;
/* 124 */       }
/* 125 */       boolean project_isNull_19 = true;
/* 126 */       UTF8String project_value_19 = null;
/* 127 */       boolean project_isNull_23 = scan_isNull_3;
/* 128 */       double project_value_23 = -1.0;
/* 129 */       if (!scan_isNull_3) {
/* 130 */         try {
/* 131 */           project_value_23 = Double.valueOf(scan_value_3.toString());
/* 132 */         } catch (java.lang.NumberFormatException e) {
/* 133 */           project_isNull_23 = true;
/* 134 */         }
/* 135 */       }
/* 136 */       boolean project_value_21 = true;
/* 137 */
/* 138 */       if (!project_isNull_23) {
/* 139 */         boolean project_isNull_26 = scan_isNull_2;
/* 140 */         double project_value_26 = -1.0;
/* 141 */         if (!scan_isNull_2) {
/* 142 */           try {
/* 143 */             project_value_26 = Double.valueOf(scan_value_2.toString());
/* 144 */           } catch (java.lang.NumberFormatException e) {
/* 145 */             project_isNull_26 = true;
/* 146 */           }
/* 147 */         }
/* 148 */         project_value_21 = project_isNull_26;
/* 149 */       }
/* 150 */       boolean project_isNull_20 = false;
/* 151 */       UTF8String project_value_20 = null;
/* 152 */       if (!false && project_value_21) {
/* 153 */         project_isNull_20 = true;
/* 154 */         project_value_20 = ((UTF8String)null);
/* 155 */       } else {
/* 156 */         boolean project_isNull_30 = scan_isNull_3;
/* 157 */         double project_value_30 = -1.0;
/* 158 */         if (!scan_isNull_3) {
/* 159 */           try {
/* 160 */             project_value_30 = Double.valueOf(scan_value_3.toString());
/* 161 */           } catch (java.lang.NumberFormatException e) {
/* 162 */             project_isNull_30 = true;
/* 163 */           }
/* 164 */         }
/* 165 */         boolean project_isNull_32 = scan_isNull_2;
/* 166 */         double project_value_32 = -1.0;
/* 167 */         if (!scan_isNull_2) {
/* 168 */           try {
/* 169 */             project_value_32 = Double.valueOf(scan_value_2.toString());
/* 170 */           } catch (java.lang.NumberFormatException e) {
/* 171 */             project_isNull_32 = true;
/* 172 */           }
/* 173 */         }
/* 174 */         Object project_arg_4 = project_isNull_30 ? null : ((scala.Function1[]) references[12] /* converters */)[0].apply(project_value_30);
/* 175 */         Object project_arg_5 = project_isNull_32 ? null : ((scala.Function1[]) references[12] /* converters */)[1].apply(project_value_32);
/* 176 */
/* 177 */         UTF8String project_result_3 = null;
/* 178 */         try {
/* 179 */           project_result_3 = (UTF8String)((scala.Function1[]) references[12] /* converters */)[2].apply(((scala.Function2) references[14] /* udf */).apply(project_arg_4, project_arg_5));
/* 180 */         } catch (Exception e) {
/* 181 */           throw new org.apache.spark.SparkException(((java.lang.String) references[13] /* errMsg */), e);
/* 182 */         }
/* 183 */
/* 184 */         boolean project_isNull_29 = project_result_3 == null;
/* 185 */         UTF8String project_value_29 = null;
/* 186 */         if (!project_isNull_29) {
/* 187 */           project_value_29 = project_result_3;
/* 188 */         }
/* 189 */         project_isNull_20 = project_isNull_29;
/* 190 */         project_value_20 = project_value_29;
/* 191 */       }
/* 192 */       if (!project_isNull_20) {
/* 193 */         project_isNull_19 = false; // resultCode could change nullability.
/* 194 */         project_value_19 = project_value_20.replace(((UTF8String) references[15] /* literal */), ((UTF8String) references[16] /* literal */));
/* 195 */
/* 196 */       }
/* 197 */       boolean project_isNull_18 = project_isNull_19;
/* 198 */       double project_value_18 = -1.0;
/* 199 */       if (!project_isNull_19) {
/* 200 */         try {
/* 201 */           project_value_18 = Double.valueOf(project_value_19.toString());
/* 202 */         } catch (java.lang.NumberFormatException e) {
/* 203 */           project_isNull_18 = true;
/* 204 */         }
/* 205 */       }
/* 206 */       boolean project_value_16 = true;
/* 207 */
/* 208 */       if (!project_isNull_18) {
/* 209 */         UTF8String project_result_4 = null;
/* 210 */         try {
/* 211 */           project_result_4 = (UTF8String)((scala.Function1[]) references[17] /* converters */)[0].apply(((scala.Function0) references[19] /* udf */).apply());
/* 212 */         } catch (Exception e) {
/* 213 */           throw new org.apache.spark.SparkException(((java.lang.String) references[18] /* errMsg */), e);
/* 214 */         }
/* 215 */
/* 216 */         boolean project_isNull_38 = project_result_4 == null;
/* 217 */         UTF8String project_value_38 = null;
/* 218 */         if (!project_isNull_38) {
/* 219 */           project_value_38 = project_result_4;
/* 220 */         }
/* 221 */         boolean project_isNull_37 = project_isNull_38;
/* 222 */         int project_value_37 = -1;
/* 223 */         if (!project_isNull_38) {
/* 224 */           UTF8String.IntWrapper project_intWrapper_0 = new UTF8String.IntWrapper();
/* 225 */           if (project_value_38.toInt(project_intWrapper_0)) {
/* 226 */             project_value_37 = project_intWrapper_0.value;
/* 227 */           } else {
/* 228 */             project_isNull_37 = true;
/* 229 */           }
/* 230 */           project_intWrapper_0 = null;
/* 231 */         }
/* 232 */         project_value_16 = project_isNull_37;
/* 233 */       }
/* 234 */       boolean project_isNull_15 = false;
/* 235 */       UTF8String project_value_15 = null;
/* 236 */       if (!false && project_value_16) {
/* 237 */         project_isNull_15 = true;
/* 238 */         project_value_15 = ((UTF8String)null);
/* 239 */       } else {
/* 240 */         boolean project_isNull_42 = true;
/* 241 */         UTF8String project_value_42 = null;
/* 242 */         boolean project_isNull_46 = scan_isNull_3;
/* 243 */         double project_value_46 = -1.0;
/* 244 */         if (!scan_isNull_3) {
/* 245 */           try {
/* 246 */             project_value_46 = Double.valueOf(scan_value_3.toString());
/* 247 */           } catch (java.lang.NumberFormatException e) {
/* 248 */             project_isNull_46 = true;
/* 249 */           }
/* 250 */         }
/* 251 */         boolean project_value_44 = true;
/* 252 */
/* 253 */         if (!project_isNull_46) {
/* 254 */           boolean project_isNull_49 = scan_isNull_2;
/* 255 */           double project_value_49 = -1.0;
/* 256 */           if (!scan_isNull_2) {
/* 257 */             try {
/* 258 */               project_value_49 = Double.valueOf(scan_value_2.toString());
/* 259 */             } catch (java.lang.NumberFormatException e) {
/* 260 */               project_isNull_49 = true;
/* 261 */             }
/* 262 */           }
/* 263 */           project_value_44 = project_isNull_49;
/* 264 */         }
/* 265 */         boolean project_isNull_43 = false;
/* 266 */         UTF8String project_value_43 = null;
/* 267 */         if (!false && project_value_44) {
/* 268 */           project_isNull_43 = true;
/* 269 */           project_value_43 = ((UTF8String)null);
/* 270 */         } else {
/* 271 */           boolean project_isNull_53 = scan_isNull_3;
/* 272 */           double project_value_53 = -1.0;
/* 273 */           if (!scan_isNull_3) {
/* 274 */             try {
/* 275 */               project_value_53 = Double.valueOf(scan_value_3.toString());
/* 276 */             } catch (java.lang.NumberFormatException e) {
/* 277 */               project_isNull_53 = true;
/* 278 */             }
/* 279 */           }
/* 280 */           boolean project_isNull_55 = scan_isNull_2;
/* 281 */           double project_value_55 = -1.0;
/* 282 */           if (!scan_isNull_2) {
/* 283 */             try {
/* 284 */               project_value_55 = Double.valueOf(scan_value_2.toString());
/* 285 */             } catch (java.lang.NumberFormatException e) {
/* 286 */               project_isNull_55 = true;
/* 287 */             }
/* 288 */           }
/* 289 */           Object project_arg_6 = project_isNull_53 ? null : ((scala.Function1[]) references[22] /* converters */)[0].apply(project_value_53);
/* 290 */           Object project_arg_7 = project_isNull_55 ? null : ((scala.Function1[]) references[22] /* converters */)[1].apply(project_value_55);
/* 291 */
/* 292 */           UTF8String project_result_6 = null;
/* 293 */           try {
/* 294 */             project_result_6 = (UTF8String)((scala.Function1[]) references[22] /* converters */)[2].apply(((scala.Function2) references[24] /* udf */).apply(project_arg_6, project_arg_7));
/* 295 */           } catch (Exception e) {
/* 296 */             throw new org.apache.spark.SparkException(((java.lang.String) references[23] /* errMsg */), e);
/* 297 */           }
/* 298 */
/* 299 */           boolean project_isNull_52 = project_result_6 == null;
/* 300 */           UTF8String project_value_52 = null;
/* 301 */           if (!project_isNull_52) {
/* 302 */             project_value_52 = project_result_6;
/* 303 */           }
/* 304 */           project_isNull_43 = project_isNull_52;
/* 305 */           project_value_43 = project_value_52;
/* 306 */         }
/* 307 */         if (!project_isNull_43) {
/* 308 */           project_isNull_42 = false; // resultCode could change nullability.
/* 309 */           project_value_42 = project_value_43.replace(((UTF8String) references[25] /* literal */), ((UTF8String) references[26] /* literal */));
/* 310 */
/* 311 */         }
/* 312 */         boolean project_isNull_41 = project_isNull_42;
/* 313 */         double project_value_41 = -1.0;
/* 314 */         if (!project_isNull_42) {
/* 315 */           try {
/* 316 */             project_value_41 = Double.valueOf(project_value_42.toString());
/* 317 */           } catch (java.lang.NumberFormatException e) {
/* 318 */             project_isNull_41 = true;
/* 319 */           }
/* 320 */         }
/* 321 */         UTF8String project_result_7 = null;
/* 322 */         try {
/* 323 */           project_result_7 = (UTF8String)((scala.Function1[]) references[27] /* converters */)[0].apply(((scala.Function0) references[29] /* udf */).apply());
/* 324 */         } catch (Exception e) {
/* 325 */           throw new org.apache.spark.SparkException(((java.lang.String) references[28] /* errMsg */), e);
/* 326 */         }
/* 327 */
/* 328 */         boolean project_isNull_60 = project_result_7 == null;
/* 329 */         UTF8String project_value_60 = null;
/* 330 */         if (!project_isNull_60) {
/* 331 */           project_value_60 = project_result_7;
/* 332 */         }
/* 333 */         boolean project_isNull_59 = project_isNull_60;
/* 334 */         int project_value_59 = -1;
/* 335 */         if (!project_isNull_60) {
/* 336 */           UTF8String.IntWrapper project_intWrapper_1 = new UTF8String.IntWrapper();
/* 337 */           if (project_value_60.toInt(project_intWrapper_1)) {
/* 338 */             project_value_59 = project_intWrapper_1.value;
/* 339 */           } else {
/* 340 */             project_isNull_59 = true;
/* 341 */           }
/* 342 */           project_intWrapper_1 = null;
/* 343 */         }
/* 344 */         Object project_arg_8 = project_isNull_41 ? null : ((scala.Function1[]) references[20] /* converters */)[0].apply(project_value_41);
/* 345 */         Object project_arg_9 = project_isNull_59 ? null : ((scala.Function1[]) references[20] /* converters */)[1].apply(project_value_59);
/* 346 */
/* 347 */         UTF8String project_result_5 = null;
/* 348 */         try {
/* 349 */           project_result_5 = (UTF8String)((scala.Function1[]) references[20] /* converters */)[2].apply(((scala.Function2) references[30] /* udf */).apply(project_arg_8, project_arg_9));
/* 350 */         } catch (Exception e) {
/* 351 */           throw new org.apache.spark.SparkException(((java.lang.String) references[21] /* errMsg */), e);
/* 352 */         }
/* 353 */
/* 354 */         boolean project_isNull_40 = project_result_5 == null;
/* 355 */         UTF8String project_value_40 = null;
/* 356 */         if (!project_isNull_40) {
/* 357 */           project_value_40 = project_result_5;
/* 358 */         }
/* 359 */         project_isNull_15 = project_isNull_40;
/* 360 */         project_value_15 = project_value_40;
/* 361 */       }
/* 362 */       boolean project_isNull_64 = scan_isNull_3;
/* 363 */       double project_value_64 = -1.0;
/* 364 */       if (!scan_isNull_3) {
/* 365 */         try {
/* 366 */           project_value_64 = Double.valueOf(scan_value_3.toString());
/* 367 */         } catch (java.lang.NumberFormatException e) {
/* 368 */           project_isNull_64 = true;
/* 369 */         }
/* 370 */       }
/* 371 */       boolean project_value_62 = true;
/* 372 */
/* 373 */       if (!project_isNull_64) {
/* 374 */         boolean project_isNull_67 = scan_isNull_2;
/* 375 */         double project_value_67 = -1.0;
/* 376 */         if (!scan_isNull_2) {
/* 377 */           try {
/* 378 */             project_value_67 = Double.valueOf(scan_value_2.toString());
/* 379 */           } catch (java.lang.NumberFormatException e) {
/* 380 */             project_isNull_67 = true;
/* 381 */           }
/* 382 */         }
/* 383 */         project_value_62 = project_isNull_67;
/* 384 */       }
/* 385 */       boolean project_isNull_61 = false;
/* 386 */       UTF8String project_value_61 = null;
/* 387 */       if (!false && project_value_62) {
/* 388 */         project_isNull_61 = true;
/* 389 */         project_value_61 = ((UTF8String)null);
/* 390 */       } else {
/* 391 */         boolean project_isNull_71 = scan_isNull_3;
/* 392 */         double project_value_71 = -1.0;
/* 393 */         if (!scan_isNull_3) {
/* 394 */           try {
/* 395 */             project_value_71 = Double.valueOf(scan_value_3.toString());
/* 396 */           } catch (java.lang.NumberFormatException e) {
/* 397 */             project_isNull_71 = true;
/* 398 */           }
/* 399 */         }
/* 400 */         boolean project_isNull_73 = scan_isNull_2;
/* 401 */         double project_value_73 = -1.0;
/* 402 */         if (!scan_isNull_2) {
/* 403 */           try {
/* 404 */             project_value_73 = Double.valueOf(scan_value_2.toString());
/* 405 */           } catch (java.lang.NumberFormatException e) {
/* 406 */             project_isNull_73 = true;
/* 407 */           }
/* 408 */         }
/* 409 */         Object project_arg_10 = project_isNull_71 ? null : ((scala.Function1[]) references[31] /* converters */)[0].apply(project_value_71);
/* 410 */         Object project_arg_11 = project_isNull_73 ? null : ((scala.Function1[]) references[31] /* converters */)[1].apply(project_value_73);
/* 411 */
/* 412 */         UTF8String project_result_8 = null;
/* 413 */         try {
/* 414 */           project_result_8 = (UTF8String)((scala.Function1[]) references[31] /* converters */)[2].apply(((scala.Function2) references[33] /* udf */).apply(project_arg_10, project_arg_11));
/* 415 */         } catch (Exception e) {
/* 416 */           throw new org.apache.spark.SparkException(((java.lang.String) references[32] /* errMsg */), e);
/* 417 */         }
/* 418 */
/* 419 */         boolean project_isNull_70 = project_result_8 == null;
/* 420 */         UTF8String project_value_70 = null;
/* 421 */         if (!project_isNull_70) {
/* 422 */           project_value_70 = project_result_8;
/* 423 */         }
/* 424 */         project_isNull_61 = project_isNull_70;
/* 425 */         project_value_61 = project_value_70;
/* 426 */       }
/* 427 */       UTF8String project_result_9 = null;
/* 428 */       try {
/* 429 */         project_result_9 = (UTF8String)((scala.Function1[]) references[34] /* converters */)[0].apply(((scala.Function0) references[36] /* udf */).apply());
/* 430 */       } catch (Exception e) {
/* 431 */         throw new org.apache.spark.SparkException(((java.lang.String) references[35] /* errMsg */), e);
/* 432 */       }
/* 433 */
/* 434 */       boolean project_isNull_75 = project_result_9 == null;
/* 435 */       UTF8String project_value_75 = null;
/* 436 */       if (!project_isNull_75) {
/* 437 */         project_value_75 = project_result_9;
/* 438 */       }
/* 439 */       UTF8String project_result_10 = null;
/* 440 */       try {
/* 441 */         project_result_10 = (UTF8String)((scala.Function1[]) references[37] /* converters */)[0].apply(((scala.Function0) references[39] /* udf */).apply());
/* 442 */       } catch (Exception e) {
/* 443 */         throw new org.apache.spark.SparkException(((java.lang.String) references[38] /* errMsg */), e);
/* 444 */       }
/* 445 */
/* 446 */       boolean project_isNull_76 = project_result_10 == null;
/* 447 */       UTF8String project_value_76 = null;
/* 448 */       if (!project_isNull_76) {
/* 449 */         project_value_76 = project_result_10;
/* 450 */       }
/* 451 */       project_mutableStateArray_0[0].reset();
/* 452 */
/* 453 */       project_mutableStateArray_0[0].zeroOutNullBytes();
/* 454 */
/* 455 */       if (project_isNull_0) {
/* 456 */         project_mutableStateArray_0[0].setNullAt(0);
/* 457 */       } else {
/* 458 */         project_mutableStateArray_0[0].write(0, project_value_0);
/* 459 */       }
/* 460 */
/* 461 */       if (project_isNull_6) {
/* 462 */         project_mutableStateArray_0[0].setNullAt(1);
/* 463 */       } else {
/* 464 */         project_mutableStateArray_0[0].write(1, project_value_6);
/* 465 */       }
/* 466 */
/* 467 */       if (project_isNull_12) {
/* 468 */         project_mutableStateArray_0[0].setNullAt(2);
/* 469 */       } else {
/* 470 */         project_mutableStateArray_0[0].write(2, project_value_12);
/* 471 */       }
/* 472 */
/* 473 */       if (project_isNull_15) {
/* 474 */         project_mutableStateArray_0[0].setNullAt(3);
/* 475 */       } else {
/* 476 */         project_mutableStateArray_0[0].write(3, project_value_15);
/* 477 */       }
/* 478 */
/* 479 */       if (project_isNull_61) {
/* 480 */         project_mutableStateArray_0[0].setNullAt(4);
/* 481 */       } else {
/* 482 */         project_mutableStateArray_0[0].write(4, project_value_61);
/* 483 */       }
/* 484 */
/* 485 */       if (project_isNull_75) {
/* 486 */         project_mutableStateArray_0[0].setNullAt(5);
/* 487 */       } else {
/* 488 */         project_mutableStateArray_0[0].write(5, project_value_75);
/* 489 */       }
/* 490 */
/* 491 */       if (project_isNull_76) {
/* 492 */         project_mutableStateArray_0[0].setNullAt(6);
/* 493 */       } else {
/* 494 */         project_mutableStateArray_0[0].write(6, project_value_76);
/* 495 */       }
/* 496 */       append((project_mutableStateArray_0[0].getRow()));
/* 497 */       if (shouldStop()) return;
/* 498 */     }
/* 499 */   }
/* 500 */
/* 501 */ }

Block broadcast_5 stored as values in memory (estimated size 242.9 KB, free 1987.0 MB)
Put block broadcast_5 locally took  0 ms
Putting block broadcast_5 without replication took  0 ms
Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1986.9 MB)
Added broadcast_5_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_5_piece0
Told master about block broadcast_5_piece0
Put block broadcast_5_piece0 locally took  16 ms
Putting block broadcast_5_piece0 without replication took  16 ms
Created broadcast 5 from csv at SparkUtiles.scala:37
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$write$15
 +++ Lambda closure ($anonfun$write$15) is now cleaned +++
Starting job: csv at SparkUtiles.scala:37
Registering RDD 15 (csv at SparkUtiles.scala:37)
Got job 2 (csv at SparkUtiles.scala:37) with 1 output partitions
Final stage: ResultStage 3 (csv at SparkUtiles.scala:37)
Parents of final stage: List(ShuffleMapStage 2)
Missing parents: List(ShuffleMapStage 2)
submitStage(ResultStage 3)
missing: List(ShuffleMapStage 2)
submitStage(ShuffleMapStage 2)
missing: List()
Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ShuffleMapStage 2)
Block broadcast_6 stored as values in memory (estimated size 33.0 KB, free 1986.9 MB)
Put block broadcast_6 locally took  0 ms
Putting block broadcast_6 without replication took  0 ms
Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.8 KB, free 1986.9 MB)
Added broadcast_6_piece0 in memory on 192.168.1.13:20571 (size: 12.8 KB, free: 1987.4 MB)
Updated info of block broadcast_6_piece0
Told master about block broadcast_6_piece0
Put block broadcast_6_piece0 locally took  0 ms
Putting block broadcast_6_piece0 without replication took  0 ms
Created broadcast 6 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 2.0 with 3 tasks
Epoch for TaskSet 2.0: 0
Valid locality levels for TaskSet 2.0: NO_PREF, ANY
parentName: , name: TaskSet_2.0, runningTasks: 0
Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7820 bytes)
Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7819 bytes)
Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 7817 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 2.0 (TID 2)
Running task 1.0 in stage 2.0 (TID 3)
Running task 2.0 in stage 2.0 (TID 4)
Getting local block broadcast_6
Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_5
Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
Got cleaning task CleanBroadcast(4)
Cleaning broadcast 4
Unpersisting TorrentBroadcast 4
removing broadcast 4
Removing broadcast 4
Removing block broadcast_4_piece0
Block broadcast_4_piece0 of size 12297 dropped from memory (free 2083426588)
Removed broadcast_4_piece0 on 192.168.1.13:20571 in memory (size: 12.0 KB, free: 1987.4 MB)
Updated info of block broadcast_4_piece0
Told master about block broadcast_4_piece0
Removing block broadcast_4
Block broadcast_4 of size 32776 dropped from memory (free 2083459364)
Done removing broadcast 4, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 4
Got cleaning task CleanAccum(38)
Cleaning accumulator 38
Cleaned accumulator 38
Got cleaning task CleanAccum(60)
Cleaning accumulator 60
Cleaned accumulator 60
Got cleaning task CleanAccum(58)
Cleaning accumulator 58
Cleaned accumulator 58
Got cleaning task CleanAccum(66)
Cleaning accumulator 66
Cleaned accumulator 66
Got cleaning task CleanAccum(57)
Cleaning accumulator 57
Cleaned accumulator 57
Got cleaning task CleanAccum(48)
Cleaning accumulator 48
Cleaned accumulator 48
Got cleaning task CleanBroadcast(3)
Cleaning broadcast 3
Unpersisting TorrentBroadcast 3
removing broadcast 3
Removing broadcast 3
Removing block broadcast_3_piece0
Block broadcast_3_piece0 of size 20482 dropped from memory (free 2083479846)
Removed broadcast_3_piece0 on 192.168.1.13:20571 in memory (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_3_piece0
Told master about block broadcast_3_piece0
Removing block broadcast_3
Block broadcast_3 of size 248760 dropped from memory (free 2083728606)
Done removing broadcast 3, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 3
Got cleaning task CleanAccum(63)
Cleaning accumulator 63
Cleaned accumulator 63
Got cleaning task CleanAccum(49)
Cleaning accumulator 49
Cleaned accumulator 49
Got cleaning task CleanAccum(56)
Cleaning accumulator 56
Cleaned accumulator 56
Got cleaning task CleanAccum(52)
Cleaning accumulator 52
Cleaned accumulator 52
Got cleaning task CleanAccum(54)
Cleaning accumulator 54
Cleaned accumulator 54
Got cleaning task CleanAccum(37)
Cleaning accumulator 37
Cleaned accumulator 37
Got cleaning task CleanAccum(45)
Cleaning accumulator 45
Cleaned accumulator 45
Got cleaning task CleanAccum(39)
Cleaning accumulator 39
Cleaned accumulator 39
Got cleaning task CleanAccum(47)
Cleaning accumulator 47
Cleaned accumulator 47
Got cleaning task CleanAccum(36)
Cleaning accumulator 36
Cleaned accumulator 36
Got cleaning task CleanAccum(41)
Cleaning accumulator 41
Cleaned accumulator 41
Got cleaning task CleanAccum(51)
Cleaning accumulator 51
Cleaned accumulator 51
Got cleaning task CleanAccum(64)
Cleaning accumulator 64
Cleaned accumulator 64
Got cleaning task CleanAccum(53)
Cleaning accumulator 53
Cleaned accumulator 53
Got cleaning task CleanAccum(50)
Cleaning accumulator 50
Cleaned accumulator 50
Got cleaning task CleanAccum(42)
Cleaning accumulator 42
Cleaned accumulator 42
Got cleaning task CleanAccum(40)
Cleaning accumulator 40
Cleaned accumulator 40
Got cleaning task CleanAccum(44)
Cleaning accumulator 44
Cleaned accumulator 44
Got cleaning task CleanAccum(65)
Cleaning accumulator 65
Cleaned accumulator 65
Got cleaning task CleanAccum(55)
Cleaning accumulator 55
Cleaned accumulator 55
Got cleaning task CleanAccum(46)
Cleaning accumulator 46
Cleaned accumulator 46
Got cleaning task CleanAccum(59)
Cleaning accumulator 59
Cleaned accumulator 59
Got cleaning task CleanAccum(62)
Cleaning accumulator 62
Cleaned accumulator 62
Got cleaning task CleanAccum(43)
Cleaning accumulator 43
Cleaned accumulator 43
Got cleaning task CleanAccum(61)
Cleaning accumulator 61
Cleaned accumulator 61
Finished task 2.0 in stage 2.0 (TID 4). 1440 bytes result sent to driver
Finished task 1.0 in stage 2.0 (TID 3). 1440 bytes result sent to driver
parentName: , name: TaskSet_2.0, runningTasks: 2
parentName: , name: TaskSet_2.0, runningTasks: 1
Finished task 2.0 in stage 2.0 (TID 4) in 297 ms on localhost (executor driver) (1/3)
Finished task 0.0 in stage 2.0 (TID 2). 1440 bytes result sent to driver
parentName: , name: TaskSet_2.0, runningTasks: 0
ShuffleMapTask finished on driver
Finished task 1.0 in stage 2.0 (TID 3) in 297 ms on localhost (executor driver) (2/3)
Finished task 0.0 in stage 2.0 (TID 2) in 297 ms on localhost (executor driver) (3/3)
Removed TaskSet 2.0, whose tasks have all completed, from pool 
ShuffleMapTask finished on driver
ShuffleMapTask finished on driver
ShuffleMapStage 2 (csv at SparkUtiles.scala:37) finished in 0.312 s
looking for newly runnable stages
running: Set()
waiting: Set(ResultStage 3)
failed: Set()
Increasing epoch to 1
submitStage(ResultStage 3)
missing: List()
Submitting ResultStage 3 (ShuffledRowRDD[16] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ResultStage 3)
Block broadcast_7 stored as values in memory (estimated size 129.6 KB, free 1987.1 MB)
Put block broadcast_7 locally took  0 ms
Putting block broadcast_7 without replication took  0 ms
Block broadcast_7_piece0 stored as bytes in memory (estimated size 45.9 KB, free 1987.0 MB)
Added broadcast_7_piece0 in memory on 192.168.1.13:20571 (size: 45.9 KB, free: 1987.4 MB)
Updated info of block broadcast_7_piece0
Told master about block broadcast_7_piece0
Put block broadcast_7_piece0 locally took  0 ms
Putting block broadcast_7_piece0 without replication took  0 ms
Created broadcast 7 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 3 (ShuffledRowRDD[16] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0))
Adding task set 3.0 with 1 tasks
Epoch for TaskSet 3.0: 1
Valid locality levels for TaskSet 3.0: ANY
parentName: , name: TaskSet_3.0, runningTasks: 0
Starting task 0.0 in stage 3.0 (TID 5, localhost, executor driver, partition 0, ANY, 7246 bytes)
Running task 0.0 in stage 3.0 (TID 5)
Getting local block broadcast_7
Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
Fetching outputs for shuffle 0, partitions 0-1
maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
Getting 3 non-empty blocks including 3 local blocks and 0 remote blocks
Started 0 remote fetches in 0 ms
Start fetching local blocks: shuffle_0_0_0, shuffle_0_1_0, shuffle_0_2_0
Got local blocks in  16 ms
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Got cleaning task CleanBroadcast(6)
Cleaning broadcast 6
Unpersisting TorrentBroadcast 6
removing broadcast 6
Removing broadcast 6
Removing block broadcast_6_piece0
Block broadcast_6_piece0 of size 13136 dropped from memory (free 2083561945)
Removed broadcast_6_piece0 on 192.168.1.13:20571 in memory (size: 12.8 KB, free: 1987.4 MB)
Updated info of block broadcast_6_piece0
Told master about block broadcast_6_piece0
Removing block broadcast_6
Block broadcast_6 of size 33816 dropped from memory (free 2083595761)
Commit allowed for stage=3.0, partition=0, task attempt 0
Done removing broadcast 6, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 6
Saved output of task 'attempt_20190331133204_0003_m_000000_0' to file:/D:/p1/weather-simulator/src/main/resources/emulatedData/_temporary/0/task_20190331133204_0003_m_000000
attempt_20190331133204_0003_m_000000_0: Committed
Finished task 0.0 in stage 3.0 (TID 5). 2301 bytes result sent to driver
parentName: , name: TaskSet_3.0, runningTasks: 0
Finished task 0.0 in stage 3.0 (TID 5) in 281 ms on localhost (executor driver) (1/1)
Removed TaskSet 3.0, whose tasks have all completed, from pool 
ResultStage 3 (csv at SparkUtiles.scala:37) finished in 0.313 s
After removal of stage 2, remaining stages = 1
After removal of stage 3, remaining stages = 0
Job 2 finished: csv at SparkUtiles.scala:37, took 0.648008 s
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/emulatedData/_temporary/0/task_20190331133204_0003_m_000000; isDirectory=true; modification_time=1553999524222; access_time=1553999524222; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/emulatedData
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/emulatedData/_temporary/0/task_20190331133204_0003_m_000000/part-00000-da5dc44b-a67c-4cd3-8338-8f501bae5938-c000.csv; isDirectory=false; length=74853; replication=1; blocksize=33554432; modification_time=1553999524269; access_time=1553999524222; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/emulatedData/part-00000-da5dc44b-a67c-4cd3-8338-8f501bae5938-c000.csv
Committing files staged for absolute locations Map()
Write Job 65763b78-3212-4f74-a76b-2147d3643452 committed.
Finished processing stats for write job 65763b78-3212-4f74-a76b-2147d3643452.
Parsing command: emulated
Parsing command: 
SELECT bs.location,
       bs.monthday,
       bs.maxtemp,
       bs.mintemp,
       Replace(em.temperature, '+', '') AS tempra
FROM   bomstatis AS bs
       JOIN emulated AS em
         ON To_date(bs.monthday) = To_date(em.local_time)
            AND bs.location = em.location
      
Resolving 'bs.monthday to monthday#11
Resolving 'em.local_time to local_time#22
Resolving 'bs.location to location#10
Resolving 'em.location to location#20
Resolving 'bs.location to location#10
Resolving 'bs.monthday to monthday#11
Resolving 'bs.maxtemp to maxtemp#12
Resolving 'bs.mintemp to mintemp#13
Resolving 'em.temperature to temperature#24

=== Result of Batch Resolution ===
!'Project ['bs.location, 'bs.monthday, 'bs.maxtemp, 'bs.mintemp, 'Replace('em.temperature, +, ) AS tempra#76]   Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
!+- 'Join Inner, (('To_date('bs.monthday) = 'To_date('em.local_time)) && ('bs.location = 'em.location))         +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
!   :- 'SubqueryAlias `bs`                                                                                         :- SubqueryAlias `bs`
!   :  +- 'UnresolvedRelation `bomstatis`                                                                          :  +- SubqueryAlias `bomstatis`
!   +- 'SubqueryAlias `em`                                                                                         :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!      +- 'UnresolvedRelation `emulated`                                                                           +- SubqueryAlias `em`
!                                                                                                                     +- SubqueryAlias `emulated`
!                                                                                                                        +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!                                                                                                                           +- SubqueryAlias `outtab`
!                                                                                                                              +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!                                                                                                                                 +- SubqueryAlias `bomstatis`
!                                                                                                                                    +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
 +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                         +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
    :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                               :- SubqueryAlias `bs`
    :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                     :  +- SubqueryAlias `bomstatis`
    :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                    :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
    +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `em`
       +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                         +- SubqueryAlias `emulated`
          +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]            +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
             +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                           +- SubqueryAlias `outtab`
                +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                       +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
                   +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                        +- SubqueryAlias `bomstatis`
                      +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast(location#10 as string), None), unresolvedalias(cast(monthday#11 as string), None), unresolvedalias(cast(maxtemp#12 as string), None), unresolvedalias(cast(mintemp#13 as string), None), unresolvedalias(cast(tempra#76 as string), None)]                                                                                                                                                              Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]
 +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
    +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                            +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
       :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                  :- SubqueryAlias `bs`
       :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                        :  +- SubqueryAlias `bomstatis`
       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
       +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `em`
          +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                            +- SubqueryAlias `emulated`
             +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]               +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
                +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                              +- SubqueryAlias `outtab`
                   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                          +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
                      +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                           +- SubqueryAlias `bomstatis`
                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]                                                                                                                                                                                                           Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]
 +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
    +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                            +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
       :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                  :- SubqueryAlias `bs`
       :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                        :  +- SubqueryAlias `bomstatis`
       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
       +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `em`
          +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                            +- SubqueryAlias `emulated`
             +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]               +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
                +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                              +- SubqueryAlias `outtab`
                   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                          +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
                      +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                           +- SubqueryAlias `bomstatis`
                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Finish Analysis ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                               GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                             +- LocalLimit 21
    +- Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]                                                                                                                                                                                                              +- Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]
       +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                                     +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
!         +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                                  +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!            :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                        :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                              +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!            :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                                +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!            +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                              +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!               +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                   
!                  +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   
!                     +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                               
!                        +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                        
!                           +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!                              +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                         GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                       +- LocalLimit 21
!   +- Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]                                                                                                                                                                                                        +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]
!      +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                              :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!            :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                          :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!               +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!                  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                           
          

=== Result of Batch Infer Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                  GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                +- LocalLimit 21
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]                                                                                                                                                                                        +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :- Filter (isnotnull(monthday#11) && isnotnull(location#10))
!         :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]            :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   +- Filter (isnotnull(local_time#22) && isnotnull(location#20))
!                                                                                                                                                                                                                                                                                                            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!                                                                                                                                                                                                                                                                                                               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Operator Optimization after Inferring Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                     GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                   +- LocalLimit 21
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]                                                                                                                                                                                           +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                          +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Filter (isnotnull(monthday#11) && isnotnull(location#10))                                                                                                                                                                                                                                       :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :  +- Filter (isnotnull(monthday#11) && isnotnull(location#10))
          :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Filter (isnotnull(local_time#22) && isnotnull(location#20))                                                                                                                                                                                                                                     +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]               +- Filter (isnotnull(UDF(monthday#11, location#10)) && isnotnull(split(UDF(location#10), [|])[0]))
                +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Pruning directories with: 
Post-Scan Filters: isnotnull(monthday#11),isnotnull(location#10)
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: IsNotNull(monthday),IsNotNull(location)
Pruning directories with: 
Post-Scan Filters: isnotnull(UDF(monthday#11, location#10)),isnotnull(split(UDF(location#10), [|])[0])
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, getcolumnbyordinal(3, StringType).toString, getcolumnbyordinal(4, StringType).toString, StructField(location,StringType,true), StructField(monthday,StringType,true), StructField(maxtemp,StringType,true), StructField(mintemp,StringType,true), StructField(tempra,StringType,true))), obj#97: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(location#87.toString, monthday#88.toString, maxtemp#89.toString, mintemp#90.toString, tempra#91.toString, StructField(location,StringType,true), StructField(monthday,StringType,true), StructField(maxtemp,StringType,true), StructField(mintemp,StringType,true), StructField(tempra,StringType,true)), obj#97: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [location#87, monthday#88, maxtemp#89, mintemp#90, tempra#91]                                                                                                                                                                                                                                                                                                                                                                                                                                       +- LocalRelation <empty>, [location#87, monthday#88, maxtemp#89, mintemp#90, tempra#91]
          
code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, input[3, string, true].toString, input[4, string, true].toString, StructField(location,StringType,true), StructField(monthday,StringType,true), StructField(maxtemp,StringType,true), StructField(mintemp,StringType,true), StructField(tempra,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[5];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 027 */     if (false) {
/* 028 */       mutableRow.setNullAt(0);
/* 029 */     } else {
/* 030 */
/* 031 */       mutableRow.update(0, value_0);
/* 032 */     }
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */
/* 037 */
/* 038 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 039 */
/* 040 */     boolean isNull_8 = i.isNullAt(3);
/* 041 */     UTF8String value_8 = isNull_8 ?
/* 042 */     null : (i.getUTF8String(3));
/* 043 */     boolean isNull_7 = true;
/* 044 */     java.lang.String value_7 = null;
/* 045 */     if (!isNull_8) {
/* 046 */
/* 047 */       isNull_7 = false;
/* 048 */       if (!isNull_7) {
/* 049 */
/* 050 */         Object funcResult_3 = null;
/* 051 */         funcResult_3 = value_8.toString();
/* 052 */         value_7 = (java.lang.String) funcResult_3;
/* 053 */
/* 054 */       }
/* 055 */     }
/* 056 */     if (isNull_7) {
/* 057 */       values_0[3] = null;
/* 058 */     } else {
/* 059 */       values_0[3] = value_7;
/* 060 */     }
/* 061 */
/* 062 */     boolean isNull_10 = i.isNullAt(4);
/* 063 */     UTF8String value_10 = isNull_10 ?
/* 064 */     null : (i.getUTF8String(4));
/* 065 */     boolean isNull_9 = true;
/* 066 */     java.lang.String value_9 = null;
/* 067 */     if (!isNull_10) {
/* 068 */
/* 069 */       isNull_9 = false;
/* 070 */       if (!isNull_9) {
/* 071 */
/* 072 */         Object funcResult_4 = null;
/* 073 */         funcResult_4 = value_10.toString();
/* 074 */         value_9 = (java.lang.String) funcResult_4;
/* 075 */
/* 076 */       }
/* 077 */     }
/* 078 */     if (isNull_9) {
/* 079 */       values_0[4] = null;
/* 080 */     } else {
/* 081 */       values_0[4] = value_9;
/* 082 */     }
/* 083 */
/* 084 */   }
/* 085 */
/* 086 */
/* 087 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 088 */
/* 089 */     boolean isNull_2 = i.isNullAt(0);
/* 090 */     UTF8String value_2 = isNull_2 ?
/* 091 */     null : (i.getUTF8String(0));
/* 092 */     boolean isNull_1 = true;
/* 093 */     java.lang.String value_1 = null;
/* 094 */     if (!isNull_2) {
/* 095 */
/* 096 */       isNull_1 = false;
/* 097 */       if (!isNull_1) {
/* 098 */
/* 099 */         Object funcResult_0 = null;
/* 100 */         funcResult_0 = value_2.toString();
/* 101 */         value_1 = (java.lang.String) funcResult_0;
/* 102 */
/* 103 */       }
/* 104 */     }
/* 105 */     if (isNull_1) {
/* 106 */       values_0[0] = null;
/* 107 */     } else {
/* 108 */       values_0[0] = value_1;
/* 109 */     }
/* 110 */
/* 111 */     boolean isNull_4 = i.isNullAt(1);
/* 112 */     UTF8String value_4 = isNull_4 ?
/* 113 */     null : (i.getUTF8String(1));
/* 114 */     boolean isNull_3 = true;
/* 115 */     java.lang.String value_3 = null;
/* 116 */     if (!isNull_4) {
/* 117 */
/* 118 */       isNull_3 = false;
/* 119 */       if (!isNull_3) {
/* 120 */
/* 121 */         Object funcResult_1 = null;
/* 122 */         funcResult_1 = value_4.toString();
/* 123 */         value_3 = (java.lang.String) funcResult_1;
/* 124 */
/* 125 */       }
/* 126 */     }
/* 127 */     if (isNull_3) {
/* 128 */       values_0[1] = null;
/* 129 */     } else {
/* 130 */       values_0[1] = value_3;
/* 131 */     }
/* 132 */
/* 133 */     boolean isNull_6 = i.isNullAt(2);
/* 134 */     UTF8String value_6 = isNull_6 ?
/* 135 */     null : (i.getUTF8String(2));
/* 136 */     boolean isNull_5 = true;
/* 137 */     java.lang.String value_5 = null;
/* 138 */     if (!isNull_6) {
/* 139 */
/* 140 */       isNull_5 = false;
/* 141 */       if (!isNull_5) {
/* 142 */
/* 143 */         Object funcResult_2 = null;
/* 144 */         funcResult_2 = value_6.toString();
/* 145 */         value_5 = (java.lang.String) funcResult_2;
/* 146 */
/* 147 */       }
/* 148 */     }
/* 149 */     if (isNull_5) {
/* 150 */       values_0[2] = null;
/* 151 */     } else {
/* 152 */       values_0[2] = value_5;
/* 153 */     }
/* 154 */
/* 155 */   }
/* 156 */
/* 157 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[5];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 027 */     if (false) {
/* 028 */       mutableRow.setNullAt(0);
/* 029 */     } else {
/* 030 */
/* 031 */       mutableRow.update(0, value_0);
/* 032 */     }
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */
/* 037 */
/* 038 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 039 */
/* 040 */     boolean isNull_8 = i.isNullAt(3);
/* 041 */     UTF8String value_8 = isNull_8 ?
/* 042 */     null : (i.getUTF8String(3));
/* 043 */     boolean isNull_7 = true;
/* 044 */     java.lang.String value_7 = null;
/* 045 */     if (!isNull_8) {
/* 046 */
/* 047 */       isNull_7 = false;
/* 048 */       if (!isNull_7) {
/* 049 */
/* 050 */         Object funcResult_3 = null;
/* 051 */         funcResult_3 = value_8.toString();
/* 052 */         value_7 = (java.lang.String) funcResult_3;
/* 053 */
/* 054 */       }
/* 055 */     }
/* 056 */     if (isNull_7) {
/* 057 */       values_0[3] = null;
/* 058 */     } else {
/* 059 */       values_0[3] = value_7;
/* 060 */     }
/* 061 */
/* 062 */     boolean isNull_10 = i.isNullAt(4);
/* 063 */     UTF8String value_10 = isNull_10 ?
/* 064 */     null : (i.getUTF8String(4));
/* 065 */     boolean isNull_9 = true;
/* 066 */     java.lang.String value_9 = null;
/* 067 */     if (!isNull_10) {
/* 068 */
/* 069 */       isNull_9 = false;
/* 070 */       if (!isNull_9) {
/* 071 */
/* 072 */         Object funcResult_4 = null;
/* 073 */         funcResult_4 = value_10.toString();
/* 074 */         value_9 = (java.lang.String) funcResult_4;
/* 075 */
/* 076 */       }
/* 077 */     }
/* 078 */     if (isNull_9) {
/* 079 */       values_0[4] = null;
/* 080 */     } else {
/* 081 */       values_0[4] = value_9;
/* 082 */     }
/* 083 */
/* 084 */   }
/* 085 */
/* 086 */
/* 087 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 088 */
/* 089 */     boolean isNull_2 = i.isNullAt(0);
/* 090 */     UTF8String value_2 = isNull_2 ?
/* 091 */     null : (i.getUTF8String(0));
/* 092 */     boolean isNull_1 = true;
/* 093 */     java.lang.String value_1 = null;
/* 094 */     if (!isNull_2) {
/* 095 */
/* 096 */       isNull_1 = false;
/* 097 */       if (!isNull_1) {
/* 098 */
/* 099 */         Object funcResult_0 = null;
/* 100 */         funcResult_0 = value_2.toString();
/* 101 */         value_1 = (java.lang.String) funcResult_0;
/* 102 */
/* 103 */       }
/* 104 */     }
/* 105 */     if (isNull_1) {
/* 106 */       values_0[0] = null;
/* 107 */     } else {
/* 108 */       values_0[0] = value_1;
/* 109 */     }
/* 110 */
/* 111 */     boolean isNull_4 = i.isNullAt(1);
/* 112 */     UTF8String value_4 = isNull_4 ?
/* 113 */     null : (i.getUTF8String(1));
/* 114 */     boolean isNull_3 = true;
/* 115 */     java.lang.String value_3 = null;
/* 116 */     if (!isNull_4) {
/* 117 */
/* 118 */       isNull_3 = false;
/* 119 */       if (!isNull_3) {
/* 120 */
/* 121 */         Object funcResult_1 = null;
/* 122 */         funcResult_1 = value_4.toString();
/* 123 */         value_3 = (java.lang.String) funcResult_1;
/* 124 */
/* 125 */       }
/* 126 */     }
/* 127 */     if (isNull_3) {
/* 128 */       values_0[1] = null;
/* 129 */     } else {
/* 130 */       values_0[1] = value_3;
/* 131 */     }
/* 132 */
/* 133 */     boolean isNull_6 = i.isNullAt(2);
/* 134 */     UTF8String value_6 = isNull_6 ?
/* 135 */     null : (i.getUTF8String(2));
/* 136 */     boolean isNull_5 = true;
/* 137 */     java.lang.String value_5 = null;
/* 138 */     if (!isNull_6) {
/* 139 */
/* 140 */       isNull_5 = false;
/* 141 */       if (!isNull_5) {
/* 142 */
/* 143 */         Object funcResult_2 = null;
/* 144 */         funcResult_2 = value_6.toString();
/* 145 */         value_5 = (java.lang.String) funcResult_2;
/* 146 */
/* 147 */       }
/* 148 */     }
/* 149 */     if (isNull_5) {
/* 150 */       values_0[2] = null;
/* 151 */     } else {
/* 152 */       values_0[2] = value_5;
/* 153 */     }
/* 154 */
/* 155 */   }
/* 156 */
/* 157 */ }

Code generated in 13.190711 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 96);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 032 */         null : (scan_row_0.getUTF8String(0));
/* 033 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 034 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 035 */         null : (scan_row_0.getUTF8String(1));
/* 036 */
/* 037 */         Object filter_arg_0 = scan_isNull_1 ? null : ((scala.Function1[]) references[2] /* converters */)[0].apply(scan_value_1);
/* 038 */         Object filter_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[2] /* converters */)[1].apply(scan_value_0);
/* 039 */
/* 040 */         UTF8String filter_result_0 = null;
/* 041 */         try {
/* 042 */           filter_result_0 = (UTF8String)((scala.Function1[]) references[2] /* converters */)[2].apply(((scala.Function2) references[4] /* udf */).apply(filter_arg_0, filter_arg_1));
/* 043 */         } catch (Exception e) {
/* 044 */           throw new org.apache.spark.SparkException(((java.lang.String) references[3] /* errMsg */), e);
/* 045 */         }
/* 046 */
/* 047 */         boolean filter_isNull_1 = filter_result_0 == null;
/* 048 */         UTF8String filter_value_1 = null;
/* 049 */         if (!filter_isNull_1) {
/* 050 */           filter_value_1 = filter_result_0;
/* 051 */         }
/* 052 */         if (!(!filter_isNull_1)) continue;
/* 053 */         boolean filter_isNull_5 = true;
/* 054 */         UTF8String filter_value_5 = null;
/* 055 */         boolean filter_isNull_6 = true;
/* 056 */         ArrayData filter_value_6 = null;
/* 057 */         Object filter_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 058 */
/* 059 */         UTF8String filter_result_1 = null;
/* 060 */         try {
/* 061 */           filter_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(filter_arg_2));
/* 062 */         } catch (Exception e) {
/* 063 */           throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 064 */         }
/* 065 */
/* 066 */         boolean filter_isNull_7 = filter_result_1 == null;
/* 067 */         UTF8String filter_value_7 = null;
/* 068 */         if (!filter_isNull_7) {
/* 069 */           filter_value_7 = filter_result_1;
/* 070 */         }
/* 071 */         if (!filter_isNull_7) {
/* 072 */           filter_isNull_6 = false; // resultCode could change nullability.
/* 073 */           filter_value_6 = new org.apache.spark.sql.catalyst.util.GenericArrayData(filter_value_7.split(((UTF8String) references[8] /* literal */), -1));
/* 074 */
/* 075 */         }
/* 076 */         if (!filter_isNull_6) {
/* 077 */           filter_isNull_5 = false; // resultCode could change nullability.
/* 078 */
/* 079 */           final int filter_index_0 = (int) 0;
/* 080 */           if (filter_index_0 >= filter_value_6.numElements() || filter_index_0 < 0 || filter_value_6.isNullAt(filter_index_0)) {
/* 081 */             filter_isNull_5 = true;
/* 082 */           } else {
/* 083 */             filter_value_5 = filter_value_6.getUTF8String(filter_index_0);
/* 084 */           }
/* 085 */
/* 086 */         }
/* 087 */         if (!(!filter_isNull_5)) continue;
/* 088 */
/* 089 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 090 */
/* 091 */         boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 092 */         UTF8String scan_value_2 = scan_isNull_2 ?
/* 093 */         null : (scan_row_0.getUTF8String(2));
/* 094 */         boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 095 */         UTF8String scan_value_3 = scan_isNull_3 ?
/* 096 */         null : (scan_row_0.getUTF8String(3));
/* 097 */
/* 098 */         boolean project_isNull_0 = true;
/* 099 */         UTF8String project_value_0 = null;
/* 100 */         boolean project_isNull_1 = true;
/* 101 */         ArrayData project_value_1 = null;
/* 102 */         Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_0);
/* 103 */
/* 104 */         UTF8String project_result_0 = null;
/* 105 */         try {
/* 106 */           project_result_0 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[1].apply(((scala.Function1) references[11] /* udf */).apply(project_arg_0));
/* 107 */         } catch (Exception e) {
/* 108 */           throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 109 */         }
/* 110 */
/* 111 */         boolean project_isNull_2 = project_result_0 == null;
/* 112 */         UTF8String project_value_2 = null;
/* 113 */         if (!project_isNull_2) {
/* 114 */           project_value_2 = project_result_0;
/* 115 */         }
/* 116 */         if (!project_isNull_2) {
/* 117 */           project_isNull_1 = false; // resultCode could change nullability.
/* 118 */           project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[12] /* literal */), -1));
/* 119 */
/* 120 */         }
/* 121 */         if (!project_isNull_1) {
/* 122 */           project_isNull_0 = false; // resultCode could change nullability.
/* 123 */
/* 124 */           final int project_index_0 = (int) 0;
/* 125 */           if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 126 */             project_isNull_0 = true;
/* 127 */           } else {
/* 128 */             project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 129 */           }
/* 130 */
/* 131 */         }
/* 132 */         Object project_arg_1 = scan_isNull_1 ? null : ((scala.Function1[]) references[13] /* converters */)[0].apply(scan_value_1);
/* 133 */         Object project_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[13] /* converters */)[1].apply(scan_value_0);
/* 134 */
/* 135 */         UTF8String project_result_1 = null;
/* 136 */         try {
/* 137 */           project_result_1 = (UTF8String)((scala.Function1[]) references[13] /* converters */)[2].apply(((scala.Function2) references[15] /* udf */).apply(project_arg_1, project_arg_2));
/* 138 */         } catch (Exception e) {
/* 139 */           throw new org.apache.spark.SparkException(((java.lang.String) references[14] /* errMsg */), e);
/* 140 */         }
/* 141 */
/* 142 */         boolean project_isNull_6 = project_result_1 == null;
/* 143 */         UTF8String project_value_6 = null;
/* 144 */         if (!project_isNull_6) {
/* 145 */           project_value_6 = project_result_1;
/* 146 */         }
/* 147 */         boolean project_isNull_12 = scan_isNull_3;
/* 148 */         double project_value_12 = -1.0;
/* 149 */         if (!scan_isNull_3) {
/* 150 */           try {
/* 151 */             project_value_12 = Double.valueOf(scan_value_3.toString());
/* 152 */           } catch (java.lang.NumberFormatException e) {
/* 153 */             project_isNull_12 = true;
/* 154 */           }
/* 155 */         }
/* 156 */         boolean project_value_10 = true;
/* 157 */
/* 158 */         if (!project_isNull_12) {
/* 159 */           boolean project_isNull_15 = scan_isNull_2;
/* 160 */           double project_value_15 = -1.0;
/* 161 */           if (!scan_isNull_2) {
/* 162 */             try {
/* 163 */               project_value_15 = Double.valueOf(scan_value_2.toString());
/* 164 */             } catch (java.lang.NumberFormatException e) {
/* 165 */               project_isNull_15 = true;
/* 166 */             }
/* 167 */           }
/* 168 */           project_value_10 = project_isNull_15;
/* 169 */         }
/* 170 */         boolean project_isNull_9 = false;
/* 171 */         UTF8String project_value_9 = null;
/* 172 */         if (!false && project_value_10) {
/* 173 */           project_isNull_9 = true;
/* 174 */           project_value_9 = ((UTF8String)null);
/* 175 */         } else {
/* 176 */           boolean project_isNull_19 = scan_isNull_3;
/* 177 */           double project_value_19 = -1.0;
/* 178 */           if (!scan_isNull_3) {
/* 179 */             try {
/* 180 */               project_value_19 = Double.valueOf(scan_value_3.toString());
/* 181 */             } catch (java.lang.NumberFormatException e) {
/* 182 */               project_isNull_19 = true;
/* 183 */             }
/* 184 */           }
/* 185 */           boolean project_isNull_21 = scan_isNull_2;
/* 186 */           double project_value_21 = -1.0;
/* 187 */           if (!scan_isNull_2) {
/* 188 */             try {
/* 189 */               project_value_21 = Double.valueOf(scan_value_2.toString());
/* 190 */             } catch (java.lang.NumberFormatException e) {
/* 191 */               project_isNull_21 = true;
/* 192 */             }
/* 193 */           }
/* 194 */           Object project_arg_3 = project_isNull_19 ? null : ((scala.Function1[]) references[16] /* converters */)[0].apply(project_value_19);
/* 195 */           Object project_arg_4 = project_isNull_21 ? null : ((scala.Function1[]) references[16] /* converters */)[1].apply(project_value_21);
/* 196 */
/* 197 */           UTF8String project_result_2 = null;
/* 198 */           try {
/* 199 */             project_result_2 = (UTF8String)((scala.Function1[]) references[16] /* converters */)[2].apply(((scala.Function2) references[18] /* udf */).apply(project_arg_3, project_arg_4));
/* 200 */           } catch (Exception e) {
/* 201 */             throw new org.apache.spark.SparkException(((java.lang.String) references[17] /* errMsg */), e);
/* 202 */           }
/* 203 */
/* 204 */           boolean project_isNull_18 = project_result_2 == null;
/* 205 */           UTF8String project_value_18 = null;
/* 206 */           if (!project_isNull_18) {
/* 207 */             project_value_18 = project_result_2;
/* 208 */           }
/* 209 */           project_isNull_9 = project_isNull_18;
/* 210 */           project_value_9 = project_value_18;
/* 211 */         }
/* 212 */         filter_mutableStateArray_0[1].reset();
/* 213 */
/* 214 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 215 */
/* 216 */         if (project_isNull_0) {
/* 217 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 218 */         } else {
/* 219 */           filter_mutableStateArray_0[1].write(0, project_value_0);
/* 220 */         }
/* 221 */
/* 222 */         if (project_isNull_6) {
/* 223 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 224 */         } else {
/* 225 */           filter_mutableStateArray_0[1].write(1, project_value_6);
/* 226 */         }
/* 227 */
/* 228 */         if (project_isNull_9) {
/* 229 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 230 */         } else {
/* 231 */           filter_mutableStateArray_0[1].write(2, project_value_9);
/* 232 */         }
/* 233 */         append((filter_mutableStateArray_0[1].getRow()));
/* 234 */
/* 235 */       } while(false);
/* 236 */       if (shouldStop()) return;
/* 237 */     }
/* 238 */   }
/* 239 */
/* 240 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 96);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 032 */         null : (scan_row_0.getUTF8String(0));
/* 033 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 034 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 035 */         null : (scan_row_0.getUTF8String(1));
/* 036 */
/* 037 */         Object filter_arg_0 = scan_isNull_1 ? null : ((scala.Function1[]) references[2] /* converters */)[0].apply(scan_value_1);
/* 038 */         Object filter_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[2] /* converters */)[1].apply(scan_value_0);
/* 039 */
/* 040 */         UTF8String filter_result_0 = null;
/* 041 */         try {
/* 042 */           filter_result_0 = (UTF8String)((scala.Function1[]) references[2] /* converters */)[2].apply(((scala.Function2) references[4] /* udf */).apply(filter_arg_0, filter_arg_1));
/* 043 */         } catch (Exception e) {
/* 044 */           throw new org.apache.spark.SparkException(((java.lang.String) references[3] /* errMsg */), e);
/* 045 */         }
/* 046 */
/* 047 */         boolean filter_isNull_1 = filter_result_0 == null;
/* 048 */         UTF8String filter_value_1 = null;
/* 049 */         if (!filter_isNull_1) {
/* 050 */           filter_value_1 = filter_result_0;
/* 051 */         }
/* 052 */         if (!(!filter_isNull_1)) continue;
/* 053 */         boolean filter_isNull_5 = true;
/* 054 */         UTF8String filter_value_5 = null;
/* 055 */         boolean filter_isNull_6 = true;
/* 056 */         ArrayData filter_value_6 = null;
/* 057 */         Object filter_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 058 */
/* 059 */         UTF8String filter_result_1 = null;
/* 060 */         try {
/* 061 */           filter_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(filter_arg_2));
/* 062 */         } catch (Exception e) {
/* 063 */           throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 064 */         }
/* 065 */
/* 066 */         boolean filter_isNull_7 = filter_result_1 == null;
/* 067 */         UTF8String filter_value_7 = null;
/* 068 */         if (!filter_isNull_7) {
/* 069 */           filter_value_7 = filter_result_1;
/* 070 */         }
/* 071 */         if (!filter_isNull_7) {
/* 072 */           filter_isNull_6 = false; // resultCode could change nullability.
/* 073 */           filter_value_6 = new org.apache.spark.sql.catalyst.util.GenericArrayData(filter_value_7.split(((UTF8String) references[8] /* literal */), -1));
/* 074 */
/* 075 */         }
/* 076 */         if (!filter_isNull_6) {
/* 077 */           filter_isNull_5 = false; // resultCode could change nullability.
/* 078 */
/* 079 */           final int filter_index_0 = (int) 0;
/* 080 */           if (filter_index_0 >= filter_value_6.numElements() || filter_index_0 < 0 || filter_value_6.isNullAt(filter_index_0)) {
/* 081 */             filter_isNull_5 = true;
/* 082 */           } else {
/* 083 */             filter_value_5 = filter_value_6.getUTF8String(filter_index_0);
/* 084 */           }
/* 085 */
/* 086 */         }
/* 087 */         if (!(!filter_isNull_5)) continue;
/* 088 */
/* 089 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 090 */
/* 091 */         boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 092 */         UTF8String scan_value_2 = scan_isNull_2 ?
/* 093 */         null : (scan_row_0.getUTF8String(2));
/* 094 */         boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 095 */         UTF8String scan_value_3 = scan_isNull_3 ?
/* 096 */         null : (scan_row_0.getUTF8String(3));
/* 097 */
/* 098 */         boolean project_isNull_0 = true;
/* 099 */         UTF8String project_value_0 = null;
/* 100 */         boolean project_isNull_1 = true;
/* 101 */         ArrayData project_value_1 = null;
/* 102 */         Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_0);
/* 103 */
/* 104 */         UTF8String project_result_0 = null;
/* 105 */         try {
/* 106 */           project_result_0 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[1].apply(((scala.Function1) references[11] /* udf */).apply(project_arg_0));
/* 107 */         } catch (Exception e) {
/* 108 */           throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 109 */         }
/* 110 */
/* 111 */         boolean project_isNull_2 = project_result_0 == null;
/* 112 */         UTF8String project_value_2 = null;
/* 113 */         if (!project_isNull_2) {
/* 114 */           project_value_2 = project_result_0;
/* 115 */         }
/* 116 */         if (!project_isNull_2) {
/* 117 */           project_isNull_1 = false; // resultCode could change nullability.
/* 118 */           project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[12] /* literal */), -1));
/* 119 */
/* 120 */         }
/* 121 */         if (!project_isNull_1) {
/* 122 */           project_isNull_0 = false; // resultCode could change nullability.
/* 123 */
/* 124 */           final int project_index_0 = (int) 0;
/* 125 */           if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 126 */             project_isNull_0 = true;
/* 127 */           } else {
/* 128 */             project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 129 */           }
/* 130 */
/* 131 */         }
/* 132 */         Object project_arg_1 = scan_isNull_1 ? null : ((scala.Function1[]) references[13] /* converters */)[0].apply(scan_value_1);
/* 133 */         Object project_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[13] /* converters */)[1].apply(scan_value_0);
/* 134 */
/* 135 */         UTF8String project_result_1 = null;
/* 136 */         try {
/* 137 */           project_result_1 = (UTF8String)((scala.Function1[]) references[13] /* converters */)[2].apply(((scala.Function2) references[15] /* udf */).apply(project_arg_1, project_arg_2));
/* 138 */         } catch (Exception e) {
/* 139 */           throw new org.apache.spark.SparkException(((java.lang.String) references[14] /* errMsg */), e);
/* 140 */         }
/* 141 */
/* 142 */         boolean project_isNull_6 = project_result_1 == null;
/* 143 */         UTF8String project_value_6 = null;
/* 144 */         if (!project_isNull_6) {
/* 145 */           project_value_6 = project_result_1;
/* 146 */         }
/* 147 */         boolean project_isNull_12 = scan_isNull_3;
/* 148 */         double project_value_12 = -1.0;
/* 149 */         if (!scan_isNull_3) {
/* 150 */           try {
/* 151 */             project_value_12 = Double.valueOf(scan_value_3.toString());
/* 152 */           } catch (java.lang.NumberFormatException e) {
/* 153 */             project_isNull_12 = true;
/* 154 */           }
/* 155 */         }
/* 156 */         boolean project_value_10 = true;
/* 157 */
/* 158 */         if (!project_isNull_12) {
/* 159 */           boolean project_isNull_15 = scan_isNull_2;
/* 160 */           double project_value_15 = -1.0;
/* 161 */           if (!scan_isNull_2) {
/* 162 */             try {
/* 163 */               project_value_15 = Double.valueOf(scan_value_2.toString());
/* 164 */             } catch (java.lang.NumberFormatException e) {
/* 165 */               project_isNull_15 = true;
/* 166 */             }
/* 167 */           }
/* 168 */           project_value_10 = project_isNull_15;
/* 169 */         }
/* 170 */         boolean project_isNull_9 = false;
/* 171 */         UTF8String project_value_9 = null;
/* 172 */         if (!false && project_value_10) {
/* 173 */           project_isNull_9 = true;
/* 174 */           project_value_9 = ((UTF8String)null);
/* 175 */         } else {
/* 176 */           boolean project_isNull_19 = scan_isNull_3;
/* 177 */           double project_value_19 = -1.0;
/* 178 */           if (!scan_isNull_3) {
/* 179 */             try {
/* 180 */               project_value_19 = Double.valueOf(scan_value_3.toString());
/* 181 */             } catch (java.lang.NumberFormatException e) {
/* 182 */               project_isNull_19 = true;
/* 183 */             }
/* 184 */           }
/* 185 */           boolean project_isNull_21 = scan_isNull_2;
/* 186 */           double project_value_21 = -1.0;
/* 187 */           if (!scan_isNull_2) {
/* 188 */             try {
/* 189 */               project_value_21 = Double.valueOf(scan_value_2.toString());
/* 190 */             } catch (java.lang.NumberFormatException e) {
/* 191 */               project_isNull_21 = true;
/* 192 */             }
/* 193 */           }
/* 194 */           Object project_arg_3 = project_isNull_19 ? null : ((scala.Function1[]) references[16] /* converters */)[0].apply(project_value_19);
/* 195 */           Object project_arg_4 = project_isNull_21 ? null : ((scala.Function1[]) references[16] /* converters */)[1].apply(project_value_21);
/* 196 */
/* 197 */           UTF8String project_result_2 = null;
/* 198 */           try {
/* 199 */             project_result_2 = (UTF8String)((scala.Function1[]) references[16] /* converters */)[2].apply(((scala.Function2) references[18] /* udf */).apply(project_arg_3, project_arg_4));
/* 200 */           } catch (Exception e) {
/* 201 */             throw new org.apache.spark.SparkException(((java.lang.String) references[17] /* errMsg */), e);
/* 202 */           }
/* 203 */
/* 204 */           boolean project_isNull_18 = project_result_2 == null;
/* 205 */           UTF8String project_value_18 = null;
/* 206 */           if (!project_isNull_18) {
/* 207 */             project_value_18 = project_result_2;
/* 208 */           }
/* 209 */           project_isNull_9 = project_isNull_18;
/* 210 */           project_value_9 = project_value_18;
/* 211 */         }
/* 212 */         filter_mutableStateArray_0[1].reset();
/* 213 */
/* 214 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 215 */
/* 216 */         if (project_isNull_0) {
/* 217 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 218 */         } else {
/* 219 */           filter_mutableStateArray_0[1].write(0, project_value_0);
/* 220 */         }
/* 221 */
/* 222 */         if (project_isNull_6) {
/* 223 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 224 */         } else {
/* 225 */           filter_mutableStateArray_0[1].write(1, project_value_6);
/* 226 */         }
/* 227 */
/* 228 */         if (project_isNull_9) {
/* 229 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 230 */         } else {
/* 231 */           filter_mutableStateArray_0[1].write(2, project_value_9);
/* 232 */         }
/* 233 */         append((filter_mutableStateArray_0[1].getRow()));
/* 234 */
/* 235 */       } while(false);
/* 236 */       if (shouldStop()) return;
/* 237 */     }
/* 238 */   }
/* 239 */
/* 240 */ }

Code generated in 30.007297 ms
Block broadcast_8 stored as values in memory (estimated size 242.9 KB, free 1986.8 MB)
Put block broadcast_8 locally took  0 ms
Putting block broadcast_8 without replication took  0 ms
Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1986.8 MB)
Added broadcast_8_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_8_piece0
Told master about block broadcast_8_piece0
Put block broadcast_8_piece0 locally took  0 ms
Putting block broadcast_8_piece0 without replication took  0 ms
Created broadcast 8 from run at ThreadPoolExecutor.java:1149
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$collect$2
 +++ Lambda closure ($anonfun$collect$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: run at ThreadPoolExecutor.java:1149
Got job 3 (run at ThreadPoolExecutor.java:1149) with 3 output partitions
Final stage: ResultStage 4 (run at ThreadPoolExecutor.java:1149)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 4)
missing: List()
Submitting ResultStage 4 (MapPartitionsRDD[20] at run at ThreadPoolExecutor.java:1149), which has no missing parents
submitMissingTasks(ResultStage 4)
Block broadcast_9 stored as values in memory (estimated size 22.5 KB, free 1986.8 MB)
Put block broadcast_9 locally took  0 ms
Putting block broadcast_9 without replication took  0 ms
Block broadcast_9_piece0 stored as bytes in memory (estimated size 9.8 KB, free 1986.8 MB)
Added broadcast_9_piece0 in memory on 192.168.1.13:20571 (size: 9.8 KB, free: 1987.4 MB)
Updated info of block broadcast_9_piece0
Told master about block broadcast_9_piece0
Put block broadcast_9_piece0 locally took  0 ms
Putting block broadcast_9_piece0 without replication took  0 ms
Created broadcast 9 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 4.0 with 3 tasks
Epoch for TaskSet 4.0: 1
Valid locality levels for TaskSet 4.0: NO_PREF, ANY
parentName: , name: TaskSet_4.0, runningTasks: 0
Starting task 0.0 in stage 4.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
Starting task 1.0 in stage 4.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 7830 bytes)
Starting task 2.0 in stage 4.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 7828 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 1.0 in stage 4.0 (TID 7)
Running task 0.0 in stage 4.0 (TID 6)
Running task 2.0 in stage 4.0 (TID 8)
Getting local block broadcast_9
Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_8
Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 2.0 in stage 4.0 (TID 8). 7178 bytes result sent to driver
parentName: , name: TaskSet_4.0, runningTasks: 2
Finished task 2.0 in stage 4.0 (TID 8) in 78 ms on localhost (executor driver) (1/3)
Finished task 0.0 in stage 4.0 (TID 6). 7388 bytes result sent to driver
parentName: , name: TaskSet_4.0, runningTasks: 1
Finished task 0.0 in stage 4.0 (TID 6) in 94 ms on localhost (executor driver) (2/3)
Finished task 1.0 in stage 4.0 (TID 7). 7219 bytes result sent to driver
parentName: , name: TaskSet_4.0, runningTasks: 0
Finished task 1.0 in stage 4.0 (TID 7) in 110 ms on localhost (executor driver) (3/3)
Removed TaskSet 4.0, whose tasks have all completed, from pool 
ResultStage 4 (run at ThreadPoolExecutor.java:1149) finished in 0.110 s
After removal of stage 4, remaining stages = 0
Job 3 finished: run at ThreadPoolExecutor.java:1149, took 0.105766 s
Task 0 acquired 32.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@27d38b1
code for cast(input[1, string, true] as date),input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(1);
/* 032 */     UTF8String value_1 = isNull_1 ?
/* 033 */     null : (i.getUTF8String(1));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     int value_0 = -1;
/* 036 */     if (!isNull_1) {
/* 037 */       scala.Option<Integer> intOpt_0 =
/* 038 */       org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(value_1);
/* 039 */       if (intOpt_0.isDefined()) {
/* 040 */         value_0 = ((Integer) intOpt_0.get()).intValue();
/* 041 */       } else {
/* 042 */         isNull_0 = true;
/* 043 */       }
/* 044 */     }
/* 045 */     if (isNull_0) {
/* 046 */       mutableStateArray_0[0].setNullAt(0);
/* 047 */     } else {
/* 048 */       mutableStateArray_0[0].write(0, value_0);
/* 049 */     }
/* 050 */
/* 051 */     boolean isNull_2 = i.isNullAt(0);
/* 052 */     UTF8String value_2 = isNull_2 ?
/* 053 */     null : (i.getUTF8String(0));
/* 054 */     if (isNull_2) {
/* 055 */       mutableStateArray_0[0].setNullAt(1);
/* 056 */     } else {
/* 057 */       mutableStateArray_0[0].write(1, value_2);
/* 058 */     }
/* 059 */     return (mutableStateArray_0[0].getRow());
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(1);
/* 032 */     UTF8String value_1 = isNull_1 ?
/* 033 */     null : (i.getUTF8String(1));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     int value_0 = -1;
/* 036 */     if (!isNull_1) {
/* 037 */       scala.Option<Integer> intOpt_0 =
/* 038 */       org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(value_1);
/* 039 */       if (intOpt_0.isDefined()) {
/* 040 */         value_0 = ((Integer) intOpt_0.get()).intValue();
/* 041 */       } else {
/* 042 */         isNull_0 = true;
/* 043 */       }
/* 044 */     }
/* 045 */     if (isNull_0) {
/* 046 */       mutableStateArray_0[0].setNullAt(0);
/* 047 */     } else {
/* 048 */       mutableStateArray_0[0].write(0, value_0);
/* 049 */     }
/* 050 */
/* 051 */     boolean isNull_2 = i.isNullAt(0);
/* 052 */     UTF8String value_2 = isNull_2 ?
/* 053 */     null : (i.getUTF8String(0));
/* 054 */     if (isNull_2) {
/* 055 */       mutableStateArray_0[0].setNullAt(1);
/* 056 */     } else {
/* 057 */       mutableStateArray_0[0].write(1, value_2);
/* 058 */     }
/* 059 */     return (mutableStateArray_0[0].getRow());
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

Code generated in 10.299255 ms
Task 0 acquired 8.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@27d38b1
Task 0 acquired 64.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@27d38b1
Task 0 release 32.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@27d38b1
Block broadcast_10 stored as values in memory (estimated size 8.1 MB, free 1978.7 MB)
Put block broadcast_10 locally took  0 ms
Putting block broadcast_10 without replication took  0 ms
Block broadcast_10_piece0 stored as bytes in memory (estimated size 22.6 KB, free 1978.7 MB)
Added broadcast_10_piece0 in memory on 192.168.1.13:20571 (size: 22.6 KB, free: 1987.4 MB)
Updated info of block broadcast_10_piece0
Told master about block broadcast_10_piece0
Put block broadcast_10_piece0 locally took  0 ms
Putting block broadcast_10_piece0 without replication took  0 ms
Created broadcast 10 from run at ThreadPoolExecutor.java:1149
Getting local block broadcast_10
Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 011 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     wholestagecodegen_init_0_0();
/* 021 */     wholestagecodegen_init_0_1();
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   private void wholestagecodegen_init_0_1() {
/* 026 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(5, 160);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   protected void processNext() throws java.io.IOException {
/* 031 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 032 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 033 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 034 */       do {
/* 035 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 036 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 037 */         null : (scan_row_0.getUTF8String(1));
/* 038 */
/* 039 */         if (!(!scan_isNull_1)) continue;
/* 040 */
/* 041 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 042 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 043 */         null : (scan_row_0.getUTF8String(0));
/* 044 */
/* 045 */         if (!(!scan_isNull_0)) continue;
/* 046 */
/* 047 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 048 */
/* 049 */         // generate join key for stream side
/* 050 */         filter_mutableStateArray_0[2].reset();
/* 051 */
/* 052 */         filter_mutableStateArray_0[2].zeroOutNullBytes();
/* 053 */
/* 054 */         boolean bhj_isNull_0 = false;
/* 055 */         int bhj_value_0 = -1;
/* 056 */         if (!false) {
/* 057 */           scala.Option<Integer> bhj_intOpt_0 =
/* 058 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(scan_value_1);
/* 059 */           if (bhj_intOpt_0.isDefined()) {
/* 060 */             bhj_value_0 = ((Integer) bhj_intOpt_0.get()).intValue();
/* 061 */           } else {
/* 062 */             bhj_isNull_0 = true;
/* 063 */           }
/* 064 */         }
/* 065 */         if (bhj_isNull_0) {
/* 066 */           filter_mutableStateArray_0[2].setNullAt(0);
/* 067 */         } else {
/* 068 */           filter_mutableStateArray_0[2].write(0, bhj_value_0);
/* 069 */         }
/* 070 */
/* 071 */         if (false) {
/* 072 */           filter_mutableStateArray_0[2].setNullAt(1);
/* 073 */         } else {
/* 074 */           filter_mutableStateArray_0[2].write(1, scan_value_0);
/* 075 */         }
/* 076 */         // find matches from HashedRelation
/* 077 */         UnsafeRow bhj_matched_0 = (filter_mutableStateArray_0[2].getRow()).anyNull() ? null: (UnsafeRow)bhj_relation_0.getValue((filter_mutableStateArray_0[2].getRow()));
/* 078 */         if (bhj_matched_0 != null) {
/* 079 */           {
/* 080 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 081 */
/* 082 */             boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 083 */             UTF8String scan_value_2 = scan_isNull_2 ?
/* 084 */             null : (scan_row_0.getUTF8String(2));
/* 085 */             boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 086 */             UTF8String scan_value_3 = scan_isNull_3 ?
/* 087 */             null : (scan_row_0.getUTF8String(3));
/* 088 */             boolean project_isNull_12 = true;
/* 089 */             UTF8String project_value_12 = null;
/* 090 */             boolean bhj_isNull_5 = bhj_matched_0.isNullAt(2);
/* 091 */             UTF8String bhj_value_5 = bhj_isNull_5 ?
/* 092 */             null : (bhj_matched_0.getUTF8String(2));
/* 093 */             if (!bhj_isNull_5) {
/* 094 */               project_isNull_12 = false; // resultCode could change nullability.
/* 095 */               project_value_12 = bhj_value_5.replace(((UTF8String) references[5] /* literal */), ((UTF8String) references[6] /* literal */));
/* 096 */
/* 097 */             }
/* 098 */             filter_mutableStateArray_0[4].reset();
/* 099 */
/* 100 */             filter_mutableStateArray_0[4].zeroOutNullBytes();
/* 101 */
/* 102 */             if (false) {
/* 103 */               filter_mutableStateArray_0[4].setNullAt(0);
/* 104 */             } else {
/* 105 */               filter_mutableStateArray_0[4].write(0, scan_value_0);
/* 106 */             }
/* 107 */
/* 108 */             if (false) {
/* 109 */               filter_mutableStateArray_0[4].setNullAt(1);
/* 110 */             } else {
/* 111 */               filter_mutableStateArray_0[4].write(1, scan_value_1);
/* 112 */             }
/* 113 */
/* 114 */             if (scan_isNull_2) {
/* 115 */               filter_mutableStateArray_0[4].setNullAt(2);
/* 116 */             } else {
/* 117 */               filter_mutableStateArray_0[4].write(2, scan_value_2);
/* 118 */             }
/* 119 */
/* 120 */             if (scan_isNull_3) {
/* 121 */               filter_mutableStateArray_0[4].setNullAt(3);
/* 122 */             } else {
/* 123 */               filter_mutableStateArray_0[4].write(3, scan_value_3);
/* 124 */             }
/* 125 */
/* 126 */             if (project_isNull_12) {
/* 127 */               filter_mutableStateArray_0[4].setNullAt(4);
/* 128 */             } else {
/* 129 */               filter_mutableStateArray_0[4].write(4, project_value_12);
/* 130 */             }
/* 131 */             append((filter_mutableStateArray_0[4].getRow()));
/* 132 */
/* 133 */           }
/* 134 */         }
/* 135 */
/* 136 */       } while(false);
/* 137 */       if (shouldStop()) return;
/* 138 */     }
/* 139 */   }
/* 140 */
/* 141 */   private void wholestagecodegen_init_0_0() {
/* 142 */     scan_mutableStateArray_0[0] = inputs[0];
/* 143 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 144 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 145 */
/* 146 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[2] /* broadcast */).value()).asReadOnlyCopy();
/* 147 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 148 */
/* 149 */     org.apache.spark.TaskContext$.MODULE$.get().addTaskCompletionListener(new org.apache.spark.util.TaskCompletionListener() {
/* 150 */         @Override
/* 151 */         public void onTaskCompletion(org.apache.spark.TaskContext context) {
/* 152 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */).set(bhj_relation_0.getAverageProbesPerLookup());
/* 153 */         }
/* 154 */       });
/* 155 */
/* 156 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 157 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 158 */
/* 159 */   }
/* 160 */
/* 161 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 011 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     wholestagecodegen_init_0_0();
/* 021 */     wholestagecodegen_init_0_1();
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   private void wholestagecodegen_init_0_1() {
/* 026 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(5, 160);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   protected void processNext() throws java.io.IOException {
/* 031 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 032 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 033 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 034 */       do {
/* 035 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 036 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 037 */         null : (scan_row_0.getUTF8String(1));
/* 038 */
/* 039 */         if (!(!scan_isNull_1)) continue;
/* 040 */
/* 041 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 042 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 043 */         null : (scan_row_0.getUTF8String(0));
/* 044 */
/* 045 */         if (!(!scan_isNull_0)) continue;
/* 046 */
/* 047 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 048 */
/* 049 */         // generate join key for stream side
/* 050 */         filter_mutableStateArray_0[2].reset();
/* 051 */
/* 052 */         filter_mutableStateArray_0[2].zeroOutNullBytes();
/* 053 */
/* 054 */         boolean bhj_isNull_0 = false;
/* 055 */         int bhj_value_0 = -1;
/* 056 */         if (!false) {
/* 057 */           scala.Option<Integer> bhj_intOpt_0 =
/* 058 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(scan_value_1);
/* 059 */           if (bhj_intOpt_0.isDefined()) {
/* 060 */             bhj_value_0 = ((Integer) bhj_intOpt_0.get()).intValue();
/* 061 */           } else {
/* 062 */             bhj_isNull_0 = true;
/* 063 */           }
/* 064 */         }
/* 065 */         if (bhj_isNull_0) {
/* 066 */           filter_mutableStateArray_0[2].setNullAt(0);
/* 067 */         } else {
/* 068 */           filter_mutableStateArray_0[2].write(0, bhj_value_0);
/* 069 */         }
/* 070 */
/* 071 */         if (false) {
/* 072 */           filter_mutableStateArray_0[2].setNullAt(1);
/* 073 */         } else {
/* 074 */           filter_mutableStateArray_0[2].write(1, scan_value_0);
/* 075 */         }
/* 076 */         // find matches from HashedRelation
/* 077 */         UnsafeRow bhj_matched_0 = (filter_mutableStateArray_0[2].getRow()).anyNull() ? null: (UnsafeRow)bhj_relation_0.getValue((filter_mutableStateArray_0[2].getRow()));
/* 078 */         if (bhj_matched_0 != null) {
/* 079 */           {
/* 080 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 081 */
/* 082 */             boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 083 */             UTF8String scan_value_2 = scan_isNull_2 ?
/* 084 */             null : (scan_row_0.getUTF8String(2));
/* 085 */             boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 086 */             UTF8String scan_value_3 = scan_isNull_3 ?
/* 087 */             null : (scan_row_0.getUTF8String(3));
/* 088 */             boolean project_isNull_12 = true;
/* 089 */             UTF8String project_value_12 = null;
/* 090 */             boolean bhj_isNull_5 = bhj_matched_0.isNullAt(2);
/* 091 */             UTF8String bhj_value_5 = bhj_isNull_5 ?
/* 092 */             null : (bhj_matched_0.getUTF8String(2));
/* 093 */             if (!bhj_isNull_5) {
/* 094 */               project_isNull_12 = false; // resultCode could change nullability.
/* 095 */               project_value_12 = bhj_value_5.replace(((UTF8String) references[5] /* literal */), ((UTF8String) references[6] /* literal */));
/* 096 */
/* 097 */             }
/* 098 */             filter_mutableStateArray_0[4].reset();
/* 099 */
/* 100 */             filter_mutableStateArray_0[4].zeroOutNullBytes();
/* 101 */
/* 102 */             if (false) {
/* 103 */               filter_mutableStateArray_0[4].setNullAt(0);
/* 104 */             } else {
/* 105 */               filter_mutableStateArray_0[4].write(0, scan_value_0);
/* 106 */             }
/* 107 */
/* 108 */             if (false) {
/* 109 */               filter_mutableStateArray_0[4].setNullAt(1);
/* 110 */             } else {
/* 111 */               filter_mutableStateArray_0[4].write(1, scan_value_1);
/* 112 */             }
/* 113 */
/* 114 */             if (scan_isNull_2) {
/* 115 */               filter_mutableStateArray_0[4].setNullAt(2);
/* 116 */             } else {
/* 117 */               filter_mutableStateArray_0[4].write(2, scan_value_2);
/* 118 */             }
/* 119 */
/* 120 */             if (scan_isNull_3) {
/* 121 */               filter_mutableStateArray_0[4].setNullAt(3);
/* 122 */             } else {
/* 123 */               filter_mutableStateArray_0[4].write(3, scan_value_3);
/* 124 */             }
/* 125 */
/* 126 */             if (project_isNull_12) {
/* 127 */               filter_mutableStateArray_0[4].setNullAt(4);
/* 128 */             } else {
/* 129 */               filter_mutableStateArray_0[4].write(4, project_value_12);
/* 130 */             }
/* 131 */             append((filter_mutableStateArray_0[4].getRow()));
/* 132 */
/* 133 */           }
/* 134 */         }
/* 135 */
/* 136 */       } while(false);
/* 137 */       if (shouldStop()) return;
/* 138 */     }
/* 139 */   }
/* 140 */
/* 141 */   private void wholestagecodegen_init_0_0() {
/* 142 */     scan_mutableStateArray_0[0] = inputs[0];
/* 143 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 144 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 145 */
/* 146 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[2] /* broadcast */).value()).asReadOnlyCopy();
/* 147 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 148 */
/* 149 */     org.apache.spark.TaskContext$.MODULE$.get().addTaskCompletionListener(new org.apache.spark.util.TaskCompletionListener() {
/* 150 */         @Override
/* 151 */         public void onTaskCompletion(org.apache.spark.TaskContext context) {
/* 152 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */).set(bhj_relation_0.getAverageProbesPerLookup());
/* 153 */         }
/* 154 */       });
/* 155 */
/* 156 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 157 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 158 */
/* 159 */   }
/* 160 */
/* 161 */ }

Code generated in 24.847003 ms
Block broadcast_11 stored as values in memory (estimated size 242.9 KB, free 1978.5 MB)
Put block broadcast_11 locally took  0 ms
Putting block broadcast_11 without replication took  0 ms
Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1978.4 MB)
Added broadcast_11_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_11_piece0
Told master about block broadcast_11_piece0
Put block broadcast_11_piece0 locally took  0 ms
Putting block broadcast_11_piece0 without replication took  0 ms
Created broadcast 11 from show at Run.scala:65
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$1
 +++ Lambda closure ($anonfun$executeTake$1) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$2
 +++ Lambda closure ($anonfun$executeTake$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: show at Run.scala:65
Got job 4 (show at Run.scala:65) with 1 output partitions
Final stage: ResultStage 5 (show at Run.scala:65)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 5)
missing: List()
Submitting ResultStage 5 (MapPartitionsRDD[24] at show at Run.scala:65), which has no missing parents
submitMissingTasks(ResultStage 5)
Block broadcast_12 stored as values in memory (estimated size 17.6 KB, free 1978.4 MB)
Put block broadcast_12 locally took  0 ms
Putting block broadcast_12 without replication took  0 ms
Got cleaning task CleanAccum(157)
Cleaning accumulator 157
Cleaned accumulator 157
Got cleaning task CleanAccum(168)
Cleaning accumulator 168
Cleaned accumulator 168
Got cleaning task CleanAccum(155)
Cleaning accumulator 155
Cleaned accumulator 155
Got cleaning task CleanAccum(163)
Cleaning accumulator 163
Cleaned accumulator 163
Got cleaning task CleanAccum(166)
Cleaning accumulator 166
Cleaned accumulator 166
Got cleaning task CleanBroadcast(9)
Cleaning broadcast 9
Unpersisting TorrentBroadcast 9
Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.8 KB, free 1978.4 MB)
removing broadcast 9
Removing broadcast 9
Removing block broadcast_9_piece0
Block broadcast_9_piece0 of size 10045 dropped from memory (free 2074530002)
Added broadcast_12_piece0 in memory on 192.168.1.13:20571 (size: 8.8 KB, free: 1987.4 MB)
Updated info of block broadcast_12_piece0
Told master about block broadcast_12_piece0
Put block broadcast_12_piece0 locally took  0 ms
Putting block broadcast_12_piece0 without replication took  0 ms
Removed broadcast_9_piece0 on 192.168.1.13:20571 in memory (size: 9.8 KB, free: 1987.4 MB)
Created broadcast 12 from broadcast at DAGScheduler.scala:1161
Updated info of block broadcast_9_piece0
Told master about block broadcast_9_piece0
Removing block broadcast_9
Block broadcast_9 of size 23000 dropped from memory (free 2074553002)
Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at show at Run.scala:65) (first 15 tasks are for partitions Vector(0))
Adding task set 5.0 with 1 tasks
Epoch for TaskSet 5.0: 1
Done removing broadcast 9, response is 0
Valid locality levels for TaskSet 5.0: NO_PREF, ANY
Sent response: 0 to 192.168.1.13:20530
parentName: , name: TaskSet_5.0, runningTasks: 0
Starting task 0.0 in stage 5.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
Cleaned broadcast 9
Got cleaning task CleanAccum(170)
Cleaning accumulator 170
No tasks for locality level NO_PREF, so moving to locality level ANY
Cleaned accumulator 170
Got cleaning task CleanAccum(148)
Cleaning accumulator 148
Cleaned accumulator 148
Got cleaning task CleanAccum(167)
Cleaning accumulator 167
Cleaned accumulator 167
Got cleaning task CleanAccum(151)
Cleaning accumulator 151
Running task 0.0 in stage 5.0 (TID 9)
Cleaned accumulator 151
Got cleaning task CleanAccum(165)
Cleaning accumulator 165
Cleaned accumulator 165
Got cleaning task CleanAccum(169)
Cleaning accumulator 169
Cleaned accumulator 169
Got cleaning task CleanAccum(152)
Cleaning accumulator 152
Cleaned accumulator 152
Got cleaning task CleanAccum(158)
Cleaning accumulator 158
Cleaned accumulator 158
Got cleaning task CleanAccum(161)
Cleaning accumulator 161
Cleaned accumulator 161
Got cleaning task CleanAccum(149)
Cleaning accumulator 149
Cleaned accumulator 149
Got cleaning task CleanAccum(147)
Cleaning accumulator 147
Cleaned accumulator 147
Got cleaning task CleanAccum(159)
Cleaning accumulator 159
Cleaned accumulator 159
Got cleaning task CleanAccum(162)
Cleaning accumulator 162
Cleaned accumulator 162
Got cleaning task CleanAccum(154)
Cleaning accumulator 154
Cleaned accumulator 154
Got cleaning task CleanAccum(156)
Cleaning accumulator 156
Cleaned accumulator 156
Got cleaning task CleanAccum(160)
Cleaning accumulator 160
Cleaned accumulator 160
Got cleaning task CleanAccum(153)
Cleaning accumulator 153
Cleaned accumulator 153
Got cleaning task CleanAccum(164)
Cleaning accumulator 164
Cleaned accumulator 164
Got cleaning task CleanAccum(146)
Cleaning accumulator 146
Cleaned accumulator 146
Got cleaning task CleanAccum(150)
Cleaning accumulator 150
Cleaned accumulator 150
Getting local block broadcast_12
Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_11
Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 0.0 in stage 5.0 (TID 9). 1804 bytes result sent to driver
parentName: , name: TaskSet_5.0, runningTasks: 0
Finished task 0.0 in stage 5.0 (TID 9) in 15 ms on localhost (executor driver) (1/1)
Removed TaskSet 5.0, whose tasks have all completed, from pool 
ResultStage 5 (show at Run.scala:65) finished in 0.015 s
After removal of stage 5, remaining stages = 0
Job 4 finished: show at Run.scala:65, took 0.030291 s
Writing CSV files at src/main/resources/verify with saveMode=Overwrite

=== Result of Batch Finish Analysis ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                                                                                                                                                                       InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                                    +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                                  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
!      +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                               +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                     :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                           +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!         :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                             +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!         +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                           +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                   
!               +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   
!                  +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                               
!                     +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                        
!                        +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!                           +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                                                                                                                                                                 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                              +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                            +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                           +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                          :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]            :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                    +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Infer Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                             InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                          +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                        +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :- Filter (isnotnull(monthday#11) && isnotnull(location#10))
!         :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]            :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   +- Filter (isnotnull(local_time#22) && isnotnull(location#20))
!                                                                                                                                                                                                                                                                                                            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!                                                                                                                                                                                                                                                                                                               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Operator Optimization after Inferring Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                                InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                             +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                           +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                          +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Filter (isnotnull(monthday#11) && isnotnull(location#10))                                                                                                                                                                                                                                       :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :  +- Filter (isnotnull(monthday#11) && isnotnull(location#10))
          :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Filter (isnotnull(local_time#22) && isnotnull(location#20))                                                                                                                                                                                                                                     +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]               +- Filter (isnotnull(UDF(monthday#11, location#10)) && isnotnull(split(UDF(location#10), [|])[0]))
                +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Pruning directories with: 
Post-Scan Filters: isnotnull(monthday#11),isnotnull(location#10)
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: IsNotNull(monthday),IsNotNull(location)
Pruning directories with: 
Post-Scan Filters: isnotnull(UDF(monthday#11, location#10)),isnotnull(split(UDF(location#10), [|])[0])
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 
Creating committer org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol; job ed31ba26-4daf-4e3a-8a7e-4a9339999086; output=file:/D:/p1/weather-simulator/src/main/resources/verify; dynamic=false
Using (String, String, Boolean) constructor
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 96);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 032 */         null : (scan_row_0.getUTF8String(0));
/* 033 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 034 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 035 */         null : (scan_row_0.getUTF8String(1));
/* 036 */
/* 037 */         Object filter_arg_0 = scan_isNull_1 ? null : ((scala.Function1[]) references[2] /* converters */)[0].apply(scan_value_1);
/* 038 */         Object filter_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[2] /* converters */)[1].apply(scan_value_0);
/* 039 */
/* 040 */         UTF8String filter_result_0 = null;
/* 041 */         try {
/* 042 */           filter_result_0 = (UTF8String)((scala.Function1[]) references[2] /* converters */)[2].apply(((scala.Function2) references[4] /* udf */).apply(filter_arg_0, filter_arg_1));
/* 043 */         } catch (Exception e) {
/* 044 */           throw new org.apache.spark.SparkException(((java.lang.String) references[3] /* errMsg */), e);
/* 045 */         }
/* 046 */
/* 047 */         boolean filter_isNull_1 = filter_result_0 == null;
/* 048 */         UTF8String filter_value_1 = null;
/* 049 */         if (!filter_isNull_1) {
/* 050 */           filter_value_1 = filter_result_0;
/* 051 */         }
/* 052 */         if (!(!filter_isNull_1)) continue;
/* 053 */         boolean filter_isNull_5 = true;
/* 054 */         UTF8String filter_value_5 = null;
/* 055 */         boolean filter_isNull_6 = true;
/* 056 */         ArrayData filter_value_6 = null;
/* 057 */         Object filter_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 058 */
/* 059 */         UTF8String filter_result_1 = null;
/* 060 */         try {
/* 061 */           filter_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(filter_arg_2));
/* 062 */         } catch (Exception e) {
/* 063 */           throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 064 */         }
/* 065 */
/* 066 */         boolean filter_isNull_7 = filter_result_1 == null;
/* 067 */         UTF8String filter_value_7 = null;
/* 068 */         if (!filter_isNull_7) {
/* 069 */           filter_value_7 = filter_result_1;
/* 070 */         }
/* 071 */         if (!filter_isNull_7) {
/* 072 */           filter_isNull_6 = false; // resultCode could change nullability.
/* 073 */           filter_value_6 = new org.apache.spark.sql.catalyst.util.GenericArrayData(filter_value_7.split(((UTF8String) references[8] /* literal */), -1));
/* 074 */
/* 075 */         }
/* 076 */         if (!filter_isNull_6) {
/* 077 */           filter_isNull_5 = false; // resultCode could change nullability.
/* 078 */
/* 079 */           final int filter_index_0 = (int) 0;
/* 080 */           if (filter_index_0 >= filter_value_6.numElements() || filter_index_0 < 0 || filter_value_6.isNullAt(filter_index_0)) {
/* 081 */             filter_isNull_5 = true;
/* 082 */           } else {
/* 083 */             filter_value_5 = filter_value_6.getUTF8String(filter_index_0);
/* 084 */           }
/* 085 */
/* 086 */         }
/* 087 */         if (!(!filter_isNull_5)) continue;
/* 088 */
/* 089 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 090 */
/* 091 */         boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 092 */         UTF8String scan_value_2 = scan_isNull_2 ?
/* 093 */         null : (scan_row_0.getUTF8String(2));
/* 094 */         boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 095 */         UTF8String scan_value_3 = scan_isNull_3 ?
/* 096 */         null : (scan_row_0.getUTF8String(3));
/* 097 */
/* 098 */         boolean project_isNull_0 = true;
/* 099 */         UTF8String project_value_0 = null;
/* 100 */         boolean project_isNull_1 = true;
/* 101 */         ArrayData project_value_1 = null;
/* 102 */         Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_0);
/* 103 */
/* 104 */         UTF8String project_result_0 = null;
/* 105 */         try {
/* 106 */           project_result_0 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[1].apply(((scala.Function1) references[11] /* udf */).apply(project_arg_0));
/* 107 */         } catch (Exception e) {
/* 108 */           throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 109 */         }
/* 110 */
/* 111 */         boolean project_isNull_2 = project_result_0 == null;
/* 112 */         UTF8String project_value_2 = null;
/* 113 */         if (!project_isNull_2) {
/* 114 */           project_value_2 = project_result_0;
/* 115 */         }
/* 116 */         if (!project_isNull_2) {
/* 117 */           project_isNull_1 = false; // resultCode could change nullability.
/* 118 */           project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[12] /* literal */), -1));
/* 119 */
/* 120 */         }
/* 121 */         if (!project_isNull_1) {
/* 122 */           project_isNull_0 = false; // resultCode could change nullability.
/* 123 */
/* 124 */           final int project_index_0 = (int) 0;
/* 125 */           if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 126 */             project_isNull_0 = true;
/* 127 */           } else {
/* 128 */             project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 129 */           }
/* 130 */
/* 131 */         }
/* 132 */         Object project_arg_1 = scan_isNull_1 ? null : ((scala.Function1[]) references[13] /* converters */)[0].apply(scan_value_1);
/* 133 */         Object project_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[13] /* converters */)[1].apply(scan_value_0);
/* 134 */
/* 135 */         UTF8String project_result_1 = null;
/* 136 */         try {
/* 137 */           project_result_1 = (UTF8String)((scala.Function1[]) references[13] /* converters */)[2].apply(((scala.Function2) references[15] /* udf */).apply(project_arg_1, project_arg_2));
/* 138 */         } catch (Exception e) {
/* 139 */           throw new org.apache.spark.SparkException(((java.lang.String) references[14] /* errMsg */), e);
/* 140 */         }
/* 141 */
/* 142 */         boolean project_isNull_6 = project_result_1 == null;
/* 143 */         UTF8String project_value_6 = null;
/* 144 */         if (!project_isNull_6) {
/* 145 */           project_value_6 = project_result_1;
/* 146 */         }
/* 147 */         boolean project_isNull_12 = scan_isNull_3;
/* 148 */         double project_value_12 = -1.0;
/* 149 */         if (!scan_isNull_3) {
/* 150 */           try {
/* 151 */             project_value_12 = Double.valueOf(scan_value_3.toString());
/* 152 */           } catch (java.lang.NumberFormatException e) {
/* 153 */             project_isNull_12 = true;
/* 154 */           }
/* 155 */         }
/* 156 */         boolean project_value_10 = true;
/* 157 */
/* 158 */         if (!project_isNull_12) {
/* 159 */           boolean project_isNull_15 = scan_isNull_2;
/* 160 */           double project_value_15 = -1.0;
/* 161 */           if (!scan_isNull_2) {
/* 162 */             try {
/* 163 */               project_value_15 = Double.valueOf(scan_value_2.toString());
/* 164 */             } catch (java.lang.NumberFormatException e) {
/* 165 */               project_isNull_15 = true;
/* 166 */             }
/* 167 */           }
/* 168 */           project_value_10 = project_isNull_15;
/* 169 */         }
/* 170 */         boolean project_isNull_9 = false;
/* 171 */         UTF8String project_value_9 = null;
/* 172 */         if (!false && project_value_10) {
/* 173 */           project_isNull_9 = true;
/* 174 */           project_value_9 = ((UTF8String)null);
/* 175 */         } else {
/* 176 */           boolean project_isNull_19 = scan_isNull_3;
/* 177 */           double project_value_19 = -1.0;
/* 178 */           if (!scan_isNull_3) {
/* 179 */             try {
/* 180 */               project_value_19 = Double.valueOf(scan_value_3.toString());
/* 181 */             } catch (java.lang.NumberFormatException e) {
/* 182 */               project_isNull_19 = true;
/* 183 */             }
/* 184 */           }
/* 185 */           boolean project_isNull_21 = scan_isNull_2;
/* 186 */           double project_value_21 = -1.0;
/* 187 */           if (!scan_isNull_2) {
/* 188 */             try {
/* 189 */               project_value_21 = Double.valueOf(scan_value_2.toString());
/* 190 */             } catch (java.lang.NumberFormatException e) {
/* 191 */               project_isNull_21 = true;
/* 192 */             }
/* 193 */           }
/* 194 */           Object project_arg_3 = project_isNull_19 ? null : ((scala.Function1[]) references[16] /* converters */)[0].apply(project_value_19);
/* 195 */           Object project_arg_4 = project_isNull_21 ? null : ((scala.Function1[]) references[16] /* converters */)[1].apply(project_value_21);
/* 196 */
/* 197 */           UTF8String project_result_2 = null;
/* 198 */           try {
/* 199 */             project_result_2 = (UTF8String)((scala.Function1[]) references[16] /* converters */)[2].apply(((scala.Function2) references[18] /* udf */).apply(project_arg_3, project_arg_4));
/* 200 */           } catch (Exception e) {
/* 201 */             throw new org.apache.spark.SparkException(((java.lang.String) references[17] /* errMsg */), e);
/* 202 */           }
/* 203 */
/* 204 */           boolean project_isNull_18 = project_result_2 == null;
/* 205 */           UTF8String project_value_18 = null;
/* 206 */           if (!project_isNull_18) {
/* 207 */             project_value_18 = project_result_2;
/* 208 */           }
/* 209 */           project_isNull_9 = project_isNull_18;
/* 210 */           project_value_9 = project_value_18;
/* 211 */         }
/* 212 */         filter_mutableStateArray_0[1].reset();
/* 213 */
/* 214 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 215 */
/* 216 */         if (project_isNull_0) {
/* 217 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 218 */         } else {
/* 219 */           filter_mutableStateArray_0[1].write(0, project_value_0);
/* 220 */         }
/* 221 */
/* 222 */         if (project_isNull_6) {
/* 223 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 224 */         } else {
/* 225 */           filter_mutableStateArray_0[1].write(1, project_value_6);
/* 226 */         }
/* 227 */
/* 228 */         if (project_isNull_9) {
/* 229 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 230 */         } else {
/* 231 */           filter_mutableStateArray_0[1].write(2, project_value_9);
/* 232 */         }
/* 233 */         append((filter_mutableStateArray_0[1].getRow()));
/* 234 */
/* 235 */       } while(false);
/* 236 */       if (shouldStop()) return;
/* 237 */     }
/* 238 */   }
/* 239 */
/* 240 */ }

Block broadcast_13 stored as values in memory (estimated size 242.9 KB, free 1978.2 MB)
Put block broadcast_13 locally took  16 ms
Putting block broadcast_13 without replication took  16 ms
Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1978.2 MB)
Added broadcast_13_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.3 MB)
Updated info of block broadcast_13_piece0
Told master about block broadcast_13_piece0
Put block broadcast_13_piece0 locally took  16 ms
Putting block broadcast_13_piece0 without replication took  16 ms
Created broadcast 13 from run at ThreadPoolExecutor.java:1149
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$collect$2
Got cleaning task CleanAccum(141)
Cleaning accumulator 141
Cleaned accumulator 141
Got cleaning task CleanAccum(186)
Cleaning accumulator 186
Cleaned accumulator 186
Got cleaning task CleanAccum(185)
Cleaning accumulator 185
Cleaned accumulator 185
Got cleaning task CleanAccum(182)
Cleaning accumulator 182
Cleaned accumulator 182
Got cleaning task CleanAccum(174)
Cleaning accumulator 174
Cleaned accumulator 174
Got cleaning task CleanAccum(171)
Cleaning accumulator 171
Cleaned accumulator 171
Got cleaning task CleanAccum(135)
Cleaning accumulator 135
Cleaned accumulator 135
Got cleaning task CleanAccum(145)
Cleaning accumulator 145
Cleaned accumulator 145
Got cleaning task CleanAccum(198)
Cleaning accumulator 198
Cleaned accumulator 198
Got cleaning task CleanAccum(187)
Cleaning accumulator 187
Cleaned accumulator 187
Got cleaning task CleanBroadcast(11)
Cleaning broadcast 11
Unpersisting TorrentBroadcast 11
removing broadcast 11
Removing broadcast 11
Removing block broadcast_11
Block broadcast_11 of size 248760 dropped from memory (free 2074532520)
Removing block broadcast_11_piece0
Block broadcast_11_piece0 of size 20482 dropped from memory (free 2074553002)
Removed broadcast_11_piece0 on 192.168.1.13:20571 in memory (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_11_piece0
Told master about block broadcast_11_piece0
Done removing broadcast 11, response is 0
Sent response: 0 to 192.168.1.13:20530
 +++ Lambda closure ($anonfun$collect$2) is now cleaned +++
Cleaned broadcast 11
Got cleaning task CleanAccum(139)
Cleaning accumulator 139
Cleaned accumulator 139
Got cleaning task CleanAccum(192)
Cleaning accumulator 192
Cleaned accumulator 192
Got cleaning task CleanAccum(142)
Cleaning accumulator 142
Cleaned accumulator 142
Got cleaning task CleanAccum(194)
Cleaning accumulator 194
Cleaned accumulator 194
Got cleaning task CleanAccum(189)
Cleaning accumulator 189
Cleaned accumulator 189
Got cleaning task CleanAccum(193)
Cleaning accumulator 193
Cleaned accumulator 193
Got cleaning task CleanAccum(134)
Cleaning accumulator 134
Cleaned accumulator 134
Got cleaning task CleanAccum(138)
Cleaning accumulator 138
Cleaned accumulator 138
Got cleaning task CleanAccum(179)
Cleaning accumulator 179
Cleaned accumulator 179
Got cleaning task CleanAccum(131)
Cleaning accumulator 131
Cleaned accumulator 131
Got cleaning task CleanAccum(175)
Cleaning lambda: $anonfun$runJob$5
Cleaning accumulator 175
Cleaned accumulator 175
Got cleaning task CleanAccum(137)
Cleaning accumulator 137
Cleaned accumulator 137
Got cleaning task CleanAccum(129)
Cleaning accumulator 129
Cleaned accumulator 129
Got cleaning task CleanAccum(180)
Cleaning accumulator 180
Cleaned accumulator 180
Got cleaning task CleanAccum(190)
Cleaning accumulator 190
Cleaned accumulator 190
Got cleaning task CleanAccum(130)
Cleaning accumulator 130
Cleaned accumulator 130
Got cleaning task CleanAccum(128)
Cleaning accumulator 128
Cleaned accumulator 128
Got cleaning task CleanAccum(183)
Cleaning accumulator 183
Cleaned accumulator 183
Got cleaning task CleanAccum(140)
Cleaning accumulator 140
Cleaned accumulator 140
Got cleaning task CleanAccum(143)
Cleaning accumulator 143
Cleaned accumulator 143
Got cleaning task CleanAccum(173)
Cleaning accumulator 173
Cleaned accumulator 173
Got cleaning task CleanAccum(177)
Cleaning accumulator 177
Cleaned accumulator 177
Got cleaning task CleanAccum(195)
Cleaning accumulator 195
Cleaned accumulator 195
Got cleaning task CleanAccum(188)
Cleaning accumulator 188
Cleaned accumulator 188
Got cleaning task CleanAccum(133)
Cleaning accumulator 133
Cleaned accumulator 133
Got cleaning task CleanBroadcast(12)
Cleaning broadcast 12
Unpersisting TorrentBroadcast 12
removing broadcast 12
Removing broadcast 12
Removing block broadcast_12_piece0
Block broadcast_12_piece0 of size 8993 dropped from memory (free 2074561995)
Removed broadcast_12_piece0 on 192.168.1.13:20571 in memory (size: 8.8 KB, free: 1987.4 MB)
Updated info of block broadcast_12_piece0
Told master about block broadcast_12_piece0
Removing block broadcast_12
Block broadcast_12 of size 17976 dropped from memory (free 2074579971)
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Done removing broadcast 12, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 12
Got cleaning task CleanAccum(172)
Cleaning accumulator 172
Cleaned accumulator 172
Got cleaning task CleanAccum(191)
Cleaning accumulator 191
Cleaned accumulator 191
Got cleaning task CleanAccum(136)
Cleaning accumulator 136
Cleaned accumulator 136
Got cleaning task CleanAccum(196)
Cleaning accumulator 196
Cleaned accumulator 196
Got cleaning task CleanAccum(144)
Cleaning accumulator 144
Cleaned accumulator 144
Got cleaning task CleanAccum(178)
Cleaning accumulator 178
Cleaned accumulator 178
Got cleaning task CleanAccum(132)
Cleaning accumulator 132
Cleaned accumulator 132
Got cleaning task CleanBroadcast(8)
Starting job: run at ThreadPoolExecutor.java:1149
Cleaning broadcast 8
Unpersisting TorrentBroadcast 8
removing broadcast 8
Removing broadcast 8
Removing block broadcast_8
Got job 5 (run at ThreadPoolExecutor.java:1149) with 3 output partitions
Final stage: ResultStage 6 (run at ThreadPoolExecutor.java:1149)
Parents of final stage: List()
Block broadcast_8 of size 248760 dropped from memory (free 2074828731)
Missing parents: List()
Removing block broadcast_8_piece0
submitStage(ResultStage 6)
Block broadcast_8_piece0 of size 20482 dropped from memory (free 2074849213)
missing: List()
Submitting ResultStage 6 (MapPartitionsRDD[27] at run at ThreadPoolExecutor.java:1149), which has no missing parents
submitMissingTasks(ResultStage 6)
Removed broadcast_8_piece0 on 192.168.1.13:20571 in memory (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_8_piece0
Told master about block broadcast_8_piece0
Done removing broadcast 8, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 8
Got cleaning task CleanAccum(184)
Cleaning accumulator 184
Cleaned accumulator 184
Got cleaning task CleanAccum(176)
Cleaning accumulator 176
Cleaned accumulator 176
Got cleaning task CleanAccum(181)
Cleaning accumulator 181
Cleaned accumulator 181
Got cleaning task CleanBroadcast(10)
Cleaning broadcast 10
Unpersisting TorrentBroadcast 10
Block broadcast_14 stored as values in memory (estimated size 22.5 KB, free 1978.7 MB)
removing broadcast 10
Removing broadcast 10
Removing block broadcast_10
Block broadcast_10 of size 8454168 dropped from memory (free 2083280381)
Put block broadcast_14 locally took  0 ms
Removing block broadcast_10_piece0
Putting block broadcast_14 without replication took  0 ms
Block broadcast_10_piece0 of size 23138 dropped from memory (free 2083303519)
Removed broadcast_10_piece0 on 192.168.1.13:20571 in memory (size: 22.6 KB, free: 1987.4 MB)
Updated info of block broadcast_10_piece0
Told master about block broadcast_10_piece0
Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.8 KB, free 1986.8 MB)
Done removing broadcast 10, response is 0
Added broadcast_14_piece0 in memory on 192.168.1.13:20571 (size: 9.8 KB, free: 1987.4 MB)
Sent response: 0 to 192.168.1.13:20530
Updated info of block broadcast_14_piece0
Told master about block broadcast_14_piece0
Put block broadcast_14_piece0 locally took  0 ms
Putting block broadcast_14_piece0 without replication took  0 ms
Created broadcast 14 from broadcast at DAGScheduler.scala:1161
Cleaned broadcast 10
Submitting 3 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 6.0 with 3 tasks
Epoch for TaskSet 6.0: 1
Valid locality levels for TaskSet 6.0: NO_PREF, ANY
parentName: , name: TaskSet_6.0, runningTasks: 0
Starting task 0.0 in stage 6.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
Starting task 1.0 in stage 6.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 7830 bytes)
Starting task 2.0 in stage 6.0 (TID 12, localhost, executor driver, partition 2, PROCESS_LOCAL, 7828 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 6.0 (TID 10)
Running task 2.0 in stage 6.0 (TID 12)
Running task 1.0 in stage 6.0 (TID 11)
Getting local block broadcast_14
Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_13
Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 1.0 in stage 6.0 (TID 11). 7186 bytes result sent to driver
parentName: , name: TaskSet_6.0, runningTasks: 2
Finished task 1.0 in stage 6.0 (TID 11) in 62 ms on localhost (executor driver) (1/3)
Finished task 0.0 in stage 6.0 (TID 10). 7321 bytes result sent to driver
parentName: , name: TaskSet_6.0, runningTasks: 1
Finished task 0.0 in stage 6.0 (TID 10) in 94 ms on localhost (executor driver) (2/3)
Finished task 2.0 in stage 6.0 (TID 12). 7098 bytes result sent to driver
parentName: , name: TaskSet_6.0, runningTasks: 0
Finished task 2.0 in stage 6.0 (TID 12) in 94 ms on localhost (executor driver) (3/3)
Removed TaskSet 6.0, whose tasks have all completed, from pool 
ResultStage 6 (run at ThreadPoolExecutor.java:1149) finished in 0.110 s
After removal of stage 6, remaining stages = 0
Job 5 finished: run at ThreadPoolExecutor.java:1149, took 0.108320 s
Task 0 acquired 32.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1065084
code for cast(input[1, string, true] as date),input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(1);
/* 032 */     UTF8String value_1 = isNull_1 ?
/* 033 */     null : (i.getUTF8String(1));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     int value_0 = -1;
/* 036 */     if (!isNull_1) {
/* 037 */       scala.Option<Integer> intOpt_0 =
/* 038 */       org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(value_1);
/* 039 */       if (intOpt_0.isDefined()) {
/* 040 */         value_0 = ((Integer) intOpt_0.get()).intValue();
/* 041 */       } else {
/* 042 */         isNull_0 = true;
/* 043 */       }
/* 044 */     }
/* 045 */     if (isNull_0) {
/* 046 */       mutableStateArray_0[0].setNullAt(0);
/* 047 */     } else {
/* 048 */       mutableStateArray_0[0].write(0, value_0);
/* 049 */     }
/* 050 */
/* 051 */     boolean isNull_2 = i.isNullAt(0);
/* 052 */     UTF8String value_2 = isNull_2 ?
/* 053 */     null : (i.getUTF8String(0));
/* 054 */     if (isNull_2) {
/* 055 */       mutableStateArray_0[0].setNullAt(1);
/* 056 */     } else {
/* 057 */       mutableStateArray_0[0].write(1, value_2);
/* 058 */     }
/* 059 */     return (mutableStateArray_0[0].getRow());
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

Task 0 acquired 8.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@1065084
Task 0 acquired 64.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1065084
Task 0 release 32.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1065084
Block broadcast_15 stored as values in memory (estimated size 8.1 MB, free 1978.7 MB)
Put block broadcast_15 locally took  0 ms
Putting block broadcast_15 without replication took  0 ms
Block broadcast_15_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1978.7 MB)
Added broadcast_15_piece0 in memory on 192.168.1.13:20571 (size: 22.7 KB, free: 1987.4 MB)
Updated info of block broadcast_15_piece0
Told master about block broadcast_15_piece0
Put block broadcast_15_piece0 locally took  0 ms
Putting block broadcast_15_piece0 without replication took  0 ms
Created broadcast 15 from run at ThreadPoolExecutor.java:1149
Getting local block broadcast_15
Level for block broadcast_15 is StorageLevel(disk, memory, deserialized, 1 replicas)

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 011 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     wholestagecodegen_init_0_0();
/* 021 */     wholestagecodegen_init_0_1();
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   private void wholestagecodegen_init_0_1() {
/* 026 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(5, 160);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   protected void processNext() throws java.io.IOException {
/* 031 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 032 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 033 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 034 */       do {
/* 035 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 036 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 037 */         null : (scan_row_0.getUTF8String(1));
/* 038 */
/* 039 */         if (!(!scan_isNull_1)) continue;
/* 040 */
/* 041 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 042 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 043 */         null : (scan_row_0.getUTF8String(0));
/* 044 */
/* 045 */         if (!(!scan_isNull_0)) continue;
/* 046 */
/* 047 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 048 */
/* 049 */         // generate join key for stream side
/* 050 */         filter_mutableStateArray_0[2].reset();
/* 051 */
/* 052 */         filter_mutableStateArray_0[2].zeroOutNullBytes();
/* 053 */
/* 054 */         boolean bhj_isNull_0 = false;
/* 055 */         int bhj_value_0 = -1;
/* 056 */         if (!false) {
/* 057 */           scala.Option<Integer> bhj_intOpt_0 =
/* 058 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(scan_value_1);
/* 059 */           if (bhj_intOpt_0.isDefined()) {
/* 060 */             bhj_value_0 = ((Integer) bhj_intOpt_0.get()).intValue();
/* 061 */           } else {
/* 062 */             bhj_isNull_0 = true;
/* 063 */           }
/* 064 */         }
/* 065 */         if (bhj_isNull_0) {
/* 066 */           filter_mutableStateArray_0[2].setNullAt(0);
/* 067 */         } else {
/* 068 */           filter_mutableStateArray_0[2].write(0, bhj_value_0);
/* 069 */         }
/* 070 */
/* 071 */         if (false) {
/* 072 */           filter_mutableStateArray_0[2].setNullAt(1);
/* 073 */         } else {
/* 074 */           filter_mutableStateArray_0[2].write(1, scan_value_0);
/* 075 */         }
/* 076 */         // find matches from HashedRelation
/* 077 */         UnsafeRow bhj_matched_0 = (filter_mutableStateArray_0[2].getRow()).anyNull() ? null: (UnsafeRow)bhj_relation_0.getValue((filter_mutableStateArray_0[2].getRow()));
/* 078 */         if (bhj_matched_0 != null) {
/* 079 */           {
/* 080 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 081 */
/* 082 */             boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 083 */             UTF8String scan_value_2 = scan_isNull_2 ?
/* 084 */             null : (scan_row_0.getUTF8String(2));
/* 085 */             boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 086 */             UTF8String scan_value_3 = scan_isNull_3 ?
/* 087 */             null : (scan_row_0.getUTF8String(3));
/* 088 */             boolean project_isNull_12 = true;
/* 089 */             UTF8String project_value_12 = null;
/* 090 */             boolean bhj_isNull_5 = bhj_matched_0.isNullAt(2);
/* 091 */             UTF8String bhj_value_5 = bhj_isNull_5 ?
/* 092 */             null : (bhj_matched_0.getUTF8String(2));
/* 093 */             if (!bhj_isNull_5) {
/* 094 */               project_isNull_12 = false; // resultCode could change nullability.
/* 095 */               project_value_12 = bhj_value_5.replace(((UTF8String) references[5] /* literal */), ((UTF8String) references[6] /* literal */));
/* 096 */
/* 097 */             }
/* 098 */             filter_mutableStateArray_0[4].reset();
/* 099 */
/* 100 */             filter_mutableStateArray_0[4].zeroOutNullBytes();
/* 101 */
/* 102 */             if (false) {
/* 103 */               filter_mutableStateArray_0[4].setNullAt(0);
/* 104 */             } else {
/* 105 */               filter_mutableStateArray_0[4].write(0, scan_value_0);
/* 106 */             }
/* 107 */
/* 108 */             if (false) {
/* 109 */               filter_mutableStateArray_0[4].setNullAt(1);
/* 110 */             } else {
/* 111 */               filter_mutableStateArray_0[4].write(1, scan_value_1);
/* 112 */             }
/* 113 */
/* 114 */             if (scan_isNull_2) {
/* 115 */               filter_mutableStateArray_0[4].setNullAt(2);
/* 116 */             } else {
/* 117 */               filter_mutableStateArray_0[4].write(2, scan_value_2);
/* 118 */             }
/* 119 */
/* 120 */             if (scan_isNull_3) {
/* 121 */               filter_mutableStateArray_0[4].setNullAt(3);
/* 122 */             } else {
/* 123 */               filter_mutableStateArray_0[4].write(3, scan_value_3);
/* 124 */             }
/* 125 */
/* 126 */             if (project_isNull_12) {
/* 127 */               filter_mutableStateArray_0[4].setNullAt(4);
/* 128 */             } else {
/* 129 */               filter_mutableStateArray_0[4].write(4, project_value_12);
/* 130 */             }
/* 131 */             append((filter_mutableStateArray_0[4].getRow()));
/* 132 */
/* 133 */           }
/* 134 */         }
/* 135 */
/* 136 */       } while(false);
/* 137 */       if (shouldStop()) return;
/* 138 */     }
/* 139 */   }
/* 140 */
/* 141 */   private void wholestagecodegen_init_0_0() {
/* 142 */     scan_mutableStateArray_0[0] = inputs[0];
/* 143 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 144 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 145 */
/* 146 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[2] /* broadcast */).value()).asReadOnlyCopy();
/* 147 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 148 */
/* 149 */     org.apache.spark.TaskContext$.MODULE$.get().addTaskCompletionListener(new org.apache.spark.util.TaskCompletionListener() {
/* 150 */         @Override
/* 151 */         public void onTaskCompletion(org.apache.spark.TaskContext context) {
/* 152 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */).set(bhj_relation_0.getAverageProbesPerLookup());
/* 153 */         }
/* 154 */       });
/* 155 */
/* 156 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 157 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 158 */
/* 159 */   }
/* 160 */
/* 161 */ }

Block broadcast_16 stored as values in memory (estimated size 242.9 KB, free 1978.5 MB)
Put block broadcast_16 locally took  0 ms
Putting block broadcast_16 without replication took  0 ms
Got cleaning task CleanAccum(238)
Cleaning accumulator 238
Cleaned accumulator 238
Got cleaning task CleanAccum(233)
Cleaning accumulator 233
Cleaned accumulator 233
Got cleaning task CleanAccum(232)
Cleaning accumulator 232
Cleaned accumulator 232
Got cleaning task CleanAccum(226)
Cleaning accumulator 226
Cleaned accumulator 226
Got cleaning task CleanAccum(222)
Cleaning accumulator 222
Cleaned accumulator 222
Got cleaning task CleanAccum(227)
Cleaning accumulator 227
Cleaned accumulator 227
Got cleaning task CleanAccum(230)
Cleaning accumulator 230
Cleaned accumulator 230
Got cleaning task CleanAccum(241)
Cleaning accumulator 241
Cleaned accumulator 241
Got cleaning task CleanAccum(235)
Cleaning accumulator 235
Cleaned accumulator 235
Got cleaning task CleanBroadcast(14)
Cleaning broadcast 14
Unpersisting TorrentBroadcast 14
removing broadcast 14
Removing broadcast 14
Removing block broadcast_14
Block broadcast_14 of size 23000 dropped from memory (free 2074590339)
Removing block broadcast_14_piece0
Block broadcast_14_piece0 of size 10051 dropped from memory (free 2074600390)
Removed broadcast_14_piece0 on 192.168.1.13:20571 in memory (size: 9.8 KB, free: 1987.4 MB)
Updated info of block broadcast_14_piece0
Told master about block broadcast_14_piece0
Done removing broadcast 14, response is 0
Sent response: 0 to 192.168.1.13:20530
Cleaned broadcast 14
Got cleaning task CleanAccum(242)
Cleaning accumulator 242
Cleaned accumulator 242
Got cleaning task CleanAccum(234)
Cleaning accumulator 234
Cleaned accumulator 234
Got cleaning task CleanAccum(229)
Cleaning accumulator 229
Cleaned accumulator 229
Got cleaning task CleanAccum(240)
Cleaning accumulator 240
Cleaned accumulator 240
Got cleaning task CleanAccum(223)
Cleaning accumulator 223
Cleaned accumulator 223
Got cleaning task CleanAccum(244)
Cleaning accumulator 244
Cleaned accumulator 244
Got cleaning task CleanAccum(245)
Cleaning accumulator 245
Cleaned accumulator 245
Got cleaning task CleanAccum(225)
Cleaning accumulator 225
Cleaned accumulator 225
Got cleaning task CleanAccum(231)
Cleaning accumulator 231
Cleaned accumulator 231
Got cleaning task CleanAccum(224)
Cleaning accumulator 224
Cleaned accumulator 224
Got cleaning task CleanAccum(228)
Cleaning accumulator 228
Cleaned accumulator 228
Got cleaning task CleanAccum(237)
Cleaning accumulator 237
Cleaned accumulator 237
Got cleaning task CleanAccum(236)
Cleaning accumulator 236
Cleaned accumulator 236
Got cleaning task CleanAccum(239)
Cleaning accumulator 239
Cleaned accumulator 239
Got cleaning task CleanAccum(243)
Cleaning accumulator 243
Cleaned accumulator 243
Got cleaning task CleanAccum(246)
Cleaning accumulator 246
Cleaned accumulator 246
Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1978.5 MB)
Added broadcast_16_piece0 in memory on 192.168.1.13:20571 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_16_piece0
Told master about block broadcast_16_piece0
Put block broadcast_16_piece0 locally took  0 ms
Putting block broadcast_16_piece0 without replication took  0 ms
Created broadcast 16 from csv at SparkUtiles.scala:37
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$write$15
 +++ Lambda closure ($anonfun$write$15) is now cleaned +++
Starting job: csv at SparkUtiles.scala:37
Registering RDD 30 (csv at SparkUtiles.scala:37)
Got job 6 (csv at SparkUtiles.scala:37) with 1 output partitions
Final stage: ResultStage 8 (csv at SparkUtiles.scala:37)
Parents of final stage: List(ShuffleMapStage 7)
Missing parents: List(ShuffleMapStage 7)
submitStage(ResultStage 8)
missing: List(ShuffleMapStage 7)
submitStage(ShuffleMapStage 7)
missing: List()
Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ShuffleMapStage 7)
Block broadcast_17 stored as values in memory (estimated size 18.4 KB, free 1978.5 MB)
Put block broadcast_17 locally took  0 ms
Putting block broadcast_17 without replication took  0 ms
Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1978.4 MB)
Added broadcast_17_piece0 in memory on 192.168.1.13:20571 (size: 9.3 KB, free: 1987.4 MB)
Updated info of block broadcast_17_piece0
Told master about block broadcast_17_piece0
Put block broadcast_17_piece0 locally took  0 ms
Putting block broadcast_17_piece0 without replication took  0 ms
Created broadcast 17 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 7.0 with 3 tasks
Epoch for TaskSet 7.0: 1
Valid locality levels for TaskSet 7.0: NO_PREF, ANY
parentName: , name: TaskSet_7.0, runningTasks: 0
Starting task 0.0 in stage 7.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7820 bytes)
Starting task 1.0 in stage 7.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 7819 bytes)
Starting task 2.0 in stage 7.0 (TID 15, localhost, executor driver, partition 2, PROCESS_LOCAL, 7817 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 2.0 in stage 7.0 (TID 15)
Running task 1.0 in stage 7.0 (TID 14)
Running task 0.0 in stage 7.0 (TID 13)
Getting local block broadcast_17
Level for block broadcast_17 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_16
Level for block broadcast_16 is StorageLevel(disk, memory, deserialized, 1 replicas)
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Finished task 0.0 in stage 7.0 (TID 13). 1659 bytes result sent to driver
parentName: , name: TaskSet_7.0, runningTasks: 2
Finished task 0.0 in stage 7.0 (TID 13) in 78 ms on localhost (executor driver) (1/3)
ShuffleMapTask finished on driver
Finished task 1.0 in stage 7.0 (TID 14). 1659 bytes result sent to driver
parentName: , name: TaskSet_7.0, runningTasks: 1
Finished task 1.0 in stage 7.0 (TID 14) in 94 ms on localhost (executor driver) (2/3)
ShuffleMapTask finished on driver
Finished task 2.0 in stage 7.0 (TID 15). 1659 bytes result sent to driver
parentName: , name: TaskSet_7.0, runningTasks: 0
Finished task 2.0 in stage 7.0 (TID 15) in 94 ms on localhost (executor driver) (3/3)
Removed TaskSet 7.0, whose tasks have all completed, from pool 
ShuffleMapTask finished on driver
ShuffleMapStage 7 (csv at SparkUtiles.scala:37) finished in 0.094 s
looking for newly runnable stages
running: Set()
waiting: Set(ResultStage 8)
failed: Set()
Increasing epoch to 2
submitStage(ResultStage 8)
missing: List()
Submitting ResultStage 8 (ShuffledRowRDD[31] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ResultStage 8)
Block broadcast_18 stored as values in memory (estimated size 129.5 KB, free 1978.3 MB)
Put block broadcast_18 locally took  0 ms
Putting block broadcast_18 without replication took  0 ms
Block broadcast_18_piece0 stored as bytes in memory (estimated size 45.8 KB, free 1978.3 MB)
Added broadcast_18_piece0 in memory on 192.168.1.13:20571 (size: 45.8 KB, free: 1987.3 MB)
Updated info of block broadcast_18_piece0
Told master about block broadcast_18_piece0
Put block broadcast_18_piece0 locally took  0 ms
Putting block broadcast_18_piece0 without replication took  0 ms
Created broadcast 18 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 8 (ShuffledRowRDD[31] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0))
Adding task set 8.0 with 1 tasks
Epoch for TaskSet 8.0: 2
Valid locality levels for TaskSet 8.0: ANY
parentName: , name: TaskSet_8.0, runningTasks: 0
Starting task 0.0 in stage 8.0 (TID 16, localhost, executor driver, partition 0, ANY, 7246 bytes)
Running task 0.0 in stage 8.0 (TID 16)
Getting local block broadcast_18
Level for block broadcast_18 is StorageLevel(disk, memory, deserialized, 1 replicas)
Fetching outputs for shuffle 1, partitions 0-1
maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
Getting 3 non-empty blocks including 3 local blocks and 0 remote blocks
Started 0 remote fetches in 0 ms
Start fetching local blocks: shuffle_1_0_0, shuffle_1_1_0, shuffle_1_2_0
Got local blocks in  0 ms
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Commit allowed for stage=8.0, partition=0, task attempt 0
Saved output of task 'attempt_20190331133205_0008_m_000000_0' to file:/D:/p1/weather-simulator/src/main/resources/verify/_temporary/0/task_20190331133205_0008_m_000000
attempt_20190331133205_0008_m_000000_0: Committed
Finished task 0.0 in stage 8.0 (TID 16). 2215 bytes result sent to driver
parentName: , name: TaskSet_8.0, runningTasks: 0
Finished task 0.0 in stage 8.0 (TID 16) in 31 ms on localhost (executor driver) (1/1)
Removed TaskSet 8.0, whose tasks have all completed, from pool 
ResultStage 8 (csv at SparkUtiles.scala:37) finished in 0.062 s
After removal of stage 8, remaining stages = 1
After removal of stage 7, remaining stages = 0
Job 6 finished: csv at SparkUtiles.scala:37, took 0.161334 s
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/verify/_temporary/0/task_20190331133205_0008_m_000000; isDirectory=true; modification_time=1553999525425; access_time=1553999525425; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/verify
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/verify/_temporary/0/task_20190331133205_0008_m_000000/part-00000-ed31ba26-4daf-4e3a-8a7e-4a9339999086-c000.csv; isDirectory=false; length=38501; replication=1; blocksize=33554432; modification_time=1553999525440; access_time=1553999525425; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/verify/part-00000-ed31ba26-4daf-4e3a-8a7e-4a9339999086-c000.csv
Committing files staged for absolute locations Map()
Write Job d9782676-afeb-44bd-8748-2393a6e12c4f committed.
Finished processing stats for write job d9782676-afeb-44bd-8748-2393a6e12c4f.
stopping org.spark_project.jetty.server.Server@422c3c7a
doStop org.spark_project.jetty.server.Server@422c3c7a
ran SparkUI-338-acceptor-0@50fe837a-ServerConnector@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
Graceful shutdown org.spark_project.jetty.server.Server@422c3c7a by 
stopping Spark@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d
stopping org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1b79df53 on org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1b79df53
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3ec211cc on org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3ec211cc
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1f03a118 produced null
Stopped org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1f03a118 produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@a8c1f44 id=3 keys=-1 selected=-1
stopping org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@6b94c200 on org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@6b94c200
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@1322b542 on org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@1322b542
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@30457a4c produced null
Stopped org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@30457a4c produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@71b3bc45 id=2 keys=-1 selected=-1
stopping org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@6a97517 on org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@6a97517
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@284b487f on org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@284b487f
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@42657f2d produced null
Stopped org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@42657f2d produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@73db4768 id=1 keys=-1 selected=-1
stopping org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@65021bb4 on org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@65021bb4
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@630c3af3 on org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@630c3af3
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4101ae38 produced null
Stopped org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4101ae38 produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@4c37b5b id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@239b0f9d
stopping HttpConnectionFactory@1e63ec0b[HTTP/1.1]
STOPPED HttpConnectionFactory@1e63ec0b[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@45cff11c
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@45cff11c
Stopped Spark@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
STOPPED Spark@1b065145{HTTP/1.1,[http/1.1]}{0.0.0.0:4263}
stopping org.spark_project.jetty.server.Server@422c3c7a
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@19542407{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@19542407{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@726e5805[org.spark_project.jetty.server.handler.gzip.GzipHandler@62435e70, org.spark_project.jetty.server.handler.gzip.GzipHandler@4763c727, org.spark_project.jetty.server.handler.gzip.GzipHandler@15c25153, org.spark_project.jetty.server.handler.gzip.GzipHandler@36676c1a, org.spark_project.jetty.server.handler.gzip.GzipHandler@7fc44dec, org.spark_project.jetty.server.handler.gzip.GzipHandler@62fad19, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f2613d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@83298d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@665e9289, org.spark_project.jetty.server.handler.gzip.GzipHandler@69637b10, org.spark_project.jetty.server.handler.gzip.GzipHandler@6c8bca63, org.spark_project.jetty.server.handler.gzip.GzipHandler@2b491fee, org.spark_project.jetty.server.handler.gzip.GzipHandler@63192798, org.spark_project.jetty.server.handler.gzip.GzipHandler@28d6290, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ce3db41, org.spark_project.jetty.server.handler.gzip.GzipHandler@34a97744, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cac4385, org.spark_project.jetty.server.handler.gzip.GzipHandler@58bf8650, org.spark_project.jetty.server.handler.gzip.GzipHandler@2c104774, org.spark_project.jetty.server.handler.gzip.GzipHandler@5860f3d7, org.spark_project.jetty.server.handler.gzip.GzipHandler@24bdb479, org.spark_project.jetty.server.handler.gzip.GzipHandler@1991f767, org.spark_project.jetty.server.handler.gzip.GzipHandler@162be91c, org.spark_project.jetty.server.handler.gzip.GzipHandler@f74e835, org.spark_project.jetty.server.handler.gzip.GzipHandler@21d8bcbe, o.s.j.s.ServletContextHandler@5dda14d0{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3dedb4a6{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@49d98dc5{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1654a892{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@5f233b26{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@19542407{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@56bca85b
stopping org.spark_project.jetty.server.handler.ErrorHandler@56bca85b
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@56bca85b
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@422c3c7a
Stopped Spark web UI at http://192.168.1.13:4263
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\ywksu\AppData\Local\Temp\spark-cf9c1d68-a573-44e8-9426-e41f4b6dfbad
ShutdownHookManger complete shutdown.
