statis filename:Sydney, site_code:066062, start_date:2018-01-01, end_date:2018-12-31
Extracing statis for stn_num=066062&month=01&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=01
Extracing statis for stn_num=066062&month=01&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=02
Extracing statis for stn_num=066062&month=01&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=03
Extracing statis for stn_num=066062&month=01&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=04
Extracing statis for stn_num=066062&month=01&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=05
Extracing statis for stn_num=066062&month=01&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=06
Extracing statis for stn_num=066062&month=01&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=07
Extracing statis for stn_num=066062&month=01&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=08
Extracing statis for stn_num=066062&month=01&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=09
Extracing statis for stn_num=066062&month=01&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=10
Extracing statis for stn_num=066062&month=01&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=11
Extracing statis for stn_num=066062&month=01&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=12
Extracing statis for stn_num=066062&month=01&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=13
Extracing statis for stn_num=066062&month=01&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=14
Extracing statis for stn_num=066062&month=01&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=15
Extracing statis for stn_num=066062&month=01&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=16
Extracing statis for stn_num=066062&month=01&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=17
Extracing statis for stn_num=066062&month=01&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=18
Extracing statis for stn_num=066062&month=01&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=19
Extracing statis for stn_num=066062&month=01&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=20
Extracing statis for stn_num=066062&month=01&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=21
Extracing statis for stn_num=066062&month=01&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=22
Extracing statis for stn_num=066062&month=01&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=23
Extracing statis for stn_num=066062&month=01&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=24
Extracing statis for stn_num=066062&month=01&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=25
Extracing statis for stn_num=066062&month=01&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=26
Extracing statis for stn_num=066062&month=01&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=27
Extracing statis for stn_num=066062&month=01&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=28
Extracing statis for stn_num=066062&month=01&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=29
Extracing statis for stn_num=066062&month=01&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=30
Extracing statis for stn_num=066062&month=01&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=01&day=31
Extracing statis for stn_num=066062&month=02&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=01
Extracing statis for stn_num=066062&month=02&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=02
Extracing statis for stn_num=066062&month=02&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=03
Extracing statis for stn_num=066062&month=02&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=04
Extracing statis for stn_num=066062&month=02&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=05
Extracing statis for stn_num=066062&month=02&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=06
Extracing statis for stn_num=066062&month=02&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=07
Extracing statis for stn_num=066062&month=02&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=08
Extracing statis for stn_num=066062&month=02&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=09
Extracing statis for stn_num=066062&month=02&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=10
Extracing statis for stn_num=066062&month=02&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=11
Extracing statis for stn_num=066062&month=02&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=12
Extracing statis for stn_num=066062&month=02&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=13
Extracing statis for stn_num=066062&month=02&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=14
Extracing statis for stn_num=066062&month=02&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=15
Extracing statis for stn_num=066062&month=02&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=16
Extracing statis for stn_num=066062&month=02&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=17
Extracing statis for stn_num=066062&month=02&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=18
Extracing statis for stn_num=066062&month=02&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=19
Extracing statis for stn_num=066062&month=02&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=20
Extracing statis for stn_num=066062&month=02&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=21
Extracing statis for stn_num=066062&month=02&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=22
Extracing statis for stn_num=066062&month=02&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=23
Extracing statis for stn_num=066062&month=02&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=24
Extracing statis for stn_num=066062&month=02&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=25
Extracing statis for stn_num=066062&month=02&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=26
Extracing statis for stn_num=066062&month=02&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=27
Extracing statis for stn_num=066062&month=02&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=02&day=28
Extracing statis for stn_num=066062&month=03&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=01
Extracing statis for stn_num=066062&month=03&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=02
Extracing statis for stn_num=066062&month=03&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=03
Extracing statis for stn_num=066062&month=03&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=04
Extracing statis for stn_num=066062&month=03&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=05
Extracing statis for stn_num=066062&month=03&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=06
Extracing statis for stn_num=066062&month=03&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=07
Extracing statis for stn_num=066062&month=03&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=08
Extracing statis for stn_num=066062&month=03&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=09
Extracing statis for stn_num=066062&month=03&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=10
Extracing statis for stn_num=066062&month=03&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=11
Extracing statis for stn_num=066062&month=03&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=12
Extracing statis for stn_num=066062&month=03&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=13
Extracing statis for stn_num=066062&month=03&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=14
Extracing statis for stn_num=066062&month=03&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=15
Extracing statis for stn_num=066062&month=03&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=16
Extracing statis for stn_num=066062&month=03&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=17
Extracing statis for stn_num=066062&month=03&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=18
Extracing statis for stn_num=066062&month=03&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=19
Extracing statis for stn_num=066062&month=03&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=20
Extracing statis for stn_num=066062&month=03&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=21
Extracing statis for stn_num=066062&month=03&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=22
Extracing statis for stn_num=066062&month=03&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=23
Extracing statis for stn_num=066062&month=03&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=24
Extracing statis for stn_num=066062&month=03&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=25
Extracing statis for stn_num=066062&month=03&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=26
Extracing statis for stn_num=066062&month=03&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=27
Extracing statis for stn_num=066062&month=03&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=28
Extracing statis for stn_num=066062&month=03&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=29
Extracing statis for stn_num=066062&month=03&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=30
Extracing statis for stn_num=066062&month=03&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=03&day=31
Extracing statis for stn_num=066062&month=04&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=01
Extracing statis for stn_num=066062&month=04&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=02
Extracing statis for stn_num=066062&month=04&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=03
Extracing statis for stn_num=066062&month=04&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=04
Extracing statis for stn_num=066062&month=04&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=05
Extracing statis for stn_num=066062&month=04&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=06
Extracing statis for stn_num=066062&month=04&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=07
Extracing statis for stn_num=066062&month=04&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=08
Extracing statis for stn_num=066062&month=04&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=09
Extracing statis for stn_num=066062&month=04&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=10
Extracing statis for stn_num=066062&month=04&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=11
Extracing statis for stn_num=066062&month=04&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=12
Extracing statis for stn_num=066062&month=04&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=13
Extracing statis for stn_num=066062&month=04&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=14
Extracing statis for stn_num=066062&month=04&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=15
Extracing statis for stn_num=066062&month=04&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=16
Extracing statis for stn_num=066062&month=04&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=17
Extracing statis for stn_num=066062&month=04&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=18
Extracing statis for stn_num=066062&month=04&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=19
Extracing statis for stn_num=066062&month=04&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=20
Extracing statis for stn_num=066062&month=04&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=21
Extracing statis for stn_num=066062&month=04&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=22
Extracing statis for stn_num=066062&month=04&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=23
Extracing statis for stn_num=066062&month=04&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=24
Extracing statis for stn_num=066062&month=04&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=25
Extracing statis for stn_num=066062&month=04&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=26
Extracing statis for stn_num=066062&month=04&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=27
Extracing statis for stn_num=066062&month=04&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=28
Extracing statis for stn_num=066062&month=04&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=29
Extracing statis for stn_num=066062&month=04&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=04&day=30
Extracing statis for stn_num=066062&month=05&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=01
Extracing statis for stn_num=066062&month=05&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=02
Extracing statis for stn_num=066062&month=05&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=03
Extracing statis for stn_num=066062&month=05&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=04
Extracing statis for stn_num=066062&month=05&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=05
Extracing statis for stn_num=066062&month=05&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=06
Extracing statis for stn_num=066062&month=05&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=07
Extracing statis for stn_num=066062&month=05&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=08
Extracing statis for stn_num=066062&month=05&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=09
Extracing statis for stn_num=066062&month=05&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=10
Extracing statis for stn_num=066062&month=05&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=11
Extracing statis for stn_num=066062&month=05&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=12
Extracing statis for stn_num=066062&month=05&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=13
Extracing statis for stn_num=066062&month=05&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=14
Extracing statis for stn_num=066062&month=05&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=15
Extracing statis for stn_num=066062&month=05&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=16
Extracing statis for stn_num=066062&month=05&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=17
Extracing statis for stn_num=066062&month=05&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=18
Extracing statis for stn_num=066062&month=05&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=19
Extracing statis for stn_num=066062&month=05&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=20
Extracing statis for stn_num=066062&month=05&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=21
Extracing statis for stn_num=066062&month=05&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=22
Extracing statis for stn_num=066062&month=05&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=23
Extracing statis for stn_num=066062&month=05&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=24
Extracing statis for stn_num=066062&month=05&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=25
Extracing statis for stn_num=066062&month=05&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=26
Extracing statis for stn_num=066062&month=05&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=27
Extracing statis for stn_num=066062&month=05&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=28
Extracing statis for stn_num=066062&month=05&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=29
Extracing statis for stn_num=066062&month=05&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=30
Extracing statis for stn_num=066062&month=05&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=05&day=31
Extracing statis for stn_num=066062&month=06&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=01
Extracing statis for stn_num=066062&month=06&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=02
Extracing statis for stn_num=066062&month=06&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=03
Extracing statis for stn_num=066062&month=06&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=04
Extracing statis for stn_num=066062&month=06&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=05
Extracing statis for stn_num=066062&month=06&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=06
Extracing statis for stn_num=066062&month=06&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=07
Extracing statis for stn_num=066062&month=06&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=08
Extracing statis for stn_num=066062&month=06&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=09
Extracing statis for stn_num=066062&month=06&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=10
Extracing statis for stn_num=066062&month=06&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=11
Extracing statis for stn_num=066062&month=06&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=12
Extracing statis for stn_num=066062&month=06&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=13
Extracing statis for stn_num=066062&month=06&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=14
Extracing statis for stn_num=066062&month=06&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=15
Extracing statis for stn_num=066062&month=06&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=16
Extracing statis for stn_num=066062&month=06&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=17
Extracing statis for stn_num=066062&month=06&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=18
Extracing statis for stn_num=066062&month=06&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=19
Extracing statis for stn_num=066062&month=06&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=20
Extracing statis for stn_num=066062&month=06&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=21
Extracing statis for stn_num=066062&month=06&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=22
Extracing statis for stn_num=066062&month=06&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=23
Extracing statis for stn_num=066062&month=06&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=24
Extracing statis for stn_num=066062&month=06&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=25
Extracing statis for stn_num=066062&month=06&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=26
Extracing statis for stn_num=066062&month=06&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=27
Extracing statis for stn_num=066062&month=06&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=28
Extracing statis for stn_num=066062&month=06&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=29
Extracing statis for stn_num=066062&month=06&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=06&day=30
Extracing statis for stn_num=066062&month=07&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=01
Extracing statis for stn_num=066062&month=07&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=02
Extracing statis for stn_num=066062&month=07&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=03
Extracing statis for stn_num=066062&month=07&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=04
Extracing statis for stn_num=066062&month=07&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=05
Extracing statis for stn_num=066062&month=07&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=06
Extracing statis for stn_num=066062&month=07&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=07
Extracing statis for stn_num=066062&month=07&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=08
Extracing statis for stn_num=066062&month=07&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=09
Extracing statis for stn_num=066062&month=07&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=10
Extracing statis for stn_num=066062&month=07&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=11
Extracing statis for stn_num=066062&month=07&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=12
Extracing statis for stn_num=066062&month=07&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=13
Extracing statis for stn_num=066062&month=07&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=14
Extracing statis for stn_num=066062&month=07&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=15
Extracing statis for stn_num=066062&month=07&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=16
Extracing statis for stn_num=066062&month=07&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=17
Extracing statis for stn_num=066062&month=07&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=18
Extracing statis for stn_num=066062&month=07&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=19
Extracing statis for stn_num=066062&month=07&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=20
Extracing statis for stn_num=066062&month=07&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=21
Extracing statis for stn_num=066062&month=07&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=22
Extracing statis for stn_num=066062&month=07&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=23
Extracing statis for stn_num=066062&month=07&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=24
Extracing statis for stn_num=066062&month=07&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=25
Extracing statis for stn_num=066062&month=07&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=26
Extracing statis for stn_num=066062&month=07&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=27
Extracing statis for stn_num=066062&month=07&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=28
Extracing statis for stn_num=066062&month=07&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=29
Extracing statis for stn_num=066062&month=07&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=30
Extracing statis for stn_num=066062&month=07&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=07&day=31
Extracing statis for stn_num=066062&month=08&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=01
Extracing statis for stn_num=066062&month=08&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=02
Extracing statis for stn_num=066062&month=08&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=03
Extracing statis for stn_num=066062&month=08&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=04
Extracing statis for stn_num=066062&month=08&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=05
Extracing statis for stn_num=066062&month=08&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=06
Extracing statis for stn_num=066062&month=08&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=07
Extracing statis for stn_num=066062&month=08&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=08
Extracing statis for stn_num=066062&month=08&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=09
Extracing statis for stn_num=066062&month=08&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=10
Extracing statis for stn_num=066062&month=08&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=11
Extracing statis for stn_num=066062&month=08&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=12
Extracing statis for stn_num=066062&month=08&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=13
Extracing statis for stn_num=066062&month=08&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=14
Extracing statis for stn_num=066062&month=08&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=15
Extracing statis for stn_num=066062&month=08&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=16
Extracing statis for stn_num=066062&month=08&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=17
Extracing statis for stn_num=066062&month=08&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=18
Extracing statis for stn_num=066062&month=08&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=19
Extracing statis for stn_num=066062&month=08&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=20
Extracing statis for stn_num=066062&month=08&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=21
Extracing statis for stn_num=066062&month=08&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=22
Extracing statis for stn_num=066062&month=08&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=23
Extracing statis for stn_num=066062&month=08&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=24
Extracing statis for stn_num=066062&month=08&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=25
Extracing statis for stn_num=066062&month=08&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=26
Extracing statis for stn_num=066062&month=08&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=27
Extracing statis for stn_num=066062&month=08&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=28
Extracing statis for stn_num=066062&month=08&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=29
Extracing statis for stn_num=066062&month=08&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=30
Extracing statis for stn_num=066062&month=08&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=08&day=31
Extracing statis for stn_num=066062&month=09&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=01
Extracing statis for stn_num=066062&month=09&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=02
Extracing statis for stn_num=066062&month=09&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=03
Extracing statis for stn_num=066062&month=09&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=04
Extracing statis for stn_num=066062&month=09&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=05
Extracing statis for stn_num=066062&month=09&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=06
Extracing statis for stn_num=066062&month=09&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=07
Extracing statis for stn_num=066062&month=09&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=08
Extracing statis for stn_num=066062&month=09&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=09
Extracing statis for stn_num=066062&month=09&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=10
Extracing statis for stn_num=066062&month=09&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=11
Extracing statis for stn_num=066062&month=09&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=12
Extracing statis for stn_num=066062&month=09&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=13
Extracing statis for stn_num=066062&month=09&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=14
Extracing statis for stn_num=066062&month=09&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=15
Extracing statis for stn_num=066062&month=09&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=16
Extracing statis for stn_num=066062&month=09&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=17
Extracing statis for stn_num=066062&month=09&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=18
Extracing statis for stn_num=066062&month=09&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=19
Extracing statis for stn_num=066062&month=09&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=20
Extracing statis for stn_num=066062&month=09&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=21
Extracing statis for stn_num=066062&month=09&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=22
Extracing statis for stn_num=066062&month=09&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=23
Extracing statis for stn_num=066062&month=09&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=24
Extracing statis for stn_num=066062&month=09&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=25
Extracing statis for stn_num=066062&month=09&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=26
Extracing statis for stn_num=066062&month=09&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=27
Extracing statis for stn_num=066062&month=09&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=28
Extracing statis for stn_num=066062&month=09&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=29
Extracing statis for stn_num=066062&month=09&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=09&day=30
Extracing statis for stn_num=066062&month=10&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=01
Extracing statis for stn_num=066062&month=10&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=02
Extracing statis for stn_num=066062&month=10&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=03
Extracing statis for stn_num=066062&month=10&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=04
Extracing statis for stn_num=066062&month=10&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=05
Extracing statis for stn_num=066062&month=10&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=06
Extracing statis for stn_num=066062&month=10&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=07
Extracing statis for stn_num=066062&month=10&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=08
Extracing statis for stn_num=066062&month=10&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=09
Extracing statis for stn_num=066062&month=10&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=10
Extracing statis for stn_num=066062&month=10&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=11
Extracing statis for stn_num=066062&month=10&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=12
Extracing statis for stn_num=066062&month=10&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=13
Extracing statis for stn_num=066062&month=10&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=14
Extracing statis for stn_num=066062&month=10&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=15
Extracing statis for stn_num=066062&month=10&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=16
Extracing statis for stn_num=066062&month=10&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=17
Extracing statis for stn_num=066062&month=10&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=18
Extracing statis for stn_num=066062&month=10&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=19
Extracing statis for stn_num=066062&month=10&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=20
Extracing statis for stn_num=066062&month=10&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=21
Extracing statis for stn_num=066062&month=10&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=22
Extracing statis for stn_num=066062&month=10&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=23
Extracing statis for stn_num=066062&month=10&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=24
Extracing statis for stn_num=066062&month=10&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=25
Extracing statis for stn_num=066062&month=10&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=26
Extracing statis for stn_num=066062&month=10&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=27
Extracing statis for stn_num=066062&month=10&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=28
Extracing statis for stn_num=066062&month=10&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=29
Extracing statis for stn_num=066062&month=10&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=30
Extracing statis for stn_num=066062&month=10&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=10&day=31
Extracing statis for stn_num=066062&month=11&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=01
Extracing statis for stn_num=066062&month=11&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=02
Extracing statis for stn_num=066062&month=11&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=03
Extracing statis for stn_num=066062&month=11&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=04
Extracing statis for stn_num=066062&month=11&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=05
Extracing statis for stn_num=066062&month=11&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=06
Extracing statis for stn_num=066062&month=11&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=07
Extracing statis for stn_num=066062&month=11&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=08
Extracing statis for stn_num=066062&month=11&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=09
Extracing statis for stn_num=066062&month=11&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=10
Extracing statis for stn_num=066062&month=11&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=11
Extracing statis for stn_num=066062&month=11&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=12
Extracing statis for stn_num=066062&month=11&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=13
Extracing statis for stn_num=066062&month=11&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=14
Extracing statis for stn_num=066062&month=11&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=15
Extracing statis for stn_num=066062&month=11&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=16
Extracing statis for stn_num=066062&month=11&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=17
Extracing statis for stn_num=066062&month=11&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=18
Extracing statis for stn_num=066062&month=11&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=19
Extracing statis for stn_num=066062&month=11&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=20
Extracing statis for stn_num=066062&month=11&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=21
Extracing statis for stn_num=066062&month=11&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=22
Extracing statis for stn_num=066062&month=11&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=23
Extracing statis for stn_num=066062&month=11&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=24
Extracing statis for stn_num=066062&month=11&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=25
Extracing statis for stn_num=066062&month=11&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=26
Extracing statis for stn_num=066062&month=11&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=27
Extracing statis for stn_num=066062&month=11&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=28
Extracing statis for stn_num=066062&month=11&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=29
Extracing statis for stn_num=066062&month=11&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=11&day=30
Extracing statis for stn_num=066062&month=12&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=01
Extracing statis for stn_num=066062&month=12&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=02
Extracing statis for stn_num=066062&month=12&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=03
Extracing statis for stn_num=066062&month=12&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=04
Extracing statis for stn_num=066062&month=12&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=05
Extracing statis for stn_num=066062&month=12&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=06
Extracing statis for stn_num=066062&month=12&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=07
Extracing statis for stn_num=066062&month=12&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=08
Extracing statis for stn_num=066062&month=12&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=09
Extracing statis for stn_num=066062&month=12&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=10
Extracing statis for stn_num=066062&month=12&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=11
Extracing statis for stn_num=066062&month=12&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=12
Extracing statis for stn_num=066062&month=12&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=13
Extracing statis for stn_num=066062&month=12&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=14
Extracing statis for stn_num=066062&month=12&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=15
Extracing statis for stn_num=066062&month=12&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=16
Extracing statis for stn_num=066062&month=12&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=17
Extracing statis for stn_num=066062&month=12&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=18
Extracing statis for stn_num=066062&month=12&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=19
Extracing statis for stn_num=066062&month=12&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=20
Extracing statis for stn_num=066062&month=12&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=21
Extracing statis for stn_num=066062&month=12&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=22
Extracing statis for stn_num=066062&month=12&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=23
Extracing statis for stn_num=066062&month=12&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=24
Extracing statis for stn_num=066062&month=12&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=25
Extracing statis for stn_num=066062&month=12&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=26
Extracing statis for stn_num=066062&month=12&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=27
Extracing statis for stn_num=066062&month=12&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=28
Extracing statis for stn_num=066062&month=12&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=29
Extracing statis for stn_num=066062&month=12&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=30
Extracing statis for stn_num=066062&month=12&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=066062&month=12&day=31
statis filename:Melbourne, site_code:086038, start_date:2018-01-01, end_date:2018-12-31
Extracing statis for stn_num=086038&month=01&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=01
Extracing statis for stn_num=086038&month=01&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=02
Extracing statis for stn_num=086038&month=01&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=03
Extracing statis for stn_num=086038&month=01&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=04
Extracing statis for stn_num=086038&month=01&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=05
Extracing statis for stn_num=086038&month=01&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=06
Extracing statis for stn_num=086038&month=01&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=07
Extracing statis for stn_num=086038&month=01&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=08
Extracing statis for stn_num=086038&month=01&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=09
Extracing statis for stn_num=086038&month=01&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=10
Extracing statis for stn_num=086038&month=01&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=11
Extracing statis for stn_num=086038&month=01&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=12
Extracing statis for stn_num=086038&month=01&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=13
Extracing statis for stn_num=086038&month=01&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=14
Extracing statis for stn_num=086038&month=01&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=15
Extracing statis for stn_num=086038&month=01&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=16
Extracing statis for stn_num=086038&month=01&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=17
Extracing statis for stn_num=086038&month=01&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=18
Extracing statis for stn_num=086038&month=01&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=19
Extracing statis for stn_num=086038&month=01&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=20
Extracing statis for stn_num=086038&month=01&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=21
Extracing statis for stn_num=086038&month=01&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=22
Extracing statis for stn_num=086038&month=01&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=23
Extracing statis for stn_num=086038&month=01&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=24
Extracing statis for stn_num=086038&month=01&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=25
Extracing statis for stn_num=086038&month=01&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=26
Extracing statis for stn_num=086038&month=01&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=27
Extracing statis for stn_num=086038&month=01&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=28
Extracing statis for stn_num=086038&month=01&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=29
Extracing statis for stn_num=086038&month=01&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=30
Extracing statis for stn_num=086038&month=01&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=01&day=31
Extracing statis for stn_num=086038&month=02&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=01
Extracing statis for stn_num=086038&month=02&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=02
Extracing statis for stn_num=086038&month=02&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=03
Extracing statis for stn_num=086038&month=02&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=04
Extracing statis for stn_num=086038&month=02&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=05
Extracing statis for stn_num=086038&month=02&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=06
Extracing statis for stn_num=086038&month=02&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=07
Extracing statis for stn_num=086038&month=02&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=08
Extracing statis for stn_num=086038&month=02&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=09
Extracing statis for stn_num=086038&month=02&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=10
Extracing statis for stn_num=086038&month=02&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=11
Extracing statis for stn_num=086038&month=02&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=12
Extracing statis for stn_num=086038&month=02&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=13
Extracing statis for stn_num=086038&month=02&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=14
Extracing statis for stn_num=086038&month=02&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=15
Extracing statis for stn_num=086038&month=02&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=16
Extracing statis for stn_num=086038&month=02&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=17
Extracing statis for stn_num=086038&month=02&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=18
Extracing statis for stn_num=086038&month=02&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=19
Extracing statis for stn_num=086038&month=02&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=20
Extracing statis for stn_num=086038&month=02&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=21
Extracing statis for stn_num=086038&month=02&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=22
Extracing statis for stn_num=086038&month=02&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=23
Extracing statis for stn_num=086038&month=02&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=24
Extracing statis for stn_num=086038&month=02&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=25
Extracing statis for stn_num=086038&month=02&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=26
Extracing statis for stn_num=086038&month=02&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=27
Extracing statis for stn_num=086038&month=02&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=02&day=28
Extracing statis for stn_num=086038&month=03&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=01
Extracing statis for stn_num=086038&month=03&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=02
Extracing statis for stn_num=086038&month=03&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=03
Extracing statis for stn_num=086038&month=03&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=04
Extracing statis for stn_num=086038&month=03&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=05
Extracing statis for stn_num=086038&month=03&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=06
Extracing statis for stn_num=086038&month=03&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=07
Extracing statis for stn_num=086038&month=03&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=08
Extracing statis for stn_num=086038&month=03&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=09
Extracing statis for stn_num=086038&month=03&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=10
Extracing statis for stn_num=086038&month=03&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=11
Extracing statis for stn_num=086038&month=03&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=12
Extracing statis for stn_num=086038&month=03&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=13
Extracing statis for stn_num=086038&month=03&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=14
Extracing statis for stn_num=086038&month=03&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=15
Extracing statis for stn_num=086038&month=03&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=16
Extracing statis for stn_num=086038&month=03&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=17
Extracing statis for stn_num=086038&month=03&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=18
Extracing statis for stn_num=086038&month=03&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=19
Extracing statis for stn_num=086038&month=03&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=20
Extracing statis for stn_num=086038&month=03&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=21
Extracing statis for stn_num=086038&month=03&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=22
Extracing statis for stn_num=086038&month=03&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=23
Extracing statis for stn_num=086038&month=03&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=24
Extracing statis for stn_num=086038&month=03&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=25
Extracing statis for stn_num=086038&month=03&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=26
Extracing statis for stn_num=086038&month=03&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=27
Extracing statis for stn_num=086038&month=03&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=28
Extracing statis for stn_num=086038&month=03&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=29
Extracing statis for stn_num=086038&month=03&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=30
Extracing statis for stn_num=086038&month=03&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=03&day=31
Extracing statis for stn_num=086038&month=04&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=01
Extracing statis for stn_num=086038&month=04&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=02
Extracing statis for stn_num=086038&month=04&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=03
Extracing statis for stn_num=086038&month=04&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=04
Extracing statis for stn_num=086038&month=04&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=05
Extracing statis for stn_num=086038&month=04&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=06
Extracing statis for stn_num=086038&month=04&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=07
Extracing statis for stn_num=086038&month=04&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=08
Extracing statis for stn_num=086038&month=04&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=09
Extracing statis for stn_num=086038&month=04&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=10
Extracing statis for stn_num=086038&month=04&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=11
Extracing statis for stn_num=086038&month=04&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=12
Extracing statis for stn_num=086038&month=04&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=13
Extracing statis for stn_num=086038&month=04&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=14
Extracing statis for stn_num=086038&month=04&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=15
Extracing statis for stn_num=086038&month=04&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=16
Extracing statis for stn_num=086038&month=04&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=17
Extracing statis for stn_num=086038&month=04&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=18
Extracing statis for stn_num=086038&month=04&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=19
Extracing statis for stn_num=086038&month=04&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=20
Extracing statis for stn_num=086038&month=04&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=21
Extracing statis for stn_num=086038&month=04&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=22
Extracing statis for stn_num=086038&month=04&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=23
Extracing statis for stn_num=086038&month=04&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=24
Extracing statis for stn_num=086038&month=04&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=25
Extracing statis for stn_num=086038&month=04&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=26
Extracing statis for stn_num=086038&month=04&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=27
Extracing statis for stn_num=086038&month=04&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=28
Extracing statis for stn_num=086038&month=04&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=29
Extracing statis for stn_num=086038&month=04&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=04&day=30
Extracing statis for stn_num=086038&month=05&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=01
Extracing statis for stn_num=086038&month=05&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=02
Extracing statis for stn_num=086038&month=05&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=03
Extracing statis for stn_num=086038&month=05&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=04
Extracing statis for stn_num=086038&month=05&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=05
Extracing statis for stn_num=086038&month=05&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=06
Extracing statis for stn_num=086038&month=05&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=07
Extracing statis for stn_num=086038&month=05&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=08
Extracing statis for stn_num=086038&month=05&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=09
Extracing statis for stn_num=086038&month=05&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=10
Extracing statis for stn_num=086038&month=05&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=11
Extracing statis for stn_num=086038&month=05&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=12
Extracing statis for stn_num=086038&month=05&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=13
Extracing statis for stn_num=086038&month=05&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=14
Extracing statis for stn_num=086038&month=05&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=15
Extracing statis for stn_num=086038&month=05&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=16
Extracing statis for stn_num=086038&month=05&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=17
Extracing statis for stn_num=086038&month=05&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=18
Extracing statis for stn_num=086038&month=05&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=19
Extracing statis for stn_num=086038&month=05&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=20
Extracing statis for stn_num=086038&month=05&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=21
Extracing statis for stn_num=086038&month=05&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=22
Extracing statis for stn_num=086038&month=05&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=23
Extracing statis for stn_num=086038&month=05&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=24
Extracing statis for stn_num=086038&month=05&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=25
Extracing statis for stn_num=086038&month=05&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=26
Extracing statis for stn_num=086038&month=05&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=27
Extracing statis for stn_num=086038&month=05&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=28
Extracing statis for stn_num=086038&month=05&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=29
Extracing statis for stn_num=086038&month=05&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=30
Extracing statis for stn_num=086038&month=05&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=05&day=31
Extracing statis for stn_num=086038&month=06&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=01
Extracing statis for stn_num=086038&month=06&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=02
Extracing statis for stn_num=086038&month=06&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=03
Extracing statis for stn_num=086038&month=06&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=04
Extracing statis for stn_num=086038&month=06&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=05
Extracing statis for stn_num=086038&month=06&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=06
Extracing statis for stn_num=086038&month=06&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=07
Extracing statis for stn_num=086038&month=06&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=08
Extracing statis for stn_num=086038&month=06&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=09
Extracing statis for stn_num=086038&month=06&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=10
Extracing statis for stn_num=086038&month=06&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=11
Extracing statis for stn_num=086038&month=06&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=12
Extracing statis for stn_num=086038&month=06&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=13
Extracing statis for stn_num=086038&month=06&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=14
Extracing statis for stn_num=086038&month=06&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=15
Extracing statis for stn_num=086038&month=06&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=16
Extracing statis for stn_num=086038&month=06&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=17
Extracing statis for stn_num=086038&month=06&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=18
Extracing statis for stn_num=086038&month=06&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=19
Extracing statis for stn_num=086038&month=06&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=20
Extracing statis for stn_num=086038&month=06&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=21
Extracing statis for stn_num=086038&month=06&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=22
Extracing statis for stn_num=086038&month=06&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=23
Extracing statis for stn_num=086038&month=06&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=24
Extracing statis for stn_num=086038&month=06&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=25
Extracing statis for stn_num=086038&month=06&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=26
Extracing statis for stn_num=086038&month=06&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=27
Extracing statis for stn_num=086038&month=06&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=28
Extracing statis for stn_num=086038&month=06&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=29
Extracing statis for stn_num=086038&month=06&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=06&day=30
Extracing statis for stn_num=086038&month=07&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=01
Extracing statis for stn_num=086038&month=07&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=02
Extracing statis for stn_num=086038&month=07&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=03
Extracing statis for stn_num=086038&month=07&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=04
Extracing statis for stn_num=086038&month=07&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=05
Extracing statis for stn_num=086038&month=07&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=06
Extracing statis for stn_num=086038&month=07&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=07
Extracing statis for stn_num=086038&month=07&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=08
Extracing statis for stn_num=086038&month=07&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=09
Extracing statis for stn_num=086038&month=07&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=10
Extracing statis for stn_num=086038&month=07&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=11
Extracing statis for stn_num=086038&month=07&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=12
Extracing statis for stn_num=086038&month=07&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=13
Extracing statis for stn_num=086038&month=07&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=14
Extracing statis for stn_num=086038&month=07&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=15
Extracing statis for stn_num=086038&month=07&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=16
Extracing statis for stn_num=086038&month=07&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=17
Extracing statis for stn_num=086038&month=07&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=18
Extracing statis for stn_num=086038&month=07&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=19
Extracing statis for stn_num=086038&month=07&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=20
Extracing statis for stn_num=086038&month=07&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=21
Extracing statis for stn_num=086038&month=07&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=22
Extracing statis for stn_num=086038&month=07&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=23
Extracing statis for stn_num=086038&month=07&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=24
Extracing statis for stn_num=086038&month=07&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=25
Extracing statis for stn_num=086038&month=07&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=26
Extracing statis for stn_num=086038&month=07&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=27
Extracing statis for stn_num=086038&month=07&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=28
Extracing statis for stn_num=086038&month=07&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=29
Extracing statis for stn_num=086038&month=07&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=30
Extracing statis for stn_num=086038&month=07&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=07&day=31
Extracing statis for stn_num=086038&month=08&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=01
Extracing statis for stn_num=086038&month=08&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=02
Extracing statis for stn_num=086038&month=08&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=03
Extracing statis for stn_num=086038&month=08&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=04
Extracing statis for stn_num=086038&month=08&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=05
Extracing statis for stn_num=086038&month=08&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=06
Extracing statis for stn_num=086038&month=08&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=07
Extracing statis for stn_num=086038&month=08&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=08
Extracing statis for stn_num=086038&month=08&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=09
Extracing statis for stn_num=086038&month=08&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=10
Extracing statis for stn_num=086038&month=08&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=11
Extracing statis for stn_num=086038&month=08&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=12
Extracing statis for stn_num=086038&month=08&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=13
Extracing statis for stn_num=086038&month=08&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=14
Extracing statis for stn_num=086038&month=08&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=15
Extracing statis for stn_num=086038&month=08&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=16
Extracing statis for stn_num=086038&month=08&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=17
Extracing statis for stn_num=086038&month=08&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=18
Extracing statis for stn_num=086038&month=08&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=19
Extracing statis for stn_num=086038&month=08&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=20
Extracing statis for stn_num=086038&month=08&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=21
Extracing statis for stn_num=086038&month=08&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=22
Extracing statis for stn_num=086038&month=08&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=23
Extracing statis for stn_num=086038&month=08&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=24
Extracing statis for stn_num=086038&month=08&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=25
Extracing statis for stn_num=086038&month=08&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=26
Extracing statis for stn_num=086038&month=08&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=27
Extracing statis for stn_num=086038&month=08&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=28
Extracing statis for stn_num=086038&month=08&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=29
Extracing statis for stn_num=086038&month=08&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=30
Extracing statis for stn_num=086038&month=08&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=08&day=31
Extracing statis for stn_num=086038&month=09&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=01
Extracing statis for stn_num=086038&month=09&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=02
Extracing statis for stn_num=086038&month=09&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=03
Extracing statis for stn_num=086038&month=09&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=04
Extracing statis for stn_num=086038&month=09&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=05
Extracing statis for stn_num=086038&month=09&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=06
Extracing statis for stn_num=086038&month=09&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=07
Extracing statis for stn_num=086038&month=09&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=08
Extracing statis for stn_num=086038&month=09&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=09
Extracing statis for stn_num=086038&month=09&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=10
Extracing statis for stn_num=086038&month=09&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=11
Extracing statis for stn_num=086038&month=09&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=12
Extracing statis for stn_num=086038&month=09&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=13
Extracing statis for stn_num=086038&month=09&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=14
Extracing statis for stn_num=086038&month=09&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=15
Extracing statis for stn_num=086038&month=09&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=16
Extracing statis for stn_num=086038&month=09&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=17
Extracing statis for stn_num=086038&month=09&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=18
Extracing statis for stn_num=086038&month=09&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=19
Extracing statis for stn_num=086038&month=09&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=20
Extracing statis for stn_num=086038&month=09&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=21
Extracing statis for stn_num=086038&month=09&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=22
Extracing statis for stn_num=086038&month=09&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=23
Extracing statis for stn_num=086038&month=09&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=24
Extracing statis for stn_num=086038&month=09&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=25
Extracing statis for stn_num=086038&month=09&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=26
Extracing statis for stn_num=086038&month=09&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=27
Extracing statis for stn_num=086038&month=09&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=28
Extracing statis for stn_num=086038&month=09&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=29
Extracing statis for stn_num=086038&month=09&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=09&day=30
Extracing statis for stn_num=086038&month=10&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=01
Extracing statis for stn_num=086038&month=10&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=02
Extracing statis for stn_num=086038&month=10&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=03
Extracing statis for stn_num=086038&month=10&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=04
Extracing statis for stn_num=086038&month=10&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=05
Extracing statis for stn_num=086038&month=10&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=06
Extracing statis for stn_num=086038&month=10&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=07
Extracing statis for stn_num=086038&month=10&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=08
Extracing statis for stn_num=086038&month=10&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=09
Extracing statis for stn_num=086038&month=10&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=10
Extracing statis for stn_num=086038&month=10&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=11
Extracing statis for stn_num=086038&month=10&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=12
Extracing statis for stn_num=086038&month=10&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=13
Extracing statis for stn_num=086038&month=10&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=14
Extracing statis for stn_num=086038&month=10&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=15
Extracing statis for stn_num=086038&month=10&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=16
Extracing statis for stn_num=086038&month=10&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=17
Extracing statis for stn_num=086038&month=10&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=18
Extracing statis for stn_num=086038&month=10&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=19
Extracing statis for stn_num=086038&month=10&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=20
Extracing statis for stn_num=086038&month=10&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=21
Extracing statis for stn_num=086038&month=10&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=22
Extracing statis for stn_num=086038&month=10&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=23
Extracing statis for stn_num=086038&month=10&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=24
Extracing statis for stn_num=086038&month=10&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=25
Extracing statis for stn_num=086038&month=10&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=26
Extracing statis for stn_num=086038&month=10&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=27
Extracing statis for stn_num=086038&month=10&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=28
Extracing statis for stn_num=086038&month=10&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=29
Extracing statis for stn_num=086038&month=10&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=30
Extracing statis for stn_num=086038&month=10&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=10&day=31
Extracing statis for stn_num=086038&month=11&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=01
Extracing statis for stn_num=086038&month=11&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=02
Extracing statis for stn_num=086038&month=11&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=03
Extracing statis for stn_num=086038&month=11&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=04
Extracing statis for stn_num=086038&month=11&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=05
Extracing statis for stn_num=086038&month=11&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=06
Extracing statis for stn_num=086038&month=11&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=07
Extracing statis for stn_num=086038&month=11&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=08
Extracing statis for stn_num=086038&month=11&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=09
Extracing statis for stn_num=086038&month=11&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=10
Extracing statis for stn_num=086038&month=11&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=11
Extracing statis for stn_num=086038&month=11&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=12
Extracing statis for stn_num=086038&month=11&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=13
Extracing statis for stn_num=086038&month=11&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=14
Extracing statis for stn_num=086038&month=11&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=15
Extracing statis for stn_num=086038&month=11&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=16
Extracing statis for stn_num=086038&month=11&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=17
Extracing statis for stn_num=086038&month=11&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=18
Extracing statis for stn_num=086038&month=11&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=19
Extracing statis for stn_num=086038&month=11&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=20
Extracing statis for stn_num=086038&month=11&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=21
Extracing statis for stn_num=086038&month=11&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=22
Extracing statis for stn_num=086038&month=11&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=23
Extracing statis for stn_num=086038&month=11&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=24
Extracing statis for stn_num=086038&month=11&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=25
Extracing statis for stn_num=086038&month=11&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=26
Extracing statis for stn_num=086038&month=11&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=27
Extracing statis for stn_num=086038&month=11&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=28
Extracing statis for stn_num=086038&month=11&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=29
Extracing statis for stn_num=086038&month=11&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=11&day=30
Extracing statis for stn_num=086038&month=12&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=01
Extracing statis for stn_num=086038&month=12&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=02
Extracing statis for stn_num=086038&month=12&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=03
Extracing statis for stn_num=086038&month=12&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=04
Extracing statis for stn_num=086038&month=12&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=05
Extracing statis for stn_num=086038&month=12&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=06
Extracing statis for stn_num=086038&month=12&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=07
Extracing statis for stn_num=086038&month=12&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=08
Extracing statis for stn_num=086038&month=12&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=09
Extracing statis for stn_num=086038&month=12&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=10
Extracing statis for stn_num=086038&month=12&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=11
Extracing statis for stn_num=086038&month=12&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=12
Extracing statis for stn_num=086038&month=12&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=13
Extracing statis for stn_num=086038&month=12&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=14
Extracing statis for stn_num=086038&month=12&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=15
Extracing statis for stn_num=086038&month=12&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=16
Extracing statis for stn_num=086038&month=12&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=17
Extracing statis for stn_num=086038&month=12&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=18
Extracing statis for stn_num=086038&month=12&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=19
Extracing statis for stn_num=086038&month=12&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=20
Extracing statis for stn_num=086038&month=12&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=21
Extracing statis for stn_num=086038&month=12&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=22
Extracing statis for stn_num=086038&month=12&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=23
Extracing statis for stn_num=086038&month=12&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=24
Extracing statis for stn_num=086038&month=12&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=25
Extracing statis for stn_num=086038&month=12&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=26
Extracing statis for stn_num=086038&month=12&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=27
Extracing statis for stn_num=086038&month=12&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=28
Extracing statis for stn_num=086038&month=12&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=29
Extracing statis for stn_num=086038&month=12&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=30
Extracing statis for stn_num=086038&month=12&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=086038&month=12&day=31
statis filename:Adelaide, site_code:023000, start_date:2018-01-01, end_date:2018-12-31
Extracing statis for stn_num=023000&month=01&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=01
Extracing statis for stn_num=023000&month=01&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=02
Extracing statis for stn_num=023000&month=01&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=03
Extracing statis for stn_num=023000&month=01&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=04
Extracing statis for stn_num=023000&month=01&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=05
Extracing statis for stn_num=023000&month=01&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=06
Extracing statis for stn_num=023000&month=01&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=07
Extracing statis for stn_num=023000&month=01&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=08
Extracing statis for stn_num=023000&month=01&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=09
Extracing statis for stn_num=023000&month=01&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=10
Extracing statis for stn_num=023000&month=01&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=11
Extracing statis for stn_num=023000&month=01&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=12
Extracing statis for stn_num=023000&month=01&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=13
Extracing statis for stn_num=023000&month=01&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=14
Extracing statis for stn_num=023000&month=01&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=15
Extracing statis for stn_num=023000&month=01&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=16
Extracing statis for stn_num=023000&month=01&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=17
Extracing statis for stn_num=023000&month=01&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=18
Extracing statis for stn_num=023000&month=01&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=19
Extracing statis for stn_num=023000&month=01&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=20
Extracing statis for stn_num=023000&month=01&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=21
Extracing statis for stn_num=023000&month=01&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=22
Extracing statis for stn_num=023000&month=01&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=23
Extracing statis for stn_num=023000&month=01&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=24
Extracing statis for stn_num=023000&month=01&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=25
Extracing statis for stn_num=023000&month=01&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=26
Extracing statis for stn_num=023000&month=01&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=27
Extracing statis for stn_num=023000&month=01&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=28
Extracing statis for stn_num=023000&month=01&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=29
Extracing statis for stn_num=023000&month=01&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=30
Extracing statis for stn_num=023000&month=01&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=01&day=31
Extracing statis for stn_num=023000&month=02&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=01
Extracing statis for stn_num=023000&month=02&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=02
Extracing statis for stn_num=023000&month=02&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=03
Extracing statis for stn_num=023000&month=02&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=04
Extracing statis for stn_num=023000&month=02&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=05
Extracing statis for stn_num=023000&month=02&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=06
Extracing statis for stn_num=023000&month=02&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=07
Extracing statis for stn_num=023000&month=02&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=08
Extracing statis for stn_num=023000&month=02&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=09
Extracing statis for stn_num=023000&month=02&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=10
Extracing statis for stn_num=023000&month=02&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=11
Extracing statis for stn_num=023000&month=02&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=12
Extracing statis for stn_num=023000&month=02&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=13
Extracing statis for stn_num=023000&month=02&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=14
Extracing statis for stn_num=023000&month=02&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=15
Extracing statis for stn_num=023000&month=02&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=16
Extracing statis for stn_num=023000&month=02&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=17
Extracing statis for stn_num=023000&month=02&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=18
Extracing statis for stn_num=023000&month=02&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=19
Extracing statis for stn_num=023000&month=02&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=20
Extracing statis for stn_num=023000&month=02&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=21
Extracing statis for stn_num=023000&month=02&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=22
Extracing statis for stn_num=023000&month=02&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=23
Extracing statis for stn_num=023000&month=02&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=24
Extracing statis for stn_num=023000&month=02&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=25
Extracing statis for stn_num=023000&month=02&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=26
Extracing statis for stn_num=023000&month=02&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=27
Extracing statis for stn_num=023000&month=02&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=02&day=28
Extracing statis for stn_num=023000&month=03&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=01
Extracing statis for stn_num=023000&month=03&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=02
Extracing statis for stn_num=023000&month=03&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=03
Extracing statis for stn_num=023000&month=03&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=04
Extracing statis for stn_num=023000&month=03&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=05
Extracing statis for stn_num=023000&month=03&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=06
Extracing statis for stn_num=023000&month=03&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=07
Extracing statis for stn_num=023000&month=03&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=08
Extracing statis for stn_num=023000&month=03&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=09
Extracing statis for stn_num=023000&month=03&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=10
Extracing statis for stn_num=023000&month=03&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=11
Extracing statis for stn_num=023000&month=03&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=12
Extracing statis for stn_num=023000&month=03&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=13
Extracing statis for stn_num=023000&month=03&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=14
Extracing statis for stn_num=023000&month=03&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=15
Extracing statis for stn_num=023000&month=03&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=16
Extracing statis for stn_num=023000&month=03&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=17
Extracing statis for stn_num=023000&month=03&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=18
Extracing statis for stn_num=023000&month=03&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=19
Extracing statis for stn_num=023000&month=03&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=20
Extracing statis for stn_num=023000&month=03&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=21
Extracing statis for stn_num=023000&month=03&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=22
Extracing statis for stn_num=023000&month=03&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=23
Extracing statis for stn_num=023000&month=03&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=24
Extracing statis for stn_num=023000&month=03&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=25
Extracing statis for stn_num=023000&month=03&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=26
Extracing statis for stn_num=023000&month=03&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=27
Extracing statis for stn_num=023000&month=03&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=28
Extracing statis for stn_num=023000&month=03&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=29
Extracing statis for stn_num=023000&month=03&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=30
Extracing statis for stn_num=023000&month=03&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=03&day=31
Extracing statis for stn_num=023000&month=04&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=01
Extracing statis for stn_num=023000&month=04&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=02
Extracing statis for stn_num=023000&month=04&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=03
Extracing statis for stn_num=023000&month=04&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=04
Extracing statis for stn_num=023000&month=04&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=05
Extracing statis for stn_num=023000&month=04&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=06
Extracing statis for stn_num=023000&month=04&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=07
Extracing statis for stn_num=023000&month=04&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=08
Extracing statis for stn_num=023000&month=04&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=09
Extracing statis for stn_num=023000&month=04&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=10
Extracing statis for stn_num=023000&month=04&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=11
Extracing statis for stn_num=023000&month=04&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=12
Extracing statis for stn_num=023000&month=04&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=13
Extracing statis for stn_num=023000&month=04&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=14
Extracing statis for stn_num=023000&month=04&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=15
Extracing statis for stn_num=023000&month=04&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=16
Extracing statis for stn_num=023000&month=04&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=17
Extracing statis for stn_num=023000&month=04&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=18
Extracing statis for stn_num=023000&month=04&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=19
Extracing statis for stn_num=023000&month=04&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=20
Extracing statis for stn_num=023000&month=04&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=21
Extracing statis for stn_num=023000&month=04&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=22
Extracing statis for stn_num=023000&month=04&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=23
Extracing statis for stn_num=023000&month=04&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=24
Extracing statis for stn_num=023000&month=04&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=25
Extracing statis for stn_num=023000&month=04&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=26
Extracing statis for stn_num=023000&month=04&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=27
Extracing statis for stn_num=023000&month=04&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=28
Extracing statis for stn_num=023000&month=04&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=29
Extracing statis for stn_num=023000&month=04&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=04&day=30
Extracing statis for stn_num=023000&month=05&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=01
Extracing statis for stn_num=023000&month=05&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=02
Extracing statis for stn_num=023000&month=05&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=03
Extracing statis for stn_num=023000&month=05&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=04
Extracing statis for stn_num=023000&month=05&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=05
Extracing statis for stn_num=023000&month=05&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=06
Extracing statis for stn_num=023000&month=05&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=07
Extracing statis for stn_num=023000&month=05&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=08
Extracing statis for stn_num=023000&month=05&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=09
Extracing statis for stn_num=023000&month=05&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=10
Extracing statis for stn_num=023000&month=05&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=11
Extracing statis for stn_num=023000&month=05&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=12
Extracing statis for stn_num=023000&month=05&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=13
Extracing statis for stn_num=023000&month=05&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=14
Extracing statis for stn_num=023000&month=05&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=15
Extracing statis for stn_num=023000&month=05&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=16
Extracing statis for stn_num=023000&month=05&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=17
Extracing statis for stn_num=023000&month=05&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=18
Extracing statis for stn_num=023000&month=05&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=19
Extracing statis for stn_num=023000&month=05&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=20
Extracing statis for stn_num=023000&month=05&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=21
Extracing statis for stn_num=023000&month=05&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=22
Extracing statis for stn_num=023000&month=05&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=23
Extracing statis for stn_num=023000&month=05&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=24
Extracing statis for stn_num=023000&month=05&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=25
Extracing statis for stn_num=023000&month=05&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=26
Extracing statis for stn_num=023000&month=05&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=27
Extracing statis for stn_num=023000&month=05&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=28
Extracing statis for stn_num=023000&month=05&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=29
Extracing statis for stn_num=023000&month=05&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=30
Extracing statis for stn_num=023000&month=05&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=05&day=31
Extracing statis for stn_num=023000&month=06&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=01
Extracing statis for stn_num=023000&month=06&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=02
Extracing statis for stn_num=023000&month=06&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=03
Extracing statis for stn_num=023000&month=06&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=04
Extracing statis for stn_num=023000&month=06&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=05
Extracing statis for stn_num=023000&month=06&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=06
Extracing statis for stn_num=023000&month=06&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=07
Extracing statis for stn_num=023000&month=06&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=08
Extracing statis for stn_num=023000&month=06&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=09
Extracing statis for stn_num=023000&month=06&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=10
Extracing statis for stn_num=023000&month=06&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=11
Extracing statis for stn_num=023000&month=06&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=12
Extracing statis for stn_num=023000&month=06&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=13
Extracing statis for stn_num=023000&month=06&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=14
Extracing statis for stn_num=023000&month=06&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=15
Extracing statis for stn_num=023000&month=06&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=16
Extracing statis for stn_num=023000&month=06&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=17
Extracing statis for stn_num=023000&month=06&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=18
Extracing statis for stn_num=023000&month=06&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=19
Extracing statis for stn_num=023000&month=06&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=20
Extracing statis for stn_num=023000&month=06&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=21
Extracing statis for stn_num=023000&month=06&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=22
Extracing statis for stn_num=023000&month=06&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=23
Extracing statis for stn_num=023000&month=06&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=24
Extracing statis for stn_num=023000&month=06&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=25
Extracing statis for stn_num=023000&month=06&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=26
Extracing statis for stn_num=023000&month=06&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=27
Extracing statis for stn_num=023000&month=06&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=28
Extracing statis for stn_num=023000&month=06&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=29
Extracing statis for stn_num=023000&month=06&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=06&day=30
Extracing statis for stn_num=023000&month=07&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=01
Extracing statis for stn_num=023000&month=07&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=02
Extracing statis for stn_num=023000&month=07&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=03
Extracing statis for stn_num=023000&month=07&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=04
Extracing statis for stn_num=023000&month=07&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=05
Extracing statis for stn_num=023000&month=07&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=06
Extracing statis for stn_num=023000&month=07&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=07
Extracing statis for stn_num=023000&month=07&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=08
Extracing statis for stn_num=023000&month=07&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=09
Extracing statis for stn_num=023000&month=07&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=10
Extracing statis for stn_num=023000&month=07&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=11
Extracing statis for stn_num=023000&month=07&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=12
Extracing statis for stn_num=023000&month=07&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=13
Extracing statis for stn_num=023000&month=07&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=14
Extracing statis for stn_num=023000&month=07&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=15
Extracing statis for stn_num=023000&month=07&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=16
Extracing statis for stn_num=023000&month=07&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=17
Extracing statis for stn_num=023000&month=07&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=18
Extracing statis for stn_num=023000&month=07&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=19
Extracing statis for stn_num=023000&month=07&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=20
Extracing statis for stn_num=023000&month=07&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=21
Extracing statis for stn_num=023000&month=07&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=22
Extracing statis for stn_num=023000&month=07&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=23
Extracing statis for stn_num=023000&month=07&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=24
Extracing statis for stn_num=023000&month=07&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=25
Extracing statis for stn_num=023000&month=07&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=26
Extracing statis for stn_num=023000&month=07&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=27
Extracing statis for stn_num=023000&month=07&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=28
Extracing statis for stn_num=023000&month=07&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=29
Extracing statis for stn_num=023000&month=07&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=30
Extracing statis for stn_num=023000&month=07&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=07&day=31
Extracing statis for stn_num=023000&month=08&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=01
Extracing statis for stn_num=023000&month=08&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=02
Extracing statis for stn_num=023000&month=08&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=03
Extracing statis for stn_num=023000&month=08&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=04
Extracing statis for stn_num=023000&month=08&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=05
Extracing statis for stn_num=023000&month=08&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=06
Extracing statis for stn_num=023000&month=08&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=07
Extracing statis for stn_num=023000&month=08&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=08
Extracing statis for stn_num=023000&month=08&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=09
Extracing statis for stn_num=023000&month=08&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=10
Extracing statis for stn_num=023000&month=08&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=11
Extracing statis for stn_num=023000&month=08&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=12
Extracing statis for stn_num=023000&month=08&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=13
Extracing statis for stn_num=023000&month=08&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=14
Extracing statis for stn_num=023000&month=08&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=15
Extracing statis for stn_num=023000&month=08&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=16
Extracing statis for stn_num=023000&month=08&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=17
Extracing statis for stn_num=023000&month=08&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=18
Extracing statis for stn_num=023000&month=08&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=19
Extracing statis for stn_num=023000&month=08&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=20
Extracing statis for stn_num=023000&month=08&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=21
Extracing statis for stn_num=023000&month=08&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=22
Extracing statis for stn_num=023000&month=08&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=23
Extracing statis for stn_num=023000&month=08&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=24
Extracing statis for stn_num=023000&month=08&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=25
Extracing statis for stn_num=023000&month=08&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=26
Extracing statis for stn_num=023000&month=08&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=27
Extracing statis for stn_num=023000&month=08&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=28
Extracing statis for stn_num=023000&month=08&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=29
Extracing statis for stn_num=023000&month=08&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=30
Extracing statis for stn_num=023000&month=08&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=08&day=31
Extracing statis for stn_num=023000&month=09&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=01
Extracing statis for stn_num=023000&month=09&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=02
Extracing statis for stn_num=023000&month=09&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=03
Extracing statis for stn_num=023000&month=09&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=04
Extracing statis for stn_num=023000&month=09&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=05
Extracing statis for stn_num=023000&month=09&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=06
Extracing statis for stn_num=023000&month=09&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=07
Extracing statis for stn_num=023000&month=09&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=08
Extracing statis for stn_num=023000&month=09&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=09
Extracing statis for stn_num=023000&month=09&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=10
Extracing statis for stn_num=023000&month=09&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=11
Extracing statis for stn_num=023000&month=09&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=12
Extracing statis for stn_num=023000&month=09&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=13
Extracing statis for stn_num=023000&month=09&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=14
Extracing statis for stn_num=023000&month=09&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=15
Extracing statis for stn_num=023000&month=09&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=16
Extracing statis for stn_num=023000&month=09&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=17
Extracing statis for stn_num=023000&month=09&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=18
Extracing statis for stn_num=023000&month=09&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=19
Extracing statis for stn_num=023000&month=09&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=20
Extracing statis for stn_num=023000&month=09&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=21
Extracing statis for stn_num=023000&month=09&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=22
Extracing statis for stn_num=023000&month=09&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=23
Extracing statis for stn_num=023000&month=09&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=24
Extracing statis for stn_num=023000&month=09&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=25
Extracing statis for stn_num=023000&month=09&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=26
Extracing statis for stn_num=023000&month=09&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=27
Extracing statis for stn_num=023000&month=09&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=28
Extracing statis for stn_num=023000&month=09&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=29
Extracing statis for stn_num=023000&month=09&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=09&day=30
Extracing statis for stn_num=023000&month=10&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=01
Extracing statis for stn_num=023000&month=10&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=02
Extracing statis for stn_num=023000&month=10&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=03
Extracing statis for stn_num=023000&month=10&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=04
Extracing statis for stn_num=023000&month=10&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=05
Extracing statis for stn_num=023000&month=10&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=06
Extracing statis for stn_num=023000&month=10&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=07
Extracing statis for stn_num=023000&month=10&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=08
Extracing statis for stn_num=023000&month=10&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=09
Extracing statis for stn_num=023000&month=10&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=10
Extracing statis for stn_num=023000&month=10&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=11
Extracing statis for stn_num=023000&month=10&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=12
Extracing statis for stn_num=023000&month=10&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=13
Extracing statis for stn_num=023000&month=10&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=14
Extracing statis for stn_num=023000&month=10&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=15
Extracing statis for stn_num=023000&month=10&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=16
Extracing statis for stn_num=023000&month=10&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=17
Extracing statis for stn_num=023000&month=10&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=18
Extracing statis for stn_num=023000&month=10&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=19
Extracing statis for stn_num=023000&month=10&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=20
Extracing statis for stn_num=023000&month=10&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=21
Extracing statis for stn_num=023000&month=10&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=22
Extracing statis for stn_num=023000&month=10&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=23
Extracing statis for stn_num=023000&month=10&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=24
Extracing statis for stn_num=023000&month=10&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=25
Extracing statis for stn_num=023000&month=10&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=26
Extracing statis for stn_num=023000&month=10&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=27
Extracing statis for stn_num=023000&month=10&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=28
Extracing statis for stn_num=023000&month=10&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=29
Extracing statis for stn_num=023000&month=10&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=30
Extracing statis for stn_num=023000&month=10&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=10&day=31
Extracing statis for stn_num=023000&month=11&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=01
Extracing statis for stn_num=023000&month=11&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=02
Extracing statis for stn_num=023000&month=11&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=03
Extracing statis for stn_num=023000&month=11&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=04
Extracing statis for stn_num=023000&month=11&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=05
Extracing statis for stn_num=023000&month=11&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=06
Extracing statis for stn_num=023000&month=11&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=07
Extracing statis for stn_num=023000&month=11&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=08
Extracing statis for stn_num=023000&month=11&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=09
Extracing statis for stn_num=023000&month=11&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=10
Extracing statis for stn_num=023000&month=11&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=11
Extracing statis for stn_num=023000&month=11&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=12
Extracing statis for stn_num=023000&month=11&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=13
Extracing statis for stn_num=023000&month=11&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=14
Extracing statis for stn_num=023000&month=11&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=15
Extracing statis for stn_num=023000&month=11&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=16
Extracing statis for stn_num=023000&month=11&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=17
Extracing statis for stn_num=023000&month=11&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=18
Extracing statis for stn_num=023000&month=11&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=19
Extracing statis for stn_num=023000&month=11&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=20
Extracing statis for stn_num=023000&month=11&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=21
Extracing statis for stn_num=023000&month=11&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=22
Extracing statis for stn_num=023000&month=11&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=23
Extracing statis for stn_num=023000&month=11&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=24
Extracing statis for stn_num=023000&month=11&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=25
Extracing statis for stn_num=023000&month=11&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=26
Extracing statis for stn_num=023000&month=11&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=27
Extracing statis for stn_num=023000&month=11&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=28
Extracing statis for stn_num=023000&month=11&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=29
Extracing statis for stn_num=023000&month=11&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=11&day=30
Extracing statis for stn_num=023000&month=12&day=01
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=01
Extracing statis for stn_num=023000&month=12&day=02
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=02
Extracing statis for stn_num=023000&month=12&day=03
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=03
Extracing statis for stn_num=023000&month=12&day=04
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=04
Extracing statis for stn_num=023000&month=12&day=05
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=05
Extracing statis for stn_num=023000&month=12&day=06
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=06
Extracing statis for stn_num=023000&month=12&day=07
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=07
Extracing statis for stn_num=023000&month=12&day=08
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=08
Extracing statis for stn_num=023000&month=12&day=09
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=09
Extracing statis for stn_num=023000&month=12&day=10
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=10
Extracing statis for stn_num=023000&month=12&day=11
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=11
Extracing statis for stn_num=023000&month=12&day=12
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=12
Extracing statis for stn_num=023000&month=12&day=13
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=13
Extracing statis for stn_num=023000&month=12&day=14
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=14
Extracing statis for stn_num=023000&month=12&day=15
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=15
Extracing statis for stn_num=023000&month=12&day=16
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=16
Extracing statis for stn_num=023000&month=12&day=17
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=17
Extracing statis for stn_num=023000&month=12&day=18
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=18
Extracing statis for stn_num=023000&month=12&day=19
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=19
Extracing statis for stn_num=023000&month=12&day=20
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=20
Extracing statis for stn_num=023000&month=12&day=21
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=21
Extracing statis for stn_num=023000&month=12&day=22
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=22
Extracing statis for stn_num=023000&month=12&day=23
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=23
Extracing statis for stn_num=023000&month=12&day=24
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=24
Extracing statis for stn_num=023000&month=12&day=25
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=25
Extracing statis for stn_num=023000&month=12&day=26
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=26
Extracing statis for stn_num=023000&month=12&day=27
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=27
Extracing statis for stn_num=023000&month=12&day=28
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=28
Extracing statis for stn_num=023000&month=12&day=29
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=29
Extracing statis for stn_num=023000&month=12&day=30
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=30
Extracing statis for stn_num=023000&month=12&day=31
Processing : http://www.bom.gov.au/jsp/ncc/cdio/calendar/climate-calendar?stn_num=023000&month=12&day=31
Running Spark version 2.4.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Loaded the native-hadoop library
Using JniBasedUnixGroupsMapping for Group resolution
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:NTUserPrincipal: ywksu
Using user: "NTUserPrincipal: ywksu" with name ywksu
User entry: "ywksu"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:ywksu (auth:SIMPLE)
Submitted application: au.com.weather_simulator.utiles.SparkUtiles$
Changing view acls to: ywksu
Changing modify acls to: ywksu
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ywksu); groups with view permissions: Set(); users  with modify permissions: Set(ywksu); groups with modify permissions: Set()
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 16
Platform: Windows
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: C:\Users\ywksu\AppData\Local\Temp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 3787980800 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 16
-Dio.netty.allocator.numDirectArenas: 16
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 9172 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
-Dio.netty.machineId: 9c:b6:d0:ff:fe:00:23:81 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 10922
Successfully started service 'sparkDriver' on port 10922.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\ywksu\AppData\Local\Temp\blockmgr-200e04d4-dc28-41d3-b21d-2edf1d4fb996
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1987.5 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @2734974ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@79145d5a
o.s.j.s.ServletContextHandler@60d1a32f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@531c311e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@531c311e added {org.apache.spark.ui.JettyUtils$$anon$3-2e11485@def8fe12==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@531c311e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2e11485,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6f8f9349
o.s.j.s.ServletContextHandler@75c9e76b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7446d8d5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7446d8d5 added {org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e@d41b8fe5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7446d8d5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@354fc8f0
o.s.j.s.ServletContextHandler@41813449{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4678a2eb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4678a2eb added {org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6@9e69b044==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4678a2eb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1080b026
o.s.j.s.ServletContextHandler@58ebfd03{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5b07730f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5b07730f added {org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2@2732ff36==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5b07730f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@14c01636
o.s.j.s.ServletContextHandler@590c73d3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6b9ce1bf,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6b9ce1bf added {org.apache.spark.ui.JettyUtils$$anon$3-61884cb1@ed3ca665==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6b9ce1bf added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-61884cb1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@75ed9710
o.s.j.s.ServletContextHandler@4fc5e095{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@435871cb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@435871cb added {org.apache.spark.ui.JettyUtils$$anon$3-609640d5@b9ee5590==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@435871cb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-609640d5,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19fb8826
o.s.j.s.ServletContextHandler@192d74fb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4bef0fe3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4bef0fe3 added {org.apache.spark.ui.JettyUtils$$anon$3-62ea3440@712d8ee1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4bef0fe3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-62ea3440,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@27953a83
o.s.j.s.ServletContextHandler@556d0826{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66ce957f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66ce957f added {org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2@a08bb83c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66ce957f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@666b83a4
o.s.j.s.ServletContextHandler@749c877b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@efde75f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@efde75f added {org.apache.spark.ui.JettyUtils$$anon$3-16ecee1@5cd33bc2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@efde75f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-16ecee1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3b220bcb
o.s.j.s.ServletContextHandler@2b95e48b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a3329b9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a3329b9 added {org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8@8d0e84f2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a3329b9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3f053c80
o.s.j.s.ServletContextHandler@6c6c5427{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@618c5d94,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@618c5d94 added {org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb@78b7ae2b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@618c5d94 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@13c3c1e1
o.s.j.s.ServletContextHandler@1d8062d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1e63ec0b,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1e63ec0b added {org.apache.spark.ui.JettyUtils$$anon$3-3b956878@d7354b7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1e63ec0b added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b956878,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@285c08c8
o.s.j.s.ServletContextHandler@295eaa7c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3918c187,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3918c187 added {org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc@a2c3d1b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3918c187 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@64dafeed
o.s.j.s.ServletContextHandler@388ba540{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@47605f2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@47605f2f added {org.apache.spark.ui.JettyUtils$$anon$3-2ece4966@5855dd86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@47605f2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2ece4966,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6111ba37
o.s.j.s.ServletContextHandler@7be58f16{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@242aa8d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@242aa8d9 added {org.apache.spark.ui.JettyUtils$$anon$3-5b11a194@992bf424==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@242aa8d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5b11a194,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@37bd68c3
o.s.j.s.ServletContextHandler@60f7cc1d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@11eadcba,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@11eadcba added {org.apache.spark.ui.JettyUtils$$anon$3-4721d212@50550bdd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@11eadcba added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4721d212,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5827af16
o.s.j.s.ServletContextHandler@654d8173{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@56c9bbd8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@56c9bbd8 added {org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4@4bd48321==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@56c9bbd8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@636e8cc
o.s.j.s.ServletContextHandler@f79a760{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@14f5da2c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@14f5da2c added {org.apache.spark.ui.JettyUtils$$anon$3-12dae582@682994b4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@14f5da2c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-12dae582,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@619bfe29
o.s.j.s.ServletContextHandler@5b057c8c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1eb6749b,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1eb6749b added {org.apache.spark.ui.JettyUtils$$anon$3-652a7737@b8daf59e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1eb6749b added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-652a7737,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5b7ea70d
o.s.j.s.ServletContextHandler@2bef51f2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@650eab8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@650eab8 added {org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a@cf1b5176==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@650eab8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4f2c9ba6
o.s.j.s.ServletContextHandler@4e28bdd1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53f48368,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@53f48368 added {org.spark_project.jetty.servlet.DefaultServlet-4a335fa8@9b31cde4==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53f48368 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-4a335fa8,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3829ac1
o.s.j.s.ServletContextHandler@4baf352a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1bb1fde8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1bb1fde8 added {org.apache.spark.ui.JettyUtils$$anon$4-15eebbff@fd123fcf==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1bb1fde8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-15eebbff,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2453f95d
o.s.j.s.ServletContextHandler@44828f6b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2dbe250d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2dbe250d added {org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2dbe250d added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-5ed731d0,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@557a1e2d
o.s.j.s.ServletContextHandler@26a4842b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7e38a7fe,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7e38a7fe added {org.apache.spark.ui.JettyUtils$$anon$4-366ef90e@b18840a5==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7e38a7fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-366ef90e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@a5b0b86
o.s.j.s.ServletContextHandler@4b3c354a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@78fb9a67,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@78fb9a67 added {org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae@43aebfd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@78fb9a67 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae,POJO}
org.spark_project.jetty.server.Server@4d098f9b added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@4d098f9b added {org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec,AUTO}
org.spark_project.jetty.server.Server@4d098f9b added {org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[],MANAGED}
starting org.spark_project.jetty.server.Server@4d098f9b
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
starting org.spark_project.jetty.server.Server@4d098f9b
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @2735119ms SparkUI{STARTED,8<=8<=200,i=6,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec
starting org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec
STARTED @2735119ms org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[]
STARTED @2735119ms org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[]
Started @2735119ms
STARTED @2735119ms org.spark_project.jetty.server.Server@4d098f9b
HttpConnectionFactory@58670130[HTTP/1.1] added {HttpConfiguration@74e47444{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3276732{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@4d098f9b,UNMANAGED}
ServerConnector@3276732{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3276732{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@3f28bd56,AUTO}
ServerConnector@3276732{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@31e3250d,POJO}
ServerConnector@3276732{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@58670130[HTTP/1.1],AUTO}
ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@58670130[HTTP/1.1]
ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260,MANAGED}
starting ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4542],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@3f28bd56
STARTED @2735140ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@3f28bd56
starting HttpConnectionFactory@58670130[HTTP/1.1]
STARTED @2735140ms HttpConnectionFactory@58670130[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260 added {org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=-1 selected=-1,AUTO}
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260 added {org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=-1 selected=-1,AUTO}
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260 added {org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=-1 selected=-1,AUTO}
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260 added {org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
STARTED @2735144ms org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
starting org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=-1 selected=-1
run org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1dd8022d execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1dd8022d produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1dd8022d producing
Selector loop waiting on select
queue org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
STARTED @2735146ms org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@297c8f86 execute
starting org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=-1 selected=-1
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@297c8f86 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@297c8f86 producing
Selector loop waiting on select
queue org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
STARTED @2735147ms org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
starting org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=-1 selected=-1
run org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4ed4958c execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4ed4958c produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4ed4958c producing
Selector loop waiting on select
queue org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
STARTED @2735147ms org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
STARTED @2735152ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@51034e4b execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@51034e4b produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@51034e4b producing
Selector loop waiting on select
ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542} added {acceptor-0@267f474e,POJO}
queue acceptor-0@267f474e
Started ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
run acceptor-0@267f474e
STARTED @2735153ms ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
Successfully started service 'SparkUI' on port 4542.
org.spark_project.jetty.server.Server@4d098f9b added {Spark@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a mime types IncludeExclude@1d1f7216{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@423e4cbb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6e16b8b5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a added {o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a
starting o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@531c311e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2e11485 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2e11485@def8fe12==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2e11485=org.apache.spark.ui.JettyUtils$$anon$3-2e11485@def8fe12==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@531c311e
STARTED @2735182ms org.spark_project.jetty.servlet.ServletHandler@531c311e
starting org.apache.spark.ui.JettyUtils$$anon$3-2e11485@def8fe12==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735185ms org.apache.spark.ui.JettyUtils$$anon$3-2e11485@def8fe12==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@77192705 for org.apache.spark.ui.JettyUtils$$anon$3-2e11485
Started o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}
STARTED @2735186ms o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}
STARTED @2735186ms org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a
org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5 mime types IncludeExclude@7e809b79{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5cc126dc,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@625e134e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5 added {o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5
starting o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7446d8d5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e@d41b8fe5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e=org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e@d41b8fe5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7446d8d5
STARTED @2735187ms org.spark_project.jetty.servlet.ServletHandler@7446d8d5
starting org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e@d41b8fe5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735187ms org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e@d41b8fe5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72bd06ca for org.apache.spark.ui.JettyUtils$$anon$3-5c3b6c6e
Started o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}
STARTED @2735187ms o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}
STARTED @2735187ms org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5
org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7 mime types IncludeExclude@5dbe30be{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4fe89c24,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@55795845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7 added {o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7
starting o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4678a2eb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6@9e69b044==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6=org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6@9e69b044==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4678a2eb
STARTED @2735188ms org.spark_project.jetty.servlet.ServletHandler@4678a2eb
starting org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6@9e69b044==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735188ms org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6@9e69b044==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3d08f3f5 for org.apache.spark.ui.JettyUtils$$anon$3-5b43fbf6
Started o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}
STARTED @2735188ms o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}
STARTED @2735188ms org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881 mime types IncludeExclude@5b970f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7fd4acee,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165b8a71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881 added {o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881
starting o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5b07730f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2@2732ff36==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2=org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2@2732ff36==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5b07730f
STARTED @2735190ms org.spark_project.jetty.servlet.ServletHandler@5b07730f
starting org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2@2732ff36==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735190ms org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2@2732ff36==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6175619b for org.apache.spark.ui.JettyUtils$$anon$3-1fdfafd2
Started o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @2735190ms o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @2735190ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881
org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a mime types IncludeExclude@756cf158{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f2ef586,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@751d3241}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a added {o.s.j.s.ServletContextHandler@590c73d3{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a
starting o.s.j.s.ServletContextHandler@590c73d3{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@590c73d3{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6b9ce1bf
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-61884cb1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-61884cb1@ed3ca665==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-61884cb1=org.apache.spark.ui.JettyUtils$$anon$3-61884cb1@ed3ca665==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6b9ce1bf
STARTED @2735191ms org.spark_project.jetty.servlet.ServletHandler@6b9ce1bf
starting org.apache.spark.ui.JettyUtils$$anon$3-61884cb1@ed3ca665==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735192ms org.apache.spark.ui.JettyUtils$$anon$3-61884cb1@ed3ca665==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@76c7beb3 for org.apache.spark.ui.JettyUtils$$anon$3-61884cb1
Started o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}
STARTED @2735192ms o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}
STARTED @2735192ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a
org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702 mime types IncludeExclude@2cf92cc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@30ea8c23,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7b139eab}
org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702 added {o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702
starting o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@435871cb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-609640d5 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-609640d5@b9ee5590==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-609640d5=org.apache.spark.ui.JettyUtils$$anon$3-609640d5@b9ee5590==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@435871cb
STARTED @2735193ms org.spark_project.jetty.servlet.ServletHandler@435871cb
starting org.apache.spark.ui.JettyUtils$$anon$3-609640d5@b9ee5590==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735193ms org.apache.spark.ui.JettyUtils$$anon$3-609640d5@b9ee5590==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e76dac for org.apache.spark.ui.JettyUtils$$anon$3-609640d5
Started o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}
STARTED @2735193ms o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}
STARTED @2735193ms org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702
org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3 mime types IncludeExclude@5f2f577{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6273c5a4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5d465e4b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3 added {o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3
starting o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4bef0fe3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-62ea3440 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-62ea3440@712d8ee1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-62ea3440=org.apache.spark.ui.JettyUtils$$anon$3-62ea3440@712d8ee1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4bef0fe3
STARTED @2735195ms org.spark_project.jetty.servlet.ServletHandler@4bef0fe3
starting org.apache.spark.ui.JettyUtils$$anon$3-62ea3440@712d8ee1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735195ms org.apache.spark.ui.JettyUtils$$anon$3-62ea3440@712d8ee1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@53e211ee for org.apache.spark.ui.JettyUtils$$anon$3-62ea3440
Started o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}
STARTED @2735195ms o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}
STARTED @2735195ms org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3
org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920 mime types IncludeExclude@117e0fe5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@18a3962d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@78aea4b9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920 added {o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920
starting o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66ce957f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2@a08bb83c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2=org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2@a08bb83c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66ce957f
STARTED @2735197ms org.spark_project.jetty.servlet.ServletHandler@66ce957f
starting org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2@a08bb83c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735197ms org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2@a08bb83c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2a65bb85 for org.apache.spark.ui.JettyUtils$$anon$3-55b5f5d2
Started o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @2735198ms o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @2735198ms org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920
org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b mime types IncludeExclude@4f936da8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4215838f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@452ba1db}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b added {o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b
starting o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@efde75f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-16ecee1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-16ecee1@5cd33bc2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-16ecee1=org.apache.spark.ui.JettyUtils$$anon$3-16ecee1@5cd33bc2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@efde75f
STARTED @2735199ms org.spark_project.jetty.servlet.ServletHandler@efde75f
starting org.apache.spark.ui.JettyUtils$$anon$3-16ecee1@5cd33bc2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735199ms org.apache.spark.ui.JettyUtils$$anon$3-16ecee1@5cd33bc2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2289aca5 for org.apache.spark.ui.JettyUtils$$anon$3-16ecee1
Started o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}
STARTED @2735199ms o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}
STARTED @2735199ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b
org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71 mime types IncludeExclude@184497d1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@f9d87b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6ffab045}
org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71 added {o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71
starting o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a3329b9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8@8d0e84f2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8=org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8@8d0e84f2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a3329b9
STARTED @2735201ms org.spark_project.jetty.servlet.ServletHandler@4a3329b9
starting org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8@8d0e84f2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735201ms org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8@8d0e84f2==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@26fb628 for org.apache.spark.ui.JettyUtils$$anon$3-3dddefd8
Started o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @2735201ms o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @2735201ms org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71
org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab mime types IncludeExclude@70dd7e15{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4a9f80d3,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35beb15e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab added {o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab
starting o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@618c5d94
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb@78b7ae2b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb=org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb@78b7ae2b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@618c5d94
STARTED @2735202ms org.spark_project.jetty.servlet.ServletHandler@618c5d94
starting org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb@78b7ae2b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735203ms org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb@78b7ae2b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@41fe9859 for org.apache.spark.ui.JettyUtils$$anon$3-5b40ceb
Started o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}
STARTED @2735203ms o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}
STARTED @2735203ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab
org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5 mime types IncludeExclude@6c67e137{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2c9399a4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@191ae03f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5 added {o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5
starting o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1e63ec0b
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b956878 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b956878@d7354b7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b956878=org.apache.spark.ui.JettyUtils$$anon$3-3b956878@d7354b7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1e63ec0b
STARTED @2735204ms org.spark_project.jetty.servlet.ServletHandler@1e63ec0b
starting org.apache.spark.ui.JettyUtils$$anon$3-3b956878@d7354b7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735204ms org.apache.spark.ui.JettyUtils$$anon$3-3b956878@d7354b7a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@9635fa for org.apache.spark.ui.JettyUtils$$anon$3-3b956878
Started o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}
STARTED @2735204ms o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}
STARTED @2735204ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5
org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286 mime types IncludeExclude@63c5efee{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2d10e0b1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1c98290c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286 added {o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286
starting o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3918c187
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc@a2c3d1b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc=org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc@a2c3d1b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3918c187
STARTED @2735205ms org.spark_project.jetty.servlet.ServletHandler@3918c187
starting org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc@a2c3d1b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735205ms org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc@a2c3d1b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@172ca72b for org.apache.spark.ui.JettyUtils$$anon$3-2c88b9fc
Started o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @2735205ms o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @2735205ms org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286
org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf mime types IncludeExclude@71e5f61d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2ce86164,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5e8f9e2d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf added {o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf
starting o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@47605f2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2ece4966 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2ece4966@5855dd86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2ece4966=org.apache.spark.ui.JettyUtils$$anon$3-2ece4966@5855dd86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@47605f2f
STARTED @2735206ms org.spark_project.jetty.servlet.ServletHandler@47605f2f
starting org.apache.spark.ui.JettyUtils$$anon$3-2ece4966@5855dd86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735206ms org.apache.spark.ui.JettyUtils$$anon$3-2ece4966@5855dd86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51df223b for org.apache.spark.ui.JettyUtils$$anon$3-2ece4966
Started o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @2735206ms o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @2735206ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf
org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303 mime types IncludeExclude@60d8c0dc{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4204541c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6a62689d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303 added {o.s.j.s.ServletContextHandler@7be58f16{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303
starting o.s.j.s.ServletContextHandler@7be58f16{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7be58f16{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@242aa8d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5b11a194 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5b11a194@992bf424==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5b11a194=org.apache.spark.ui.JettyUtils$$anon$3-5b11a194@992bf424==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@242aa8d9
STARTED @2735207ms org.spark_project.jetty.servlet.ServletHandler@242aa8d9
starting org.apache.spark.ui.JettyUtils$$anon$3-5b11a194@992bf424==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735207ms org.apache.spark.ui.JettyUtils$$anon$3-5b11a194@992bf424==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4602c2a9 for org.apache.spark.ui.JettyUtils$$anon$3-5b11a194
Started o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}
STARTED @2735207ms o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}
STARTED @2735208ms org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303
org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495 mime types IncludeExclude@3e2822{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@79e18e38,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@29a60c27}
org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495 added {o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495
starting o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@11eadcba
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4721d212 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4721d212@50550bdd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4721d212=org.apache.spark.ui.JettyUtils$$anon$3-4721d212@50550bdd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@11eadcba
STARTED @2735209ms org.spark_project.jetty.servlet.ServletHandler@11eadcba
starting org.apache.spark.ui.JettyUtils$$anon$3-4721d212@50550bdd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735209ms org.apache.spark.ui.JettyUtils$$anon$3-4721d212@50550bdd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1849db1a for org.apache.spark.ui.JettyUtils$$anon$3-4721d212
Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
STARTED @2735209ms o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
STARTED @2735209ms org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495
org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09 mime types IncludeExclude@1ca25c47{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5fcacc0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@533b266e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09 added {o.s.j.s.ServletContextHandler@654d8173{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09
starting o.s.j.s.ServletContextHandler@654d8173{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@654d8173{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@56c9bbd8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4@4bd48321==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4=org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4@4bd48321==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@56c9bbd8
STARTED @2735210ms org.spark_project.jetty.servlet.ServletHandler@56c9bbd8
starting org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4@4bd48321==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735210ms org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4@4bd48321==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6d1d4d7 for org.apache.spark.ui.JettyUtils$$anon$3-630cb4a4
Started o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}
STARTED @2735211ms o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}
STARTED @2735211ms org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09
org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e mime types IncludeExclude@6865c751{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@62679465,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6a988392}
org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e added {o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e
starting o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@14f5da2c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-12dae582 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-12dae582@682994b4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-12dae582=org.apache.spark.ui.JettyUtils$$anon$3-12dae582@682994b4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@14f5da2c
STARTED @2735212ms org.spark_project.jetty.servlet.ServletHandler@14f5da2c
starting org.apache.spark.ui.JettyUtils$$anon$3-12dae582@682994b4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735212ms org.apache.spark.ui.JettyUtils$$anon$3-12dae582@682994b4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1d71006f for org.apache.spark.ui.JettyUtils$$anon$3-12dae582
Started o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}
STARTED @2735212ms o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}
STARTED @2735212ms org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e
org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df mime types IncludeExclude@5f2606b{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2b58f754,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ebff828}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df added {o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df
starting o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1eb6749b
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-652a7737 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-652a7737@b8daf59e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-652a7737=org.apache.spark.ui.JettyUtils$$anon$3-652a7737@b8daf59e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1eb6749b
STARTED @2735214ms org.spark_project.jetty.servlet.ServletHandler@1eb6749b
starting org.apache.spark.ui.JettyUtils$$anon$3-652a7737@b8daf59e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735214ms org.apache.spark.ui.JettyUtils$$anon$3-652a7737@b8daf59e==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2552f2cb for org.apache.spark.ui.JettyUtils$$anon$3-652a7737
Started o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @2735214ms o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @2735214ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df
org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32 mime types IncludeExclude@5f3b9c57{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1e044120,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cf23c81}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32 added {o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32
starting o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@650eab8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a@cf1b5176==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a=org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a@cf1b5176==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@650eab8
STARTED @2735216ms org.spark_project.jetty.servlet.ServletHandler@650eab8
starting org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a@cf1b5176==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735216ms org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a@cf1b5176==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3624da92 for org.apache.spark.ui.JettyUtils$$anon$3-30f5a68a
Started o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @2735216ms o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @2735216ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32
org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125 mime types IncludeExclude@94f6bfb{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@34645867,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2484f433}
org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125 added {o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125
starting o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53f48368
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-4a335fa8 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-4a335fa8@9b31cde4==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-4a335fa8=org.spark_project.jetty.servlet.DefaultServlet-4a335fa8@9b31cde4==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53f48368
STARTED @2735217ms org.spark_project.jetty.servlet.ServletHandler@53f48368
starting org.spark_project.jetty.servlet.DefaultServlet-4a335fa8@9b31cde4==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @2735218ms org.spark_project.jetty.servlet.DefaultServlet-4a335fa8@9b31cde4==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@60b71e8f for org.spark_project.jetty.servlet.DefaultServlet-4a335fa8
resource base = jar:file:/C:/Users/ywksu/.ivy2/cache/org.apache.spark/spark-core_2.12/jars/spark-core_2.12-2.4.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}
STARTED @2735224ms o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}
STARTED @2735224ms org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125
org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854 mime types IncludeExclude@1568159{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4fcee388,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6f80fafe}
org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854 added {o.s.j.s.ServletContextHandler@4baf352a{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854
starting o.s.j.s.ServletContextHandler@4baf352a{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4baf352a{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1bb1fde8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-15eebbff from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-15eebbff@fd123fcf==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-15eebbff=org.apache.spark.ui.JettyUtils$$anon$4-15eebbff@fd123fcf==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1bb1fde8
STARTED @2735225ms org.spark_project.jetty.servlet.ServletHandler@1bb1fde8
starting org.apache.spark.ui.JettyUtils$$anon$4-15eebbff@fd123fcf==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @2735225ms org.apache.spark.ui.JettyUtils$$anon$4-15eebbff@fd123fcf==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@3af17be2 for org.apache.spark.ui.JettyUtils$$anon$4-15eebbff
Started o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}
STARTED @2735225ms o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}
STARTED @2735225ms org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854
org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac mime types IncludeExclude@37f21974{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5f4d427e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6e521c1e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac added {o.s.j.s.ServletContextHandler@44828f6b{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac
starting o.s.j.s.ServletContextHandler@44828f6b{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@44828f6b{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2dbe250d
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-5ed731d0 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-5ed731d0=org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@2dbe250d
org.spark_project.jetty.servlet.ServletHandler@2dbe250d added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593@8d3259af==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2dbe250d added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-5ed731d0 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593@8d3259af==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-5ed731d0=org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593@8d3259af==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@2dbe250d
STARTED @2735227ms org.spark_project.jetty.servlet.ServletHandler@2dbe250d
starting org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @2735227ms org.glassfish.jersey.servlet.ServletContainer-5ed731d0@e731d55b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593@8d3259af==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @2735227ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-303e3593@8d3259af==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}
STARTED @2735227ms o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}
STARTED @2735227ms org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac
org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66 mime types IncludeExclude@362a019c{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d9bec4d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c48c0c0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66 added {o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66
starting o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7e38a7fe
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-366ef90e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-366ef90e@b18840a5==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-366ef90e=org.apache.spark.ui.JettyUtils$$anon$4-366ef90e@b18840a5==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7e38a7fe
STARTED @2735229ms org.spark_project.jetty.servlet.ServletHandler@7e38a7fe
starting org.apache.spark.ui.JettyUtils$$anon$4-366ef90e@b18840a5==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @2735229ms org.apache.spark.ui.JettyUtils$$anon$4-366ef90e@b18840a5==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@10c8f62 for org.apache.spark.ui.JettyUtils$$anon$4-366ef90e
Started o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @2735229ms o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @2735229ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66
org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e mime types IncludeExclude@25f7391e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f23a3a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ab14cb9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e added {o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e
starting o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@78fb9a67
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae@43aebfd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae=org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae@43aebfd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@78fb9a67
STARTED @2735230ms org.spark_project.jetty.servlet.ServletHandler@78fb9a67
starting org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae@43aebfd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @2735230ms org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae@43aebfd==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@5fb97279 for org.apache.spark.ui.JettyUtils$$anon$4-73ff4fae
Started o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @2735230ms o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @2735230ms org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e
Bound SparkUI to 0.0.0.0, and started at http://192.168.1.13:4542
Starting executor ID driver on host localhost
Shuffle server started on port: 10964
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 10964.
Server created on 192.168.1.13:10964
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, 192.168.1.13, 10964, None)
Got a request for 192.168.1.13
Registering block manager 192.168.1.13:10964 with 1987.5 MB RAM, BlockManagerId(driver, 192.168.1.13, 10964, None)
Registered BlockManager BlockManagerId(driver, 192.168.1.13, 10964, None)
Initialized BlockManager: BlockManagerId(driver, 192.168.1.13, 10964, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4aa3d36
o.s.j.s.ServletContextHandler@2d140a7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@347bdeef,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@347bdeef added {org.apache.spark.ui.JettyUtils$$anon$3-2aa27288@7e85d3a7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@347bdeef added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2aa27288,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@347bdeef
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2aa27288 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2aa27288@7e85d3a7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2aa27288=org.apache.spark.ui.JettyUtils$$anon$3-2aa27288@7e85d3a7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@347bdeef
STARTED @2735667ms org.spark_project.jetty.servlet.ServletHandler@347bdeef
starting org.apache.spark.ui.JettyUtils$$anon$3-2aa27288@7e85d3a7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735667ms org.apache.spark.ui.JettyUtils$$anon$3-2aa27288@7e85d3a7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@240139e1 for org.apache.spark.ui.JettyUtils$$anon$3-2aa27288
Started o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}
STARTED @2735667ms o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/p1/weather-simulator/spark-warehouse/').
Warehouse path is 'file:/D:/p1/weather-simulator/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@deb3b60
o.s.j.s.ServletContextHandler@701a32{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@39aa45a1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@39aa45a1 added {org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1@77f4e0a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@39aa45a1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@27cbfddf
o.s.j.s.ServletContextHandler@27ead29e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4c060c8f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4c060c8f added {org.apache.spark.ui.JettyUtils$$anon$3-40620d8e@e4d40085==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4c060c8f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-40620d8e,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@701a32{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@701a32{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@701a32{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@701a32{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@701a32{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@39aa45a1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1@77f4e0a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1=org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1@77f4e0a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@39aa45a1
STARTED @2735882ms org.spark_project.jetty.servlet.ServletHandler@39aa45a1
starting org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1@77f4e0a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735882ms org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1@77f4e0a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@383f3558 for org.apache.spark.ui.JettyUtils$$anon$3-73aff8f1
Started o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}
STARTED @2735882ms o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4c060c8f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-40620d8e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-40620d8e@e4d40085==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-40620d8e=org.apache.spark.ui.JettyUtils$$anon$3-40620d8e@e4d40085==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4c060c8f
STARTED @2735885ms org.spark_project.jetty.servlet.ServletHandler@4c060c8f
starting org.apache.spark.ui.JettyUtils$$anon$3-40620d8e@e4d40085==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735885ms org.apache.spark.ui.JettyUtils$$anon$3-40620d8e@e4d40085==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@49b07ee3 for org.apache.spark.ui.JettyUtils$$anon$3-40620d8e
Started o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}
STARTED @2735885ms o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@65f00478
o.s.j.s.ServletContextHandler@2424686b{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea94d6a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea94d6a added {org.apache.spark.ui.JettyUtils$$anon$3-28486680@b93069ee==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea94d6a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-28486680,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4d7e7435
o.s.j.s.ServletContextHandler@4a1e3ac1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6e78fcf5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6e78fcf5 added {org.apache.spark.ui.JettyUtils$$anon$3-56febdc@307b1dd5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6e78fcf5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-56febdc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea94d6a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-28486680 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-28486680@b93069ee==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-28486680=org.apache.spark.ui.JettyUtils$$anon$3-28486680@b93069ee==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea94d6a
STARTED @2735887ms org.spark_project.jetty.servlet.ServletHandler@6ea94d6a
starting org.apache.spark.ui.JettyUtils$$anon$3-28486680@b93069ee==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735887ms org.apache.spark.ui.JettyUtils$$anon$3-28486680@b93069ee==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3b8ee898 for org.apache.spark.ui.JettyUtils$$anon$3-28486680
Started o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @2735888ms o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6e78fcf5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-56febdc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-56febdc@307b1dd5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-56febdc=org.apache.spark.ui.JettyUtils$$anon$3-56febdc@307b1dd5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6e78fcf5
STARTED @2735889ms org.spark_project.jetty.servlet.ServletHandler@6e78fcf5
starting org.apache.spark.ui.JettyUtils$$anon$3-56febdc@307b1dd5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @2735889ms org.apache.spark.ui.JettyUtils$$anon$3-56febdc@307b1dd5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7d151a for org.apache.spark.ui.JettyUtils$$anon$3-56febdc
Started o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @2735889ms o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@77bb0ab5
o.s.j.s.ServletContextHandler@f2c488{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@54acff7d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@54acff7d added {org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab@5a0dd862==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@54acff7d added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854,[o.s.j.s.ServletContextHandler@4baf352a{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286,[o.s.j.s.ServletContextHandler@295eaa7c{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab,[o.s.j.s.ServletContextHandler@6c6c5427{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf,[o.s.j.s.ServletContextHandler@388ba540{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac,[o.s.j.s.ServletContextHandler@44828f6b{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71,[o.s.j.s.ServletContextHandler@2b95e48b{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b,[o.s.j.s.ServletContextHandler@749c877b{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5,[o.s.j.s.ServletContextHandler@75c9e76b{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125,[o.s.j.s.ServletContextHandler@4e28bdd1{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e,[o.s.j.s.ServletContextHandler@f79a760{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920,[o.s.j.s.ServletContextHandler@556d0826{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32,[o.s.j.s.ServletContextHandler@2bef51f2{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495,[o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881,[o.s.j.s.ServletContextHandler@58ebfd03{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a,[o.s.j.s.ServletContextHandler@60d1a32f{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702,[o.s.j.s.ServletContextHandler@4fc5e095{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3,[o.s.j.s.ServletContextHandler@192d74fb{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5,[o.s.j.s.ServletContextHandler@1d8062d2{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@701a32{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e,[o.s.j.s.ServletContextHandler@4b3c354a{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7,[o.s.j.s.ServletContextHandler@41813449{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303,[o.s.j.s.ServletContextHandler@7be58f16{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a,[o.s.j.s.ServletContextHandler@590c73d3{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09,[o.s.j.s.ServletContextHandler@654d8173{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66,[o.s.j.s.ServletContextHandler@26a4842b{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df,[o.s.j.s.ServletContextHandler@5b057c8c{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@54acff7d
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab@5a0dd862==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab=org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab@5a0dd862==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@54acff7d
STARTED @2735891ms org.spark_project.jetty.servlet.ServletHandler@54acff7d
starting org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab@5a0dd862==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @2735891ms org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab@5a0dd862==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@5488b5c5 for org.spark_project.jetty.servlet.DefaultServlet-7bc9e6ab
resource base = jar:file:/C:/Users/ywksu/.ivy2/cache/org.apache.spark/spark-sql_2.12/jars/spark-sql_2.12-2.4.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,AVAILABLE,@Spark}
STARTED @2735892ms o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Reading files from src/main/resources/bomstatis/
sampler.classes = ; loaded no samplers
span.receiver.classes = ; loaded no span receivers
Resolving 'value to value#0

=== Result of Batch Resolution ===
!'Project [unresolvedalias('value, None)]   Project [value#0]
 +- Relation[value#0] text                  +- Relation[value#0] text
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#4: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#4: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          
Resolving 'value to value#0

=== Result of Batch Resolution ===
!'Filter (length(trim('value, None)) > 0)   Filter (length(trim(value#0, None)) > 0)
 +- Project [value#0]                       +- Project [value#0]
    +- Relation[value#0] text                  +- Relation[value#0] text
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#5: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#5: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#6: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#6: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 1                                    GlobalLimit 1
 +- LocalLimit 1                                  +- LocalLimit 1
    +- Filter (length(trim(value#0, None)) > 0)      +- Filter (length(trim(value#0, None)) > 0)
!      +- Project [value#0]                             +- Relation[value#0] text
!         +- Relation[value#0] text               
          
Pruning directories with: 
Post-Scan Filters: (length(trim(value#0, None)) > 0)
Output Data Schema: struct<value: string>
Pushed Filters: 
code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

Code generated in 246.517631 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

Code generated in 21.987547 ms
Block broadcast_0 stored as values in memory (estimated size 243.0 KB, free 1987.3 MB)
Put block broadcast_0 locally took  74 ms
Putting block broadcast_0 without replication took  76 ms
Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.2 MB)
Added broadcast_0_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  5 ms
Putting block broadcast_0_piece0 without replication took  6 ms
Created broadcast 0 from csv at SparkUtiles.scala:21
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$1
 +++ Lambda closure ($anonfun$executeTake$1) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$2
 +++ Lambda closure ($anonfun$executeTake$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: csv at SparkUtiles.scala:21
Got job 0 (csv at SparkUtiles.scala:21) with 1 output partitions
Final stage: ResultStage 0 (csv at SparkUtiles.scala:21)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 0)
missing: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at SparkUtiles.scala:21), which has no missing parents
submitMissingTasks(ResultStage 0)
Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 1987.2 MB)
Put block broadcast_1 locally took  2 ms
Putting block broadcast_1 without replication took  3 ms
Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 1987.2 MB)
Added broadcast_1_piece0 in memory on 192.168.1.13:10964 (size: 5.0 KB, free: 1987.5 MB)
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Put block broadcast_1_piece0 locally took  2 ms
Putting block broadcast_1_piece0 without replication took  2 ms
Created broadcast 1 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at SparkUtiles.scala:21) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
parentName: , name: TaskSet_0.0, runningTasks: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 0.0 (TID 0)
Getting local block broadcast_1
Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

Code generated in 17.639894 ms
Getting local block broadcast_0
Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 0.0 in stage 0.0 (TID 0). 1316 bytes result sent to driver
parentName: , name: TaskSet_0.0, runningTasks: 0
Finished task 0.0 in stage 0.0 (TID 0) in 423 ms on localhost (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (csv at SparkUtiles.scala:21) finished in 0.556 s
After removal of stage 0, remaining stages = 0
Job 0 finished: csv at SparkUtiles.scala:21, took 0.609827 s

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#8: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#8: java.lang.String
 +- Project [value#0]                                                                                                                                                     +- Project [value#0]
    +- Relation[value#0] text                                                                                                                                                +- Relation[value#0] text
          

=== Result of Batch Operator Optimization before Inferring Filters ===
!DeserializeToObject cast(value#0 as string).toString, obj#8: java.lang.String   DeserializeToObject value#0.toString, obj#8: java.lang.String
!+- Project [value#0]                                                            +- Relation[value#0] text
!   +- Relation[value#0] text                                                    
          
Pruning directories with: 
Post-Scan Filters: 
Output Data Schema: struct<value: string>
Pushed Filters: 

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }

Code generated in 8.069923 ms
Block broadcast_2 stored as values in memory (estimated size 243.0 KB, free 1987.0 MB)
Put block broadcast_2 locally took  8 ms
Putting block broadcast_2 without replication took  9 ms
Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.0 MB)
Added broadcast_2_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Put block broadcast_2_piece0 locally took  2 ms
Putting block broadcast_2_piece0 without replication took  2 ms
Created broadcast 2 from csv at SparkUtiles.scala:21
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$rdd$1
 +++ Lambda closure ($anonfun$rdd$1) is now cleaned +++
Cleaning lambda: $anonfun$inferFromDataset$2
 +++ Lambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
Parsing command: bomstatis
Parsing command: 
WITH outtab AS
(
       SELECT Get_station(location)            AS station,
              Get_timestamp(monthday,location) AS whole_time ,
              Get_temp(mintemp,maxtemp)        AS temprature,
              Get_pressure()                   AS pressure,
              Get_humidity()                   AS humidy
       FROM   bomstatis)
SELECT Split(station, "[|]")[0]                                                         as location,
       split(station, "[|]")[1]                                                         AS position,
       whole_time                                                                       AS local_time,
       get_condition (cast(replace(temprature,'+','') AS DOUBLE), cast(humidy AS int) ) AS conditions,
       temprature                                                                       AS temperature,
       pressure                                                                         AS pressure,
       humidy                                                                           AS humidity
FROM   outtab
        
Resolving 'location to location#10
Resolving 'monthday to monthday#11
Resolving 'location to location#10
Resolving 'mintemp to mintemp#13
Resolving 'maxtemp to maxtemp#12

=== Result of Batch Resolution ===
!'SubqueryAlias `outtab`                                                                                                                                                                                                    SubqueryAlias `outtab`
!+- 'Project ['Get_station('location) AS station#27, 'Get_timestamp('monthday, 'location) AS whole_time#28, 'Get_temp('mintemp, 'maxtemp) AS temprature#29, 'Get_pressure() AS pressure#30, 'Get_humidity() AS humidy#31]   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!   +- 'UnresolvedRelation `bomstatis`                                                                                                                                                                                         +- SubqueryAlias `bomstatis`
!                                                                                                                                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch UDF ===
 SubqueryAlias `outtab`                                                                                                                                                                                                SubqueryAlias `outtab`
!+- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
    +- SubqueryAlias `bomstatis`                                                                                                                                                                                          +- SubqueryAlias `bomstatis`
       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                          SubqueryAlias `outtab`
 +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
    +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                    +- SubqueryAlias `bomstatis`
       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                      +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Substitution ===
!CTE [outtab]                                                                                                                                                                                                                                                                                                       'Project ['Split('station, [|])[0] AS location#20, 'split('station, [|])[1] AS position#21, 'whole_time AS local_time#22, 'get_condition(cast('replace('temprature, +, ) as double), cast('humidy as int)) AS conditions#23, 'temprature AS temperature#24, 'pressure AS pressure#25, 'humidy AS humidity#26]
!:  +- 'SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                      +- SubqueryAlias `outtab`
!:     +- 'Project ['Get_station('location) AS station#27, 'Get_timestamp('monthday, 'location) AS whole_time#28, 'Get_temp('mintemp, 'maxtemp) AS temprature#29, 'Get_pressure() AS pressure#30, 'Get_humidity() AS humidy#31]                                                                                        +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!:        +- 'UnresolvedRelation `bomstatis`                                                                                                                                                                                                                                                                              +- SubqueryAlias `bomstatis`
!+- 'Project ['Split('station, [|])[0] AS location#20, 'split('station, [|])[1] AS position#21, 'whole_time AS local_time#22, 'get_condition(cast('replace('temprature, +, ) as double), cast('humidy as int)) AS conditions#23, 'temprature AS temperature#24, 'pressure AS pressure#25, 'humidy AS humidity#26]            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!   +- 'UnresolvedRelation `outtab`                                                                                                                                                                                                                                                                                 
          
Resolving 'station to station#27
Resolving 'station to station#27
Resolving 'whole_time to whole_time#28
Resolving 'temprature to temprature#29
Resolving 'humidy to humidy#31
Resolving 'temprature to temprature#29
Resolving 'pressure to pressure#30
Resolving 'humidy to humidy#31
Got cleaning task CleanAccum(21)
Cleaning accumulator 21

=== Result of Batch Resolution ===
!'Project ['Split('station, [|])[0] AS location#20, 'split('station, [|])[1] AS position#21, 'whole_time AS local_time#22, 'get_condition(cast('replace('temprature, +, ) as double), cast('humidy as int)) AS conditions#23, 'temprature AS temperature#24, 'pressure AS pressure#25, 'humidy AS humidity#26]      Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
 +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                          +- SubqueryAlias `outtab`
    +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]      +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
       +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                       +- SubqueryAlias `bomstatis`
          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
Cleaned accumulator 21
Got cleaning task CleanAccum(0)
Cleaning accumulator 0
Cleaned accumulator 0
Got cleaning task CleanAccum(1)
Cleaning accumulator 1
Cleaned accumulator 1
Got cleaning task CleanAccum(14)
Cleaning accumulator 14
Cleaned accumulator 14
Got cleaning task CleanAccum(34)
Cleaning accumulator 34
Cleaned accumulator 34
Got cleaning task CleanAccum(26)
Cleaning accumulator 26
Cleaned accumulator 26
Got cleaning task CleanAccum(22)
Cleaning accumulator 22
Cleaned accumulator 22
Got cleaning task CleanAccum(33)
Cleaning accumulator 33
Cleaned accumulator 33
Got cleaning task CleanAccum(6)
Cleaning accumulator 6
Cleaned accumulator 6
Got cleaning task CleanAccum(25)
Cleaning accumulator 25
Cleaned accumulator 25
Got cleaning task CleanAccum(35)
Cleaning accumulator 35
Cleaned accumulator 35
Got cleaning task CleanAccum(4)
Cleaning accumulator 4
Cleaned accumulator 4
Got cleaning task CleanAccum(10)
Cleaning accumulator 10
Cleaned accumulator 10
Got cleaning task CleanAccum(23)
Cleaning accumulator 23
Cleaned accumulator 23
Got cleaning task CleanAccum(32)
Cleaning accumulator 32
Cleaned accumulator 32
Got cleaning task CleanBroadcast(0)
Cleaning broadcast 0
Unpersisting TorrentBroadcast 0

=== Result of Batch UDF ===
!Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]     Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
 +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                          +- SubqueryAlias `outtab`
    +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]      +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
       +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                       +- SubqueryAlias `bomstatis`
          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
 +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `outtab`
    +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                           +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
       +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                            +- SubqueryAlias `bomstatis`
          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                              +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
removing broadcast 0
Removing broadcast 0
Removing block broadcast_0_piece0
Block broadcast_0_piece0 of size 20482 dropped from memory (free 2083511075)
Removed broadcast_0_piece0 on 192.168.1.13:10964 in memory (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Removing block broadcast_0
Block broadcast_0 of size 248816 dropped from memory (free 2083759891)

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast(location#20 as string), None), unresolvedalias(cast(position#21 as string), None), unresolvedalias(cast(local_time#22 as string), None), unresolvedalias(cast(conditions#23 as string), None), unresolvedalias(cast(temperature#24 as string), None), unresolvedalias(cast(pressure#25 as string), None), unresolvedalias(cast(humidity#26 as string), None)]                               Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]
 +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
    +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `outtab`
       +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                              +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
          +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `bomstatis`
             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
Done removing broadcast 0, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 0
Got cleaning task CleanAccum(15)
Cleaning accumulator 15
Cleaned accumulator 15
Got cleaning task CleanAccum(7)
Cleaning accumulator 7
Cleaned accumulator 7
Got cleaning task CleanAccum(29)
Cleaning accumulator 29
Cleaned accumulator 29
Got cleaning task CleanAccum(31)
Cleaning accumulator 31
Cleaned accumulator 31
Got cleaning task CleanAccum(9)
Cleaning accumulator 9
Cleaned accumulator 9
Got cleaning task CleanAccum(13)
Cleaning accumulator 13
Cleaned accumulator 13
Got cleaning task CleanAccum(11)
Cleaning accumulator 11
Cleaned accumulator 11
Got cleaning task CleanAccum(20)
Cleaning accumulator 20
Cleaned accumulator 20
Got cleaning task CleanAccum(27)
Cleaning accumulator 27
Cleaned accumulator 27
Got cleaning task CleanAccum(18)
Cleaning accumulator 18
Cleaned accumulator 18
Got cleaning task CleanAccum(5)
Cleaning accumulator 5
Cleaned accumulator 5
Got cleaning task CleanAccum(8)
Cleaning accumulator 8
Cleaned accumulator 8
Got cleaning task CleanAccum(24)
Cleaning accumulator 24
Cleaned accumulator 24
Got cleaning task CleanAccum(30)
Cleaning accumulator 30
Cleaned accumulator 30
Got cleaning task CleanAccum(17)
Cleaning accumulator 17
Cleaned accumulator 17
Got cleaning task CleanAccum(28)
Cleaning accumulator 28
Cleaned accumulator 28
Got cleaning task CleanAccum(12)
Cleaning accumulator 12
Cleaned accumulator 12
Got cleaning task CleanAccum(19)
Cleaning accumulator 19
Cleaned accumulator 19
Got cleaning task CleanBroadcast(2)
Cleaning broadcast 2
Unpersisting TorrentBroadcast 2

=== Result of Batch Cleanup ===
 Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]                                                                                 Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]
 +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
    +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `outtab`
       +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                              +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
          +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `bomstatis`
             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
removing broadcast 2
Removing broadcast 2
Removing block broadcast_2
Block broadcast_2 of size 248816 dropped from memory (free 2084008707)
Removing block broadcast_2_piece0
Block broadcast_2_piece0 of size 20482 dropped from memory (free 2084029189)
Removed broadcast_2_piece0 on 192.168.1.13:10964 in memory (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Done removing broadcast 2, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 2
Got cleaning task CleanAccum(2)
Cleaning accumulator 2
Cleaned accumulator 2
Got cleaning task CleanBroadcast(1)
Cleaning broadcast 1
Unpersisting TorrentBroadcast 1
removing broadcast 1
Removing broadcast 1
Removing block broadcast_1
Block broadcast_1 of size 10464 dropped from memory (free 2084039653)
Removing block broadcast_1_piece0
Block broadcast_1_piece0 of size 5147 dropped from memory (free 2084044800)
Removed broadcast_1_piece0 on 192.168.1.13:10964 in memory (size: 5.0 KB, free: 1987.5 MB)
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Done removing broadcast 1, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 1
Got cleaning task CleanAccum(3)
Cleaning accumulator 3
Cleaned accumulator 3
Got cleaning task CleanAccum(16)
Cleaning accumulator 16
Cleaned accumulator 16

=== Result of Batch Finish Analysis ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                   GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                 +- LocalLimit 21
    +- Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]                                                                                    +- Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]
       +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]         +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!         +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                        +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!            +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                    +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!               +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!                  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                   GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                 +- LocalLimit 21
!   +- Project [cast(location#20 as string) AS location#46, cast(position#21 as string) AS position#47, cast(local_time#22 as string) AS local_time#48, cast(conditions#23 as string) AS conditions#49, cast(temperature#24 as string) AS temperature#50, cast(pressure#25 as string) AS pressure#51, cast(humidity#26 as string) AS humidity#52]                                                                                    +- Project [split(UDF(location#10), [|])[0] AS location#46, split(UDF(location#10), [|])[1] AS position#47, UDF(monthday#11, location#10) AS local_time#48, if ((isnull(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double)) || isnull(cast(UDF() as int)))) null else UDF(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double), cast(UDF() as int)) AS conditions#49, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#50, UDF() AS pressure#51, UDF() AS humidity#52]
!      +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                           
!            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                           
          
Pruning directories with: 
Post-Scan Filters: 
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, getcolumnbyordinal(3, StringType).toString, getcolumnbyordinal(4, StringType).toString, getcolumnbyordinal(5, StringType).toString, getcolumnbyordinal(6, StringType).toString, StructField(location,StringType,true), StructField(position,StringType,true), StructField(local_time,StringType,true), StructField(conditions,StringType,true), StructField(temperature,StringType,true), StructField(pressure,StringType,true), StructField(humidity,StringType,true))), obj#60: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(location#46.toString, position#47.toString, local_time#48.toString, conditions#49.toString, temperature#50.toString, pressure#51.toString, humidity#52.toString, StructField(location,StringType,true), StructField(position,StringType,true), StructField(local_time,StringType,true), StructField(conditions,StringType,true), StructField(temperature,StringType,true), StructField(pressure,StringType,true), StructField(humidity,StringType,true)), obj#60: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [location#46, position#47, local_time#48, conditions#49, temperature#50, pressure#51, humidity#52]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   +- LocalRelation <empty>, [location#46, position#47, local_time#48, conditions#49, temperature#50, pressure#51, humidity#52]
          
code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, input[3, string, true].toString, input[4, string, true].toString, input[5, string, true].toString, input[6, string, true].toString, StructField(location,StringType,true), StructField(position,StringType,true), StructField(local_time,StringType,true), StructField(conditions,StringType,true), StructField(temperature,StringType,true), StructField(pressure,StringType,true), StructField(humidity,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[7];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     createExternalRow_0_2(i, values_0);
/* 027 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 028 */     if (false) {
/* 029 */       mutableRow.setNullAt(0);
/* 030 */     } else {
/* 031 */
/* 032 */       mutableRow.update(0, value_0);
/* 033 */     }
/* 034 */
/* 035 */     return mutableRow;
/* 036 */   }
/* 037 */
/* 038 */
/* 039 */   private void createExternalRow_0_2(InternalRow i, Object[] values_0) {
/* 040 */
/* 041 */     boolean isNull_14 = i.isNullAt(6);
/* 042 */     UTF8String value_14 = isNull_14 ?
/* 043 */     null : (i.getUTF8String(6));
/* 044 */     boolean isNull_13 = true;
/* 045 */     java.lang.String value_13 = null;
/* 046 */     if (!isNull_14) {
/* 047 */
/* 048 */       isNull_13 = false;
/* 049 */       if (!isNull_13) {
/* 050 */
/* 051 */         Object funcResult_6 = null;
/* 052 */         funcResult_6 = value_14.toString();
/* 053 */         value_13 = (java.lang.String) funcResult_6;
/* 054 */
/* 055 */       }
/* 056 */     }
/* 057 */     if (isNull_13) {
/* 058 */       values_0[6] = null;
/* 059 */     } else {
/* 060 */       values_0[6] = value_13;
/* 061 */     }
/* 062 */
/* 063 */   }
/* 064 */
/* 065 */
/* 066 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 067 */
/* 068 */     boolean isNull_8 = i.isNullAt(3);
/* 069 */     UTF8String value_8 = isNull_8 ?
/* 070 */     null : (i.getUTF8String(3));
/* 071 */     boolean isNull_7 = true;
/* 072 */     java.lang.String value_7 = null;
/* 073 */     if (!isNull_8) {
/* 074 */
/* 075 */       isNull_7 = false;
/* 076 */       if (!isNull_7) {
/* 077 */
/* 078 */         Object funcResult_3 = null;
/* 079 */         funcResult_3 = value_8.toString();
/* 080 */         value_7 = (java.lang.String) funcResult_3;
/* 081 */
/* 082 */       }
/* 083 */     }
/* 084 */     if (isNull_7) {
/* 085 */       values_0[3] = null;
/* 086 */     } else {
/* 087 */       values_0[3] = value_7;
/* 088 */     }
/* 089 */
/* 090 */     boolean isNull_10 = i.isNullAt(4);
/* 091 */     UTF8String value_10 = isNull_10 ?
/* 092 */     null : (i.getUTF8String(4));
/* 093 */     boolean isNull_9 = true;
/* 094 */     java.lang.String value_9 = null;
/* 095 */     if (!isNull_10) {
/* 096 */
/* 097 */       isNull_9 = false;
/* 098 */       if (!isNull_9) {
/* 099 */
/* 100 */         Object funcResult_4 = null;
/* 101 */         funcResult_4 = value_10.toString();
/* 102 */         value_9 = (java.lang.String) funcResult_4;
/* 103 */
/* 104 */       }
/* 105 */     }
/* 106 */     if (isNull_9) {
/* 107 */       values_0[4] = null;
/* 108 */     } else {
/* 109 */       values_0[4] = value_9;
/* 110 */     }
/* 111 */
/* 112 */     boolean isNull_12 = i.isNullAt(5);
/* 113 */     UTF8String value_12 = isNull_12 ?
/* 114 */     null : (i.getUTF8String(5));
/* 115 */     boolean isNull_11 = true;
/* 116 */     java.lang.String value_11 = null;
/* 117 */     if (!isNull_12) {
/* 118 */
/* 119 */       isNull_11 = false;
/* 120 */       if (!isNull_11) {
/* 121 */
/* 122 */         Object funcResult_5 = null;
/* 123 */         funcResult_5 = value_12.toString();
/* 124 */         value_11 = (java.lang.String) funcResult_5;
/* 125 */
/* 126 */       }
/* 127 */     }
/* 128 */     if (isNull_11) {
/* 129 */       values_0[5] = null;
/* 130 */     } else {
/* 131 */       values_0[5] = value_11;
/* 132 */     }
/* 133 */
/* 134 */   }
/* 135 */
/* 136 */
/* 137 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 138 */
/* 139 */     boolean isNull_2 = i.isNullAt(0);
/* 140 */     UTF8String value_2 = isNull_2 ?
/* 141 */     null : (i.getUTF8String(0));
/* 142 */     boolean isNull_1 = true;
/* 143 */     java.lang.String value_1 = null;
/* 144 */     if (!isNull_2) {
/* 145 */
/* 146 */       isNull_1 = false;
/* 147 */       if (!isNull_1) {
/* 148 */
/* 149 */         Object funcResult_0 = null;
/* 150 */         funcResult_0 = value_2.toString();
/* 151 */         value_1 = (java.lang.String) funcResult_0;
/* 152 */
/* 153 */       }
/* 154 */     }
/* 155 */     if (isNull_1) {
/* 156 */       values_0[0] = null;
/* 157 */     } else {
/* 158 */       values_0[0] = value_1;
/* 159 */     }
/* 160 */
/* 161 */     boolean isNull_4 = i.isNullAt(1);
/* 162 */     UTF8String value_4 = isNull_4 ?
/* 163 */     null : (i.getUTF8String(1));
/* 164 */     boolean isNull_3 = true;
/* 165 */     java.lang.String value_3 = null;
/* 166 */     if (!isNull_4) {
/* 167 */
/* 168 */       isNull_3 = false;
/* 169 */       if (!isNull_3) {
/* 170 */
/* 171 */         Object funcResult_1 = null;
/* 172 */         funcResult_1 = value_4.toString();
/* 173 */         value_3 = (java.lang.String) funcResult_1;
/* 174 */
/* 175 */       }
/* 176 */     }
/* 177 */     if (isNull_3) {
/* 178 */       values_0[1] = null;
/* 179 */     } else {
/* 180 */       values_0[1] = value_3;
/* 181 */     }
/* 182 */
/* 183 */     boolean isNull_6 = i.isNullAt(2);
/* 184 */     UTF8String value_6 = isNull_6 ?
/* 185 */     null : (i.getUTF8String(2));
/* 186 */     boolean isNull_5 = true;
/* 187 */     java.lang.String value_5 = null;
/* 188 */     if (!isNull_6) {
/* 189 */
/* 190 */       isNull_5 = false;
/* 191 */       if (!isNull_5) {
/* 192 */
/* 193 */         Object funcResult_2 = null;
/* 194 */         funcResult_2 = value_6.toString();
/* 195 */         value_5 = (java.lang.String) funcResult_2;
/* 196 */
/* 197 */       }
/* 198 */     }
/* 199 */     if (isNull_5) {
/* 200 */       values_0[2] = null;
/* 201 */     } else {
/* 202 */       values_0[2] = value_5;
/* 203 */     }
/* 204 */
/* 205 */   }
/* 206 */
/* 207 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[7];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     createExternalRow_0_2(i, values_0);
/* 027 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 028 */     if (false) {
/* 029 */       mutableRow.setNullAt(0);
/* 030 */     } else {
/* 031 */
/* 032 */       mutableRow.update(0, value_0);
/* 033 */     }
/* 034 */
/* 035 */     return mutableRow;
/* 036 */   }
/* 037 */
/* 038 */
/* 039 */   private void createExternalRow_0_2(InternalRow i, Object[] values_0) {
/* 040 */
/* 041 */     boolean isNull_14 = i.isNullAt(6);
/* 042 */     UTF8String value_14 = isNull_14 ?
/* 043 */     null : (i.getUTF8String(6));
/* 044 */     boolean isNull_13 = true;
/* 045 */     java.lang.String value_13 = null;
/* 046 */     if (!isNull_14) {
/* 047 */
/* 048 */       isNull_13 = false;
/* 049 */       if (!isNull_13) {
/* 050 */
/* 051 */         Object funcResult_6 = null;
/* 052 */         funcResult_6 = value_14.toString();
/* 053 */         value_13 = (java.lang.String) funcResult_6;
/* 054 */
/* 055 */       }
/* 056 */     }
/* 057 */     if (isNull_13) {
/* 058 */       values_0[6] = null;
/* 059 */     } else {
/* 060 */       values_0[6] = value_13;
/* 061 */     }
/* 062 */
/* 063 */   }
/* 064 */
/* 065 */
/* 066 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 067 */
/* 068 */     boolean isNull_8 = i.isNullAt(3);
/* 069 */     UTF8String value_8 = isNull_8 ?
/* 070 */     null : (i.getUTF8String(3));
/* 071 */     boolean isNull_7 = true;
/* 072 */     java.lang.String value_7 = null;
/* 073 */     if (!isNull_8) {
/* 074 */
/* 075 */       isNull_7 = false;
/* 076 */       if (!isNull_7) {
/* 077 */
/* 078 */         Object funcResult_3 = null;
/* 079 */         funcResult_3 = value_8.toString();
/* 080 */         value_7 = (java.lang.String) funcResult_3;
/* 081 */
/* 082 */       }
/* 083 */     }
/* 084 */     if (isNull_7) {
/* 085 */       values_0[3] = null;
/* 086 */     } else {
/* 087 */       values_0[3] = value_7;
/* 088 */     }
/* 089 */
/* 090 */     boolean isNull_10 = i.isNullAt(4);
/* 091 */     UTF8String value_10 = isNull_10 ?
/* 092 */     null : (i.getUTF8String(4));
/* 093 */     boolean isNull_9 = true;
/* 094 */     java.lang.String value_9 = null;
/* 095 */     if (!isNull_10) {
/* 096 */
/* 097 */       isNull_9 = false;
/* 098 */       if (!isNull_9) {
/* 099 */
/* 100 */         Object funcResult_4 = null;
/* 101 */         funcResult_4 = value_10.toString();
/* 102 */         value_9 = (java.lang.String) funcResult_4;
/* 103 */
/* 104 */       }
/* 105 */     }
/* 106 */     if (isNull_9) {
/* 107 */       values_0[4] = null;
/* 108 */     } else {
/* 109 */       values_0[4] = value_9;
/* 110 */     }
/* 111 */
/* 112 */     boolean isNull_12 = i.isNullAt(5);
/* 113 */     UTF8String value_12 = isNull_12 ?
/* 114 */     null : (i.getUTF8String(5));
/* 115 */     boolean isNull_11 = true;
/* 116 */     java.lang.String value_11 = null;
/* 117 */     if (!isNull_12) {
/* 118 */
/* 119 */       isNull_11 = false;
/* 120 */       if (!isNull_11) {
/* 121 */
/* 122 */         Object funcResult_5 = null;
/* 123 */         funcResult_5 = value_12.toString();
/* 124 */         value_11 = (java.lang.String) funcResult_5;
/* 125 */
/* 126 */       }
/* 127 */     }
/* 128 */     if (isNull_11) {
/* 129 */       values_0[5] = null;
/* 130 */     } else {
/* 131 */       values_0[5] = value_11;
/* 132 */     }
/* 133 */
/* 134 */   }
/* 135 */
/* 136 */
/* 137 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 138 */
/* 139 */     boolean isNull_2 = i.isNullAt(0);
/* 140 */     UTF8String value_2 = isNull_2 ?
/* 141 */     null : (i.getUTF8String(0));
/* 142 */     boolean isNull_1 = true;
/* 143 */     java.lang.String value_1 = null;
/* 144 */     if (!isNull_2) {
/* 145 */
/* 146 */       isNull_1 = false;
/* 147 */       if (!isNull_1) {
/* 148 */
/* 149 */         Object funcResult_0 = null;
/* 150 */         funcResult_0 = value_2.toString();
/* 151 */         value_1 = (java.lang.String) funcResult_0;
/* 152 */
/* 153 */       }
/* 154 */     }
/* 155 */     if (isNull_1) {
/* 156 */       values_0[0] = null;
/* 157 */     } else {
/* 158 */       values_0[0] = value_1;
/* 159 */     }
/* 160 */
/* 161 */     boolean isNull_4 = i.isNullAt(1);
/* 162 */     UTF8String value_4 = isNull_4 ?
/* 163 */     null : (i.getUTF8String(1));
/* 164 */     boolean isNull_3 = true;
/* 165 */     java.lang.String value_3 = null;
/* 166 */     if (!isNull_4) {
/* 167 */
/* 168 */       isNull_3 = false;
/* 169 */       if (!isNull_3) {
/* 170 */
/* 171 */         Object funcResult_1 = null;
/* 172 */         funcResult_1 = value_4.toString();
/* 173 */         value_3 = (java.lang.String) funcResult_1;
/* 174 */
/* 175 */       }
/* 176 */     }
/* 177 */     if (isNull_3) {
/* 178 */       values_0[1] = null;
/* 179 */     } else {
/* 180 */       values_0[1] = value_3;
/* 181 */     }
/* 182 */
/* 183 */     boolean isNull_6 = i.isNullAt(2);
/* 184 */     UTF8String value_6 = isNull_6 ?
/* 185 */     null : (i.getUTF8String(2));
/* 186 */     boolean isNull_5 = true;
/* 187 */     java.lang.String value_5 = null;
/* 188 */     if (!isNull_6) {
/* 189 */
/* 190 */       isNull_5 = false;
/* 191 */       if (!isNull_5) {
/* 192 */
/* 193 */         Object funcResult_2 = null;
/* 194 */         funcResult_2 = value_6.toString();
/* 195 */         value_5 = (java.lang.String) funcResult_2;
/* 196 */
/* 197 */       }
/* 198 */     }
/* 199 */     if (isNull_5) {
/* 200 */       values_0[2] = null;
/* 201 */     } else {
/* 202 */       values_0[2] = value_5;
/* 203 */     }
/* 204 */
/* 205 */   }
/* 206 */
/* 207 */ }

Code generated in 24.713472 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 029 */       UTF8String scan_value_0 = scan_isNull_0 ?
/* 030 */       null : (scan_row_0.getUTF8String(0));
/* 031 */       boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 032 */       UTF8String scan_value_2 = scan_isNull_2 ?
/* 033 */       null : (scan_row_0.getUTF8String(2));
/* 034 */       boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 035 */       UTF8String scan_value_3 = scan_isNull_3 ?
/* 036 */       null : (scan_row_0.getUTF8String(3));
/* 037 */
/* 038 */       boolean project_isNull_0 = true;
/* 039 */       UTF8String project_value_0 = null;
/* 040 */       boolean project_isNull_1 = true;
/* 041 */       ArrayData project_value_1 = null;
/* 042 */       Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[1] /* converters */)[0].apply(scan_value_0);
/* 043 */
/* 044 */       UTF8String project_result_0 = null;
/* 045 */       try {
/* 046 */         project_result_0 = (UTF8String)((scala.Function1[]) references[1] /* converters */)[1].apply(((scala.Function1) references[3] /* udf */).apply(project_arg_0));
/* 047 */       } catch (Exception e) {
/* 048 */         throw new org.apache.spark.SparkException(((java.lang.String) references[2] /* errMsg */), e);
/* 049 */       }
/* 050 */
/* 051 */       boolean project_isNull_2 = project_result_0 == null;
/* 052 */       UTF8String project_value_2 = null;
/* 053 */       if (!project_isNull_2) {
/* 054 */         project_value_2 = project_result_0;
/* 055 */       }
/* 056 */       if (!project_isNull_2) {
/* 057 */         project_isNull_1 = false; // resultCode could change nullability.
/* 058 */         project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[4] /* literal */), -1));
/* 059 */
/* 060 */       }
/* 061 */       if (!project_isNull_1) {
/* 062 */         project_isNull_0 = false; // resultCode could change nullability.
/* 063 */
/* 064 */         final int project_index_0 = (int) 0;
/* 065 */         if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 066 */           project_isNull_0 = true;
/* 067 */         } else {
/* 068 */           project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 069 */         }
/* 070 */
/* 071 */       }
/* 072 */       boolean project_isNull_6 = true;
/* 073 */       UTF8String project_value_6 = null;
/* 074 */       boolean project_isNull_7 = true;
/* 075 */       ArrayData project_value_7 = null;
/* 076 */       Object project_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 077 */
/* 078 */       UTF8String project_result_1 = null;
/* 079 */       try {
/* 080 */         project_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(project_arg_1));
/* 081 */       } catch (Exception e) {
/* 082 */         throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 083 */       }
/* 084 */
/* 085 */       boolean project_isNull_8 = project_result_1 == null;
/* 086 */       UTF8String project_value_8 = null;
/* 087 */       if (!project_isNull_8) {
/* 088 */         project_value_8 = project_result_1;
/* 089 */       }
/* 090 */       if (!project_isNull_8) {
/* 091 */         project_isNull_7 = false; // resultCode could change nullability.
/* 092 */         project_value_7 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_8.split(((UTF8String) references[8] /* literal */), -1));
/* 093 */
/* 094 */       }
/* 095 */       if (!project_isNull_7) {
/* 096 */         project_isNull_6 = false; // resultCode could change nullability.
/* 097 */
/* 098 */         final int project_index_1 = (int) 1;
/* 099 */         if (project_index_1 >= project_value_7.numElements() || project_index_1 < 0 || project_value_7.isNullAt(project_index_1)) {
/* 100 */           project_isNull_6 = true;
/* 101 */         } else {
/* 102 */           project_value_6 = project_value_7.getUTF8String(project_index_1);
/* 103 */         }
/* 104 */
/* 105 */       }
/* 106 */       boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 107 */       UTF8String scan_value_1 = scan_isNull_1 ?
/* 108 */       null : (scan_row_0.getUTF8String(1));
/* 109 */
/* 110 */       Object project_arg_2 = scan_isNull_1 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_1);
/* 111 */       Object project_arg_3 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[1].apply(scan_value_0);
/* 112 */
/* 113 */       UTF8String project_result_2 = null;
/* 114 */       try {
/* 115 */         project_result_2 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[2].apply(((scala.Function2) references[11] /* udf */).apply(project_arg_2, project_arg_3));
/* 116 */       } catch (Exception e) {
/* 117 */         throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 118 */       }
/* 119 */
/* 120 */       boolean project_isNull_12 = project_result_2 == null;
/* 121 */       UTF8String project_value_12 = null;
/* 122 */       if (!project_isNull_12) {
/* 123 */         project_value_12 = project_result_2;
/* 124 */       }
/* 125 */       boolean project_isNull_19 = true;
/* 126 */       UTF8String project_value_19 = null;
/* 127 */       boolean project_isNull_23 = scan_isNull_3;
/* 128 */       double project_value_23 = -1.0;
/* 129 */       if (!scan_isNull_3) {
/* 130 */         try {
/* 131 */           project_value_23 = Double.valueOf(scan_value_3.toString());
/* 132 */         } catch (java.lang.NumberFormatException e) {
/* 133 */           project_isNull_23 = true;
/* 134 */         }
/* 135 */       }
/* 136 */       boolean project_value_21 = true;
/* 137 */
/* 138 */       if (!project_isNull_23) {
/* 139 */         boolean project_isNull_26 = scan_isNull_2;
/* 140 */         double project_value_26 = -1.0;
/* 141 */         if (!scan_isNull_2) {
/* 142 */           try {
/* 143 */             project_value_26 = Double.valueOf(scan_value_2.toString());
/* 144 */           } catch (java.lang.NumberFormatException e) {
/* 145 */             project_isNull_26 = true;
/* 146 */           }
/* 147 */         }
/* 148 */         project_value_21 = project_isNull_26;
/* 149 */       }
/* 150 */       boolean project_isNull_20 = false;
/* 151 */       UTF8String project_value_20 = null;
/* 152 */       if (!false && project_value_21) {
/* 153 */         project_isNull_20 = true;
/* 154 */         project_value_20 = ((UTF8String)null);
/* 155 */       } else {
/* 156 */         boolean project_isNull_30 = scan_isNull_3;
/* 157 */         double project_value_30 = -1.0;
/* 158 */         if (!scan_isNull_3) {
/* 159 */           try {
/* 160 */             project_value_30 = Double.valueOf(scan_value_3.toString());
/* 161 */           } catch (java.lang.NumberFormatException e) {
/* 162 */             project_isNull_30 = true;
/* 163 */           }
/* 164 */         }
/* 165 */         boolean project_isNull_32 = scan_isNull_2;
/* 166 */         double project_value_32 = -1.0;
/* 167 */         if (!scan_isNull_2) {
/* 168 */           try {
/* 169 */             project_value_32 = Double.valueOf(scan_value_2.toString());
/* 170 */           } catch (java.lang.NumberFormatException e) {
/* 171 */             project_isNull_32 = true;
/* 172 */           }
/* 173 */         }
/* 174 */         Object project_arg_4 = project_isNull_30 ? null : ((scala.Function1[]) references[12] /* converters */)[0].apply(project_value_30);
/* 175 */         Object project_arg_5 = project_isNull_32 ? null : ((scala.Function1[]) references[12] /* converters */)[1].apply(project_value_32);
/* 176 */
/* 177 */         UTF8String project_result_3 = null;
/* 178 */         try {
/* 179 */           project_result_3 = (UTF8String)((scala.Function1[]) references[12] /* converters */)[2].apply(((scala.Function2) references[14] /* udf */).apply(project_arg_4, project_arg_5));
/* 180 */         } catch (Exception e) {
/* 181 */           throw new org.apache.spark.SparkException(((java.lang.String) references[13] /* errMsg */), e);
/* 182 */         }
/* 183 */
/* 184 */         boolean project_isNull_29 = project_result_3 == null;
/* 185 */         UTF8String project_value_29 = null;
/* 186 */         if (!project_isNull_29) {
/* 187 */           project_value_29 = project_result_3;
/* 188 */         }
/* 189 */         project_isNull_20 = project_isNull_29;
/* 190 */         project_value_20 = project_value_29;
/* 191 */       }
/* 192 */       if (!project_isNull_20) {
/* 193 */         project_isNull_19 = false; // resultCode could change nullability.
/* 194 */         project_value_19 = project_value_20.replace(((UTF8String) references[15] /* literal */), ((UTF8String) references[16] /* literal */));
/* 195 */
/* 196 */       }
/* 197 */       boolean project_isNull_18 = project_isNull_19;
/* 198 */       double project_value_18 = -1.0;
/* 199 */       if (!project_isNull_19) {
/* 200 */         try {
/* 201 */           project_value_18 = Double.valueOf(project_value_19.toString());
/* 202 */         } catch (java.lang.NumberFormatException e) {
/* 203 */           project_isNull_18 = true;
/* 204 */         }
/* 205 */       }
/* 206 */       boolean project_value_16 = true;
/* 207 */
/* 208 */       if (!project_isNull_18) {
/* 209 */         UTF8String project_result_4 = null;
/* 210 */         try {
/* 211 */           project_result_4 = (UTF8String)((scala.Function1[]) references[17] /* converters */)[0].apply(((scala.Function0) references[19] /* udf */).apply());
/* 212 */         } catch (Exception e) {
/* 213 */           throw new org.apache.spark.SparkException(((java.lang.String) references[18] /* errMsg */), e);
/* 214 */         }
/* 215 */
/* 216 */         boolean project_isNull_38 = project_result_4 == null;
/* 217 */         UTF8String project_value_38 = null;
/* 218 */         if (!project_isNull_38) {
/* 219 */           project_value_38 = project_result_4;
/* 220 */         }
/* 221 */         boolean project_isNull_37 = project_isNull_38;
/* 222 */         int project_value_37 = -1;
/* 223 */         if (!project_isNull_38) {
/* 224 */           UTF8String.IntWrapper project_intWrapper_0 = new UTF8String.IntWrapper();
/* 225 */           if (project_value_38.toInt(project_intWrapper_0)) {
/* 226 */             project_value_37 = project_intWrapper_0.value;
/* 227 */           } else {
/* 228 */             project_isNull_37 = true;
/* 229 */           }
/* 230 */           project_intWrapper_0 = null;
/* 231 */         }
/* 232 */         project_value_16 = project_isNull_37;
/* 233 */       }
/* 234 */       boolean project_isNull_15 = false;
/* 235 */       UTF8String project_value_15 = null;
/* 236 */       if (!false && project_value_16) {
/* 237 */         project_isNull_15 = true;
/* 238 */         project_value_15 = ((UTF8String)null);
/* 239 */       } else {
/* 240 */         boolean project_isNull_42 = true;
/* 241 */         UTF8String project_value_42 = null;
/* 242 */         boolean project_isNull_46 = scan_isNull_3;
/* 243 */         double project_value_46 = -1.0;
/* 244 */         if (!scan_isNull_3) {
/* 245 */           try {
/* 246 */             project_value_46 = Double.valueOf(scan_value_3.toString());
/* 247 */           } catch (java.lang.NumberFormatException e) {
/* 248 */             project_isNull_46 = true;
/* 249 */           }
/* 250 */         }
/* 251 */         boolean project_value_44 = true;
/* 252 */
/* 253 */         if (!project_isNull_46) {
/* 254 */           boolean project_isNull_49 = scan_isNull_2;
/* 255 */           double project_value_49 = -1.0;
/* 256 */           if (!scan_isNull_2) {
/* 257 */             try {
/* 258 */               project_value_49 = Double.valueOf(scan_value_2.toString());
/* 259 */             } catch (java.lang.NumberFormatException e) {
/* 260 */               project_isNull_49 = true;
/* 261 */             }
/* 262 */           }
/* 263 */           project_value_44 = project_isNull_49;
/* 264 */         }
/* 265 */         boolean project_isNull_43 = false;
/* 266 */         UTF8String project_value_43 = null;
/* 267 */         if (!false && project_value_44) {
/* 268 */           project_isNull_43 = true;
/* 269 */           project_value_43 = ((UTF8String)null);
/* 270 */         } else {
/* 271 */           boolean project_isNull_53 = scan_isNull_3;
/* 272 */           double project_value_53 = -1.0;
/* 273 */           if (!scan_isNull_3) {
/* 274 */             try {
/* 275 */               project_value_53 = Double.valueOf(scan_value_3.toString());
/* 276 */             } catch (java.lang.NumberFormatException e) {
/* 277 */               project_isNull_53 = true;
/* 278 */             }
/* 279 */           }
/* 280 */           boolean project_isNull_55 = scan_isNull_2;
/* 281 */           double project_value_55 = -1.0;
/* 282 */           if (!scan_isNull_2) {
/* 283 */             try {
/* 284 */               project_value_55 = Double.valueOf(scan_value_2.toString());
/* 285 */             } catch (java.lang.NumberFormatException e) {
/* 286 */               project_isNull_55 = true;
/* 287 */             }
/* 288 */           }
/* 289 */           Object project_arg_6 = project_isNull_53 ? null : ((scala.Function1[]) references[22] /* converters */)[0].apply(project_value_53);
/* 290 */           Object project_arg_7 = project_isNull_55 ? null : ((scala.Function1[]) references[22] /* converters */)[1].apply(project_value_55);
/* 291 */
/* 292 */           UTF8String project_result_6 = null;
/* 293 */           try {
/* 294 */             project_result_6 = (UTF8String)((scala.Function1[]) references[22] /* converters */)[2].apply(((scala.Function2) references[24] /* udf */).apply(project_arg_6, project_arg_7));
/* 295 */           } catch (Exception e) {
/* 296 */             throw new org.apache.spark.SparkException(((java.lang.String) references[23] /* errMsg */), e);
/* 297 */           }
/* 298 */
/* 299 */           boolean project_isNull_52 = project_result_6 == null;
/* 300 */           UTF8String project_value_52 = null;
/* 301 */           if (!project_isNull_52) {
/* 302 */             project_value_52 = project_result_6;
/* 303 */           }
/* 304 */           project_isNull_43 = project_isNull_52;
/* 305 */           project_value_43 = project_value_52;
/* 306 */         }
/* 307 */         if (!project_isNull_43) {
/* 308 */           project_isNull_42 = false; // resultCode could change nullability.
/* 309 */           project_value_42 = project_value_43.replace(((UTF8String) references[25] /* literal */), ((UTF8String) references[26] /* literal */));
/* 310 */
/* 311 */         }
/* 312 */         boolean project_isNull_41 = project_isNull_42;
/* 313 */         double project_value_41 = -1.0;
/* 314 */         if (!project_isNull_42) {
/* 315 */           try {
/* 316 */             project_value_41 = Double.valueOf(project_value_42.toString());
/* 317 */           } catch (java.lang.NumberFormatException e) {
/* 318 */             project_isNull_41 = true;
/* 319 */           }
/* 320 */         }
/* 321 */         UTF8String project_result_7 = null;
/* 322 */         try {
/* 323 */           project_result_7 = (UTF8String)((scala.Function1[]) references[27] /* converters */)[0].apply(((scala.Function0) references[29] /* udf */).apply());
/* 324 */         } catch (Exception e) {
/* 325 */           throw new org.apache.spark.SparkException(((java.lang.String) references[28] /* errMsg */), e);
/* 326 */         }
/* 327 */
/* 328 */         boolean project_isNull_60 = project_result_7 == null;
/* 329 */         UTF8String project_value_60 = null;
/* 330 */         if (!project_isNull_60) {
/* 331 */           project_value_60 = project_result_7;
/* 332 */         }
/* 333 */         boolean project_isNull_59 = project_isNull_60;
/* 334 */         int project_value_59 = -1;
/* 335 */         if (!project_isNull_60) {
/* 336 */           UTF8String.IntWrapper project_intWrapper_1 = new UTF8String.IntWrapper();
/* 337 */           if (project_value_60.toInt(project_intWrapper_1)) {
/* 338 */             project_value_59 = project_intWrapper_1.value;
/* 339 */           } else {
/* 340 */             project_isNull_59 = true;
/* 341 */           }
/* 342 */           project_intWrapper_1 = null;
/* 343 */         }
/* 344 */         Object project_arg_8 = project_isNull_41 ? null : ((scala.Function1[]) references[20] /* converters */)[0].apply(project_value_41);
/* 345 */         Object project_arg_9 = project_isNull_59 ? null : ((scala.Function1[]) references[20] /* converters */)[1].apply(project_value_59);
/* 346 */
/* 347 */         UTF8String project_result_5 = null;
/* 348 */         try {
/* 349 */           project_result_5 = (UTF8String)((scala.Function1[]) references[20] /* converters */)[2].apply(((scala.Function2) references[30] /* udf */).apply(project_arg_8, project_arg_9));
/* 350 */         } catch (Exception e) {
/* 351 */           throw new org.apache.spark.SparkException(((java.lang.String) references[21] /* errMsg */), e);
/* 352 */         }
/* 353 */
/* 354 */         boolean project_isNull_40 = project_result_5 == null;
/* 355 */         UTF8String project_value_40 = null;
/* 356 */         if (!project_isNull_40) {
/* 357 */           project_value_40 = project_result_5;
/* 358 */         }
/* 359 */         project_isNull_15 = project_isNull_40;
/* 360 */         project_value_15 = project_value_40;
/* 361 */       }
/* 362 */       boolean project_isNull_64 = scan_isNull_3;
/* 363 */       double project_value_64 = -1.0;
/* 364 */       if (!scan_isNull_3) {
/* 365 */         try {
/* 366 */           project_value_64 = Double.valueOf(scan_value_3.toString());
/* 367 */         } catch (java.lang.NumberFormatException e) {
/* 368 */           project_isNull_64 = true;
/* 369 */         }
/* 370 */       }
/* 371 */       boolean project_value_62 = true;
/* 372 */
/* 373 */       if (!project_isNull_64) {
/* 374 */         boolean project_isNull_67 = scan_isNull_2;
/* 375 */         double project_value_67 = -1.0;
/* 376 */         if (!scan_isNull_2) {
/* 377 */           try {
/* 378 */             project_value_67 = Double.valueOf(scan_value_2.toString());
/* 379 */           } catch (java.lang.NumberFormatException e) {
/* 380 */             project_isNull_67 = true;
/* 381 */           }
/* 382 */         }
/* 383 */         project_value_62 = project_isNull_67;
/* 384 */       }
/* 385 */       boolean project_isNull_61 = false;
/* 386 */       UTF8String project_value_61 = null;
/* 387 */       if (!false && project_value_62) {
/* 388 */         project_isNull_61 = true;
/* 389 */         project_value_61 = ((UTF8String)null);
/* 390 */       } else {
/* 391 */         boolean project_isNull_71 = scan_isNull_3;
/* 392 */         double project_value_71 = -1.0;
/* 393 */         if (!scan_isNull_3) {
/* 394 */           try {
/* 395 */             project_value_71 = Double.valueOf(scan_value_3.toString());
/* 396 */           } catch (java.lang.NumberFormatException e) {
/* 397 */             project_isNull_71 = true;
/* 398 */           }
/* 399 */         }
/* 400 */         boolean project_isNull_73 = scan_isNull_2;
/* 401 */         double project_value_73 = -1.0;
/* 402 */         if (!scan_isNull_2) {
/* 403 */           try {
/* 404 */             project_value_73 = Double.valueOf(scan_value_2.toString());
/* 405 */           } catch (java.lang.NumberFormatException e) {
/* 406 */             project_isNull_73 = true;
/* 407 */           }
/* 408 */         }
/* 409 */         Object project_arg_10 = project_isNull_71 ? null : ((scala.Function1[]) references[31] /* converters */)[0].apply(project_value_71);
/* 410 */         Object project_arg_11 = project_isNull_73 ? null : ((scala.Function1[]) references[31] /* converters */)[1].apply(project_value_73);
/* 411 */
/* 412 */         UTF8String project_result_8 = null;
/* 413 */         try {
/* 414 */           project_result_8 = (UTF8String)((scala.Function1[]) references[31] /* converters */)[2].apply(((scala.Function2) references[33] /* udf */).apply(project_arg_10, project_arg_11));
/* 415 */         } catch (Exception e) {
/* 416 */           throw new org.apache.spark.SparkException(((java.lang.String) references[32] /* errMsg */), e);
/* 417 */         }
/* 418 */
/* 419 */         boolean project_isNull_70 = project_result_8 == null;
/* 420 */         UTF8String project_value_70 = null;
/* 421 */         if (!project_isNull_70) {
/* 422 */           project_value_70 = project_result_8;
/* 423 */         }
/* 424 */         project_isNull_61 = project_isNull_70;
/* 425 */         project_value_61 = project_value_70;
/* 426 */       }
/* 427 */       UTF8String project_result_9 = null;
/* 428 */       try {
/* 429 */         project_result_9 = (UTF8String)((scala.Function1[]) references[34] /* converters */)[0].apply(((scala.Function0) references[36] /* udf */).apply());
/* 430 */       } catch (Exception e) {
/* 431 */         throw new org.apache.spark.SparkException(((java.lang.String) references[35] /* errMsg */), e);
/* 432 */       }
/* 433 */
/* 434 */       boolean project_isNull_75 = project_result_9 == null;
/* 435 */       UTF8String project_value_75 = null;
/* 436 */       if (!project_isNull_75) {
/* 437 */         project_value_75 = project_result_9;
/* 438 */       }
/* 439 */       UTF8String project_result_10 = null;
/* 440 */       try {
/* 441 */         project_result_10 = (UTF8String)((scala.Function1[]) references[37] /* converters */)[0].apply(((scala.Function0) references[39] /* udf */).apply());
/* 442 */       } catch (Exception e) {
/* 443 */         throw new org.apache.spark.SparkException(((java.lang.String) references[38] /* errMsg */), e);
/* 444 */       }
/* 445 */
/* 446 */       boolean project_isNull_76 = project_result_10 == null;
/* 447 */       UTF8String project_value_76 = null;
/* 448 */       if (!project_isNull_76) {
/* 449 */         project_value_76 = project_result_10;
/* 450 */       }
/* 451 */       project_mutableStateArray_0[0].reset();
/* 452 */
/* 453 */       project_mutableStateArray_0[0].zeroOutNullBytes();
/* 454 */
/* 455 */       if (project_isNull_0) {
/* 456 */         project_mutableStateArray_0[0].setNullAt(0);
/* 457 */       } else {
/* 458 */         project_mutableStateArray_0[0].write(0, project_value_0);
/* 459 */       }
/* 460 */
/* 461 */       if (project_isNull_6) {
/* 462 */         project_mutableStateArray_0[0].setNullAt(1);
/* 463 */       } else {
/* 464 */         project_mutableStateArray_0[0].write(1, project_value_6);
/* 465 */       }
/* 466 */
/* 467 */       if (project_isNull_12) {
/* 468 */         project_mutableStateArray_0[0].setNullAt(2);
/* 469 */       } else {
/* 470 */         project_mutableStateArray_0[0].write(2, project_value_12);
/* 471 */       }
/* 472 */
/* 473 */       if (project_isNull_15) {
/* 474 */         project_mutableStateArray_0[0].setNullAt(3);
/* 475 */       } else {
/* 476 */         project_mutableStateArray_0[0].write(3, project_value_15);
/* 477 */       }
/* 478 */
/* 479 */       if (project_isNull_61) {
/* 480 */         project_mutableStateArray_0[0].setNullAt(4);
/* 481 */       } else {
/* 482 */         project_mutableStateArray_0[0].write(4, project_value_61);
/* 483 */       }
/* 484 */
/* 485 */       if (project_isNull_75) {
/* 486 */         project_mutableStateArray_0[0].setNullAt(5);
/* 487 */       } else {
/* 488 */         project_mutableStateArray_0[0].write(5, project_value_75);
/* 489 */       }
/* 490 */
/* 491 */       if (project_isNull_76) {
/* 492 */         project_mutableStateArray_0[0].setNullAt(6);
/* 493 */       } else {
/* 494 */         project_mutableStateArray_0[0].write(6, project_value_76);
/* 495 */       }
/* 496 */       append((project_mutableStateArray_0[0].getRow()));
/* 497 */       if (shouldStop()) return;
/* 498 */     }
/* 499 */   }
/* 500 */
/* 501 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 029 */       UTF8String scan_value_0 = scan_isNull_0 ?
/* 030 */       null : (scan_row_0.getUTF8String(0));
/* 031 */       boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 032 */       UTF8String scan_value_2 = scan_isNull_2 ?
/* 033 */       null : (scan_row_0.getUTF8String(2));
/* 034 */       boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 035 */       UTF8String scan_value_3 = scan_isNull_3 ?
/* 036 */       null : (scan_row_0.getUTF8String(3));
/* 037 */
/* 038 */       boolean project_isNull_0 = true;
/* 039 */       UTF8String project_value_0 = null;
/* 040 */       boolean project_isNull_1 = true;
/* 041 */       ArrayData project_value_1 = null;
/* 042 */       Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[1] /* converters */)[0].apply(scan_value_0);
/* 043 */
/* 044 */       UTF8String project_result_0 = null;
/* 045 */       try {
/* 046 */         project_result_0 = (UTF8String)((scala.Function1[]) references[1] /* converters */)[1].apply(((scala.Function1) references[3] /* udf */).apply(project_arg_0));
/* 047 */       } catch (Exception e) {
/* 048 */         throw new org.apache.spark.SparkException(((java.lang.String) references[2] /* errMsg */), e);
/* 049 */       }
/* 050 */
/* 051 */       boolean project_isNull_2 = project_result_0 == null;
/* 052 */       UTF8String project_value_2 = null;
/* 053 */       if (!project_isNull_2) {
/* 054 */         project_value_2 = project_result_0;
/* 055 */       }
/* 056 */       if (!project_isNull_2) {
/* 057 */         project_isNull_1 = false; // resultCode could change nullability.
/* 058 */         project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[4] /* literal */), -1));
/* 059 */
/* 060 */       }
/* 061 */       if (!project_isNull_1) {
/* 062 */         project_isNull_0 = false; // resultCode could change nullability.
/* 063 */
/* 064 */         final int project_index_0 = (int) 0;
/* 065 */         if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 066 */           project_isNull_0 = true;
/* 067 */         } else {
/* 068 */           project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 069 */         }
/* 070 */
/* 071 */       }
/* 072 */       boolean project_isNull_6 = true;
/* 073 */       UTF8String project_value_6 = null;
/* 074 */       boolean project_isNull_7 = true;
/* 075 */       ArrayData project_value_7 = null;
/* 076 */       Object project_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 077 */
/* 078 */       UTF8String project_result_1 = null;
/* 079 */       try {
/* 080 */         project_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(project_arg_1));
/* 081 */       } catch (Exception e) {
/* 082 */         throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 083 */       }
/* 084 */
/* 085 */       boolean project_isNull_8 = project_result_1 == null;
/* 086 */       UTF8String project_value_8 = null;
/* 087 */       if (!project_isNull_8) {
/* 088 */         project_value_8 = project_result_1;
/* 089 */       }
/* 090 */       if (!project_isNull_8) {
/* 091 */         project_isNull_7 = false; // resultCode could change nullability.
/* 092 */         project_value_7 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_8.split(((UTF8String) references[8] /* literal */), -1));
/* 093 */
/* 094 */       }
/* 095 */       if (!project_isNull_7) {
/* 096 */         project_isNull_6 = false; // resultCode could change nullability.
/* 097 */
/* 098 */         final int project_index_1 = (int) 1;
/* 099 */         if (project_index_1 >= project_value_7.numElements() || project_index_1 < 0 || project_value_7.isNullAt(project_index_1)) {
/* 100 */           project_isNull_6 = true;
/* 101 */         } else {
/* 102 */           project_value_6 = project_value_7.getUTF8String(project_index_1);
/* 103 */         }
/* 104 */
/* 105 */       }
/* 106 */       boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 107 */       UTF8String scan_value_1 = scan_isNull_1 ?
/* 108 */       null : (scan_row_0.getUTF8String(1));
/* 109 */
/* 110 */       Object project_arg_2 = scan_isNull_1 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_1);
/* 111 */       Object project_arg_3 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[1].apply(scan_value_0);
/* 112 */
/* 113 */       UTF8String project_result_2 = null;
/* 114 */       try {
/* 115 */         project_result_2 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[2].apply(((scala.Function2) references[11] /* udf */).apply(project_arg_2, project_arg_3));
/* 116 */       } catch (Exception e) {
/* 117 */         throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 118 */       }
/* 119 */
/* 120 */       boolean project_isNull_12 = project_result_2 == null;
/* 121 */       UTF8String project_value_12 = null;
/* 122 */       if (!project_isNull_12) {
/* 123 */         project_value_12 = project_result_2;
/* 124 */       }
/* 125 */       boolean project_isNull_19 = true;
/* 126 */       UTF8String project_value_19 = null;
/* 127 */       boolean project_isNull_23 = scan_isNull_3;
/* 128 */       double project_value_23 = -1.0;
/* 129 */       if (!scan_isNull_3) {
/* 130 */         try {
/* 131 */           project_value_23 = Double.valueOf(scan_value_3.toString());
/* 132 */         } catch (java.lang.NumberFormatException e) {
/* 133 */           project_isNull_23 = true;
/* 134 */         }
/* 135 */       }
/* 136 */       boolean project_value_21 = true;
/* 137 */
/* 138 */       if (!project_isNull_23) {
/* 139 */         boolean project_isNull_26 = scan_isNull_2;
/* 140 */         double project_value_26 = -1.0;
/* 141 */         if (!scan_isNull_2) {
/* 142 */           try {
/* 143 */             project_value_26 = Double.valueOf(scan_value_2.toString());
/* 144 */           } catch (java.lang.NumberFormatException e) {
/* 145 */             project_isNull_26 = true;
/* 146 */           }
/* 147 */         }
/* 148 */         project_value_21 = project_isNull_26;
/* 149 */       }
/* 150 */       boolean project_isNull_20 = false;
/* 151 */       UTF8String project_value_20 = null;
/* 152 */       if (!false && project_value_21) {
/* 153 */         project_isNull_20 = true;
/* 154 */         project_value_20 = ((UTF8String)null);
/* 155 */       } else {
/* 156 */         boolean project_isNull_30 = scan_isNull_3;
/* 157 */         double project_value_30 = -1.0;
/* 158 */         if (!scan_isNull_3) {
/* 159 */           try {
/* 160 */             project_value_30 = Double.valueOf(scan_value_3.toString());
/* 161 */           } catch (java.lang.NumberFormatException e) {
/* 162 */             project_isNull_30 = true;
/* 163 */           }
/* 164 */         }
/* 165 */         boolean project_isNull_32 = scan_isNull_2;
/* 166 */         double project_value_32 = -1.0;
/* 167 */         if (!scan_isNull_2) {
/* 168 */           try {
/* 169 */             project_value_32 = Double.valueOf(scan_value_2.toString());
/* 170 */           } catch (java.lang.NumberFormatException e) {
/* 171 */             project_isNull_32 = true;
/* 172 */           }
/* 173 */         }
/* 174 */         Object project_arg_4 = project_isNull_30 ? null : ((scala.Function1[]) references[12] /* converters */)[0].apply(project_value_30);
/* 175 */         Object project_arg_5 = project_isNull_32 ? null : ((scala.Function1[]) references[12] /* converters */)[1].apply(project_value_32);
/* 176 */
/* 177 */         UTF8String project_result_3 = null;
/* 178 */         try {
/* 179 */           project_result_3 = (UTF8String)((scala.Function1[]) references[12] /* converters */)[2].apply(((scala.Function2) references[14] /* udf */).apply(project_arg_4, project_arg_5));
/* 180 */         } catch (Exception e) {
/* 181 */           throw new org.apache.spark.SparkException(((java.lang.String) references[13] /* errMsg */), e);
/* 182 */         }
/* 183 */
/* 184 */         boolean project_isNull_29 = project_result_3 == null;
/* 185 */         UTF8String project_value_29 = null;
/* 186 */         if (!project_isNull_29) {
/* 187 */           project_value_29 = project_result_3;
/* 188 */         }
/* 189 */         project_isNull_20 = project_isNull_29;
/* 190 */         project_value_20 = project_value_29;
/* 191 */       }
/* 192 */       if (!project_isNull_20) {
/* 193 */         project_isNull_19 = false; // resultCode could change nullability.
/* 194 */         project_value_19 = project_value_20.replace(((UTF8String) references[15] /* literal */), ((UTF8String) references[16] /* literal */));
/* 195 */
/* 196 */       }
/* 197 */       boolean project_isNull_18 = project_isNull_19;
/* 198 */       double project_value_18 = -1.0;
/* 199 */       if (!project_isNull_19) {
/* 200 */         try {
/* 201 */           project_value_18 = Double.valueOf(project_value_19.toString());
/* 202 */         } catch (java.lang.NumberFormatException e) {
/* 203 */           project_isNull_18 = true;
/* 204 */         }
/* 205 */       }
/* 206 */       boolean project_value_16 = true;
/* 207 */
/* 208 */       if (!project_isNull_18) {
/* 209 */         UTF8String project_result_4 = null;
/* 210 */         try {
/* 211 */           project_result_4 = (UTF8String)((scala.Function1[]) references[17] /* converters */)[0].apply(((scala.Function0) references[19] /* udf */).apply());
/* 212 */         } catch (Exception e) {
/* 213 */           throw new org.apache.spark.SparkException(((java.lang.String) references[18] /* errMsg */), e);
/* 214 */         }
/* 215 */
/* 216 */         boolean project_isNull_38 = project_result_4 == null;
/* 217 */         UTF8String project_value_38 = null;
/* 218 */         if (!project_isNull_38) {
/* 219 */           project_value_38 = project_result_4;
/* 220 */         }
/* 221 */         boolean project_isNull_37 = project_isNull_38;
/* 222 */         int project_value_37 = -1;
/* 223 */         if (!project_isNull_38) {
/* 224 */           UTF8String.IntWrapper project_intWrapper_0 = new UTF8String.IntWrapper();
/* 225 */           if (project_value_38.toInt(project_intWrapper_0)) {
/* 226 */             project_value_37 = project_intWrapper_0.value;
/* 227 */           } else {
/* 228 */             project_isNull_37 = true;
/* 229 */           }
/* 230 */           project_intWrapper_0 = null;
/* 231 */         }
/* 232 */         project_value_16 = project_isNull_37;
/* 233 */       }
/* 234 */       boolean project_isNull_15 = false;
/* 235 */       UTF8String project_value_15 = null;
/* 236 */       if (!false && project_value_16) {
/* 237 */         project_isNull_15 = true;
/* 238 */         project_value_15 = ((UTF8String)null);
/* 239 */       } else {
/* 240 */         boolean project_isNull_42 = true;
/* 241 */         UTF8String project_value_42 = null;
/* 242 */         boolean project_isNull_46 = scan_isNull_3;
/* 243 */         double project_value_46 = -1.0;
/* 244 */         if (!scan_isNull_3) {
/* 245 */           try {
/* 246 */             project_value_46 = Double.valueOf(scan_value_3.toString());
/* 247 */           } catch (java.lang.NumberFormatException e) {
/* 248 */             project_isNull_46 = true;
/* 249 */           }
/* 250 */         }
/* 251 */         boolean project_value_44 = true;
/* 252 */
/* 253 */         if (!project_isNull_46) {
/* 254 */           boolean project_isNull_49 = scan_isNull_2;
/* 255 */           double project_value_49 = -1.0;
/* 256 */           if (!scan_isNull_2) {
/* 257 */             try {
/* 258 */               project_value_49 = Double.valueOf(scan_value_2.toString());
/* 259 */             } catch (java.lang.NumberFormatException e) {
/* 260 */               project_isNull_49 = true;
/* 261 */             }
/* 262 */           }
/* 263 */           project_value_44 = project_isNull_49;
/* 264 */         }
/* 265 */         boolean project_isNull_43 = false;
/* 266 */         UTF8String project_value_43 = null;
/* 267 */         if (!false && project_value_44) {
/* 268 */           project_isNull_43 = true;
/* 269 */           project_value_43 = ((UTF8String)null);
/* 270 */         } else {
/* 271 */           boolean project_isNull_53 = scan_isNull_3;
/* 272 */           double project_value_53 = -1.0;
/* 273 */           if (!scan_isNull_3) {
/* 274 */             try {
/* 275 */               project_value_53 = Double.valueOf(scan_value_3.toString());
/* 276 */             } catch (java.lang.NumberFormatException e) {
/* 277 */               project_isNull_53 = true;
/* 278 */             }
/* 279 */           }
/* 280 */           boolean project_isNull_55 = scan_isNull_2;
/* 281 */           double project_value_55 = -1.0;
/* 282 */           if (!scan_isNull_2) {
/* 283 */             try {
/* 284 */               project_value_55 = Double.valueOf(scan_value_2.toString());
/* 285 */             } catch (java.lang.NumberFormatException e) {
/* 286 */               project_isNull_55 = true;
/* 287 */             }
/* 288 */           }
/* 289 */           Object project_arg_6 = project_isNull_53 ? null : ((scala.Function1[]) references[22] /* converters */)[0].apply(project_value_53);
/* 290 */           Object project_arg_7 = project_isNull_55 ? null : ((scala.Function1[]) references[22] /* converters */)[1].apply(project_value_55);
/* 291 */
/* 292 */           UTF8String project_result_6 = null;
/* 293 */           try {
/* 294 */             project_result_6 = (UTF8String)((scala.Function1[]) references[22] /* converters */)[2].apply(((scala.Function2) references[24] /* udf */).apply(project_arg_6, project_arg_7));
/* 295 */           } catch (Exception e) {
/* 296 */             throw new org.apache.spark.SparkException(((java.lang.String) references[23] /* errMsg */), e);
/* 297 */           }
/* 298 */
/* 299 */           boolean project_isNull_52 = project_result_6 == null;
/* 300 */           UTF8String project_value_52 = null;
/* 301 */           if (!project_isNull_52) {
/* 302 */             project_value_52 = project_result_6;
/* 303 */           }
/* 304 */           project_isNull_43 = project_isNull_52;
/* 305 */           project_value_43 = project_value_52;
/* 306 */         }
/* 307 */         if (!project_isNull_43) {
/* 308 */           project_isNull_42 = false; // resultCode could change nullability.
/* 309 */           project_value_42 = project_value_43.replace(((UTF8String) references[25] /* literal */), ((UTF8String) references[26] /* literal */));
/* 310 */
/* 311 */         }
/* 312 */         boolean project_isNull_41 = project_isNull_42;
/* 313 */         double project_value_41 = -1.0;
/* 314 */         if (!project_isNull_42) {
/* 315 */           try {
/* 316 */             project_value_41 = Double.valueOf(project_value_42.toString());
/* 317 */           } catch (java.lang.NumberFormatException e) {
/* 318 */             project_isNull_41 = true;
/* 319 */           }
/* 320 */         }
/* 321 */         UTF8String project_result_7 = null;
/* 322 */         try {
/* 323 */           project_result_7 = (UTF8String)((scala.Function1[]) references[27] /* converters */)[0].apply(((scala.Function0) references[29] /* udf */).apply());
/* 324 */         } catch (Exception e) {
/* 325 */           throw new org.apache.spark.SparkException(((java.lang.String) references[28] /* errMsg */), e);
/* 326 */         }
/* 327 */
/* 328 */         boolean project_isNull_60 = project_result_7 == null;
/* 329 */         UTF8String project_value_60 = null;
/* 330 */         if (!project_isNull_60) {
/* 331 */           project_value_60 = project_result_7;
/* 332 */         }
/* 333 */         boolean project_isNull_59 = project_isNull_60;
/* 334 */         int project_value_59 = -1;
/* 335 */         if (!project_isNull_60) {
/* 336 */           UTF8String.IntWrapper project_intWrapper_1 = new UTF8String.IntWrapper();
/* 337 */           if (project_value_60.toInt(project_intWrapper_1)) {
/* 338 */             project_value_59 = project_intWrapper_1.value;
/* 339 */           } else {
/* 340 */             project_isNull_59 = true;
/* 341 */           }
/* 342 */           project_intWrapper_1 = null;
/* 343 */         }
/* 344 */         Object project_arg_8 = project_isNull_41 ? null : ((scala.Function1[]) references[20] /* converters */)[0].apply(project_value_41);
/* 345 */         Object project_arg_9 = project_isNull_59 ? null : ((scala.Function1[]) references[20] /* converters */)[1].apply(project_value_59);
/* 346 */
/* 347 */         UTF8String project_result_5 = null;
/* 348 */         try {
/* 349 */           project_result_5 = (UTF8String)((scala.Function1[]) references[20] /* converters */)[2].apply(((scala.Function2) references[30] /* udf */).apply(project_arg_8, project_arg_9));
/* 350 */         } catch (Exception e) {
/* 351 */           throw new org.apache.spark.SparkException(((java.lang.String) references[21] /* errMsg */), e);
/* 352 */         }
/* 353 */
/* 354 */         boolean project_isNull_40 = project_result_5 == null;
/* 355 */         UTF8String project_value_40 = null;
/* 356 */         if (!project_isNull_40) {
/* 357 */           project_value_40 = project_result_5;
/* 358 */         }
/* 359 */         project_isNull_15 = project_isNull_40;
/* 360 */         project_value_15 = project_value_40;
/* 361 */       }
/* 362 */       boolean project_isNull_64 = scan_isNull_3;
/* 363 */       double project_value_64 = -1.0;
/* 364 */       if (!scan_isNull_3) {
/* 365 */         try {
/* 366 */           project_value_64 = Double.valueOf(scan_value_3.toString());
/* 367 */         } catch (java.lang.NumberFormatException e) {
/* 368 */           project_isNull_64 = true;
/* 369 */         }
/* 370 */       }
/* 371 */       boolean project_value_62 = true;
/* 372 */
/* 373 */       if (!project_isNull_64) {
/* 374 */         boolean project_isNull_67 = scan_isNull_2;
/* 375 */         double project_value_67 = -1.0;
/* 376 */         if (!scan_isNull_2) {
/* 377 */           try {
/* 378 */             project_value_67 = Double.valueOf(scan_value_2.toString());
/* 379 */           } catch (java.lang.NumberFormatException e) {
/* 380 */             project_isNull_67 = true;
/* 381 */           }
/* 382 */         }
/* 383 */         project_value_62 = project_isNull_67;
/* 384 */       }
/* 385 */       boolean project_isNull_61 = false;
/* 386 */       UTF8String project_value_61 = null;
/* 387 */       if (!false && project_value_62) {
/* 388 */         project_isNull_61 = true;
/* 389 */         project_value_61 = ((UTF8String)null);
/* 390 */       } else {
/* 391 */         boolean project_isNull_71 = scan_isNull_3;
/* 392 */         double project_value_71 = -1.0;
/* 393 */         if (!scan_isNull_3) {
/* 394 */           try {
/* 395 */             project_value_71 = Double.valueOf(scan_value_3.toString());
/* 396 */           } catch (java.lang.NumberFormatException e) {
/* 397 */             project_isNull_71 = true;
/* 398 */           }
/* 399 */         }
/* 400 */         boolean project_isNull_73 = scan_isNull_2;
/* 401 */         double project_value_73 = -1.0;
/* 402 */         if (!scan_isNull_2) {
/* 403 */           try {
/* 404 */             project_value_73 = Double.valueOf(scan_value_2.toString());
/* 405 */           } catch (java.lang.NumberFormatException e) {
/* 406 */             project_isNull_73 = true;
/* 407 */           }
/* 408 */         }
/* 409 */         Object project_arg_10 = project_isNull_71 ? null : ((scala.Function1[]) references[31] /* converters */)[0].apply(project_value_71);
/* 410 */         Object project_arg_11 = project_isNull_73 ? null : ((scala.Function1[]) references[31] /* converters */)[1].apply(project_value_73);
/* 411 */
/* 412 */         UTF8String project_result_8 = null;
/* 413 */         try {
/* 414 */           project_result_8 = (UTF8String)((scala.Function1[]) references[31] /* converters */)[2].apply(((scala.Function2) references[33] /* udf */).apply(project_arg_10, project_arg_11));
/* 415 */         } catch (Exception e) {
/* 416 */           throw new org.apache.spark.SparkException(((java.lang.String) references[32] /* errMsg */), e);
/* 417 */         }
/* 418 */
/* 419 */         boolean project_isNull_70 = project_result_8 == null;
/* 420 */         UTF8String project_value_70 = null;
/* 421 */         if (!project_isNull_70) {
/* 422 */           project_value_70 = project_result_8;
/* 423 */         }
/* 424 */         project_isNull_61 = project_isNull_70;
/* 425 */         project_value_61 = project_value_70;
/* 426 */       }
/* 427 */       UTF8String project_result_9 = null;
/* 428 */       try {
/* 429 */         project_result_9 = (UTF8String)((scala.Function1[]) references[34] /* converters */)[0].apply(((scala.Function0) references[36] /* udf */).apply());
/* 430 */       } catch (Exception e) {
/* 431 */         throw new org.apache.spark.SparkException(((java.lang.String) references[35] /* errMsg */), e);
/* 432 */       }
/* 433 */
/* 434 */       boolean project_isNull_75 = project_result_9 == null;
/* 435 */       UTF8String project_value_75 = null;
/* 436 */       if (!project_isNull_75) {
/* 437 */         project_value_75 = project_result_9;
/* 438 */       }
/* 439 */       UTF8String project_result_10 = null;
/* 440 */       try {
/* 441 */         project_result_10 = (UTF8String)((scala.Function1[]) references[37] /* converters */)[0].apply(((scala.Function0) references[39] /* udf */).apply());
/* 442 */       } catch (Exception e) {
/* 443 */         throw new org.apache.spark.SparkException(((java.lang.String) references[38] /* errMsg */), e);
/* 444 */       }
/* 445 */
/* 446 */       boolean project_isNull_76 = project_result_10 == null;
/* 447 */       UTF8String project_value_76 = null;
/* 448 */       if (!project_isNull_76) {
/* 449 */         project_value_76 = project_result_10;
/* 450 */       }
/* 451 */       project_mutableStateArray_0[0].reset();
/* 452 */
/* 453 */       project_mutableStateArray_0[0].zeroOutNullBytes();
/* 454 */
/* 455 */       if (project_isNull_0) {
/* 456 */         project_mutableStateArray_0[0].setNullAt(0);
/* 457 */       } else {
/* 458 */         project_mutableStateArray_0[0].write(0, project_value_0);
/* 459 */       }
/* 460 */
/* 461 */       if (project_isNull_6) {
/* 462 */         project_mutableStateArray_0[0].setNullAt(1);
/* 463 */       } else {
/* 464 */         project_mutableStateArray_0[0].write(1, project_value_6);
/* 465 */       }
/* 466 */
/* 467 */       if (project_isNull_12) {
/* 468 */         project_mutableStateArray_0[0].setNullAt(2);
/* 469 */       } else {
/* 470 */         project_mutableStateArray_0[0].write(2, project_value_12);
/* 471 */       }
/* 472 */
/* 473 */       if (project_isNull_15) {
/* 474 */         project_mutableStateArray_0[0].setNullAt(3);
/* 475 */       } else {
/* 476 */         project_mutableStateArray_0[0].write(3, project_value_15);
/* 477 */       }
/* 478 */
/* 479 */       if (project_isNull_61) {
/* 480 */         project_mutableStateArray_0[0].setNullAt(4);
/* 481 */       } else {
/* 482 */         project_mutableStateArray_0[0].write(4, project_value_61);
/* 483 */       }
/* 484 */
/* 485 */       if (project_isNull_75) {
/* 486 */         project_mutableStateArray_0[0].setNullAt(5);
/* 487 */       } else {
/* 488 */         project_mutableStateArray_0[0].write(5, project_value_75);
/* 489 */       }
/* 490 */
/* 491 */       if (project_isNull_76) {
/* 492 */         project_mutableStateArray_0[0].setNullAt(6);
/* 493 */       } else {
/* 494 */         project_mutableStateArray_0[0].write(6, project_value_76);
/* 495 */       }
/* 496 */       append((project_mutableStateArray_0[0].getRow()));
/* 497 */       if (shouldStop()) return;
/* 498 */     }
/* 499 */   }
/* 500 */
/* 501 */ }

Code generated in 167.972674 ms
Block broadcast_3 stored as values in memory (estimated size 242.9 KB, free 1987.3 MB)
Put block broadcast_3 locally took  24 ms
Putting block broadcast_3 without replication took  24 ms
Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.2 MB)
Added broadcast_3_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_3_piece0
Told master about block broadcast_3_piece0
Put block broadcast_3_piece0 locally took  1 ms
Putting block broadcast_3_piece0 without replication took  2 ms
Created broadcast 3 from show at Run.scala:50
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$1
 +++ Lambda closure ($anonfun$executeTake$1) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$2
 +++ Lambda closure ($anonfun$executeTake$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: show at Run.scala:50
Got job 1 (show at Run.scala:50) with 1 output partitions
Final stage: ResultStage 1 (show at Run.scala:50)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 1)
missing: List()
Submitting ResultStage 1 (MapPartitionsRDD[12] at show at Run.scala:50), which has no missing parents
submitMissingTasks(ResultStage 1)
Block broadcast_4 stored as values in memory (estimated size 32.0 KB, free 1987.2 MB)
Put block broadcast_4 locally took  1 ms
Putting block broadcast_4 without replication took  1 ms
Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.0 KB, free 1987.2 MB)
Added broadcast_4_piece0 in memory on 192.168.1.13:10964 (size: 12.0 KB, free: 1987.5 MB)
Updated info of block broadcast_4_piece0
Told master about block broadcast_4_piece0
Put block broadcast_4_piece0 locally took  1 ms
Putting block broadcast_4_piece0 without replication took  1 ms
Created broadcast 4 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at show at Run.scala:50) (first 15 tasks are for partitions Vector(0))
Adding task set 1.0 with 1 tasks
Epoch for TaskSet 1.0: 0
Valid locality levels for TaskSet 1.0: NO_PREF, ANY
parentName: , name: TaskSet_1.0, runningTasks: 0
Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 1.0 (TID 1)
Getting local block broadcast_4
Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Code generated in 11.971946 ms
Getting local block broadcast_3
Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 0.0 in stage 1.0 (TID 1). 2061 bytes result sent to driver
parentName: , name: TaskSet_1.0, runningTasks: 0
Finished task 0.0 in stage 1.0 (TID 1) in 141 ms on localhost (executor driver) (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
ResultStage 1 (show at Run.scala:50) finished in 0.167 s
After removal of stage 1, remaining stages = 0
Job 1 finished: show at Run.scala:50, took 0.170935 s
Writing CSV files at src/main/resources/emulatedData with saveMode=Overwrite

=== Result of Batch Finish Analysis ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]                                                                                                                                InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                        +- Repartition 1, true
    +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]      +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!      +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                     +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!         +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]                                                                                                                                InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/emulatedData, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/emulatedData), Overwrite, [location, position, local_time, conditions, temperature, pressure, humidity]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                        +- Repartition 1, true
!   +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]      +- Project [split(UDF(location#10), [|])[0] AS location#20, split(UDF(location#10), [|])[1] AS position#21, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double)) || isnull(cast(UDF() as int)))) null else UDF(cast(replace(if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)), +, ) as double), cast(UDF() as int)) AS conditions#23, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24, UDF() AS pressure#25, UDF() AS humidity#26]
!      +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                 +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                           
          
Pruning directories with: 
Post-Scan Filters: 
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 
Creating committer org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol; job 13c0f4ee-2f07-496b-99a7-87addf2802aa; output=file:/D:/p1/weather-simulator/src/main/resources/emulatedData; dynamic=false
Using (String, String, Boolean) constructor
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Got cleaning task CleanAccum(51)
Cleaning accumulator 51
Cleaned accumulator 51
Got cleaning task CleanAccum(54)
Cleaning accumulator 54
Cleaned accumulator 54
Got cleaning task CleanAccum(59)
Cleaning accumulator 59
Cleaned accumulator 59
Got cleaning task CleanAccum(55)
Cleaning accumulator 55
Cleaned accumulator 55
Got cleaning task CleanAccum(37)
Cleaning accumulator 37
Cleaned accumulator 37
Got cleaning task CleanAccum(40)

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 029 */       UTF8String scan_value_0 = scan_isNull_0 ?
/* 030 */       null : (scan_row_0.getUTF8String(0));
/* 031 */       boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 032 */       UTF8String scan_value_2 = scan_isNull_2 ?
/* 033 */       null : (scan_row_0.getUTF8String(2));
/* 034 */       boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 035 */       UTF8String scan_value_3 = scan_isNull_3 ?
/* 036 */       null : (scan_row_0.getUTF8String(3));
/* 037 */
/* 038 */       boolean project_isNull_0 = true;
/* 039 */       UTF8String project_value_0 = null;
/* 040 */       boolean project_isNull_1 = true;
/* 041 */       ArrayData project_value_1 = null;
/* 042 */       Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[1] /* converters */)[0].apply(scan_value_0);
/* 043 */
/* 044 */       UTF8String project_result_0 = null;
/* 045 */       try {
/* 046 */         project_result_0 = (UTF8String)((scala.Function1[]) references[1] /* converters */)[1].apply(((scala.Function1) references[3] /* udf */).apply(project_arg_0));
/* 047 */       } catch (Exception e) {
/* 048 */         throw new org.apache.spark.SparkException(((java.lang.String) references[2] /* errMsg */), e);
/* 049 */       }
/* 050 */
/* 051 */       boolean project_isNull_2 = project_result_0 == null;
/* 052 */       UTF8String project_value_2 = null;
/* 053 */       if (!project_isNull_2) {
/* 054 */         project_value_2 = project_result_0;
/* 055 */       }
/* 056 */       if (!project_isNull_2) {
/* 057 */         project_isNull_1 = false; // resultCode could change nullability.
/* 058 */         project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[4] /* literal */), -1));
/* 059 */
/* 060 */       }
/* 061 */       if (!project_isNull_1) {
/* 062 */         project_isNull_0 = false; // resultCode could change nullability.
/* 063 */
/* 064 */         final int project_index_0 = (int) 0;
/* 065 */         if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 066 */           project_isNull_0 = true;
/* 067 */         } else {
/* 068 */           project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 069 */         }
/* 070 */
/* 071 */       }
/* 072 */       boolean project_isNull_6 = true;
/* 073 */       UTF8String project_value_6 = null;
/* 074 */       boolean project_isNull_7 = true;
/* 075 */       ArrayData project_value_7 = null;
/* 076 */       Object project_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 077 */
/* 078 */       UTF8String project_result_1 = null;
/* 079 */       try {
/* 080 */         project_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(project_arg_1));
/* 081 */       } catch (Exception e) {
/* 082 */         throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 083 */       }
/* 084 */
/* 085 */       boolean project_isNull_8 = project_result_1 == null;
/* 086 */       UTF8String project_value_8 = null;
/* 087 */       if (!project_isNull_8) {
/* 088 */         project_value_8 = project_result_1;
/* 089 */       }
/* 090 */       if (!project_isNull_8) {
/* 091 */         project_isNull_7 = false; // resultCode could change nullability.
/* 092 */         project_value_7 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_8.split(((UTF8String) references[8] /* literal */), -1));
/* 093 */
/* 094 */       }
/* 095 */       if (!project_isNull_7) {
/* 096 */         project_isNull_6 = false; // resultCode could change nullability.
/* 097 */
/* 098 */         final int project_index_1 = (int) 1;
/* 099 */         if (project_index_1 >= project_value_7.numElements() || project_index_1 < 0 || project_value_7.isNullAt(project_index_1)) {
/* 100 */           project_isNull_6 = true;
/* 101 */         } else {
/* 102 */           project_value_6 = project_value_7.getUTF8String(project_index_1);
/* 103 */         }
/* 104 */
/* 105 */       }
/* 106 */       boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 107 */       UTF8String scan_value_1 = scan_isNull_1 ?
/* 108 */       null : (scan_row_0.getUTF8String(1));
/* 109 */
/* 110 */       Object project_arg_2 = scan_isNull_1 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_1);
/* 111 */       Object project_arg_3 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[1].apply(scan_value_0);
/* 112 */
/* 113 */       UTF8String project_result_2 = null;
/* 114 */       try {
/* 115 */         project_result_2 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[2].apply(((scala.Function2) references[11] /* udf */).apply(project_arg_2, project_arg_3));
/* 116 */       } catch (Exception e) {
/* 117 */         throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 118 */       }
/* 119 */
/* 120 */       boolean project_isNull_12 = project_result_2 == null;
/* 121 */       UTF8String project_value_12 = null;
/* 122 */       if (!project_isNull_12) {
/* 123 */         project_value_12 = project_result_2;
/* 124 */       }
/* 125 */       boolean project_isNull_19 = true;
/* 126 */       UTF8String project_value_19 = null;
/* 127 */       boolean project_isNull_23 = scan_isNull_3;
/* 128 */       double project_value_23 = -1.0;
/* 129 */       if (!scan_isNull_3) {
/* 130 */         try {
/* 131 */           project_value_23 = Double.valueOf(scan_value_3.toString());
/* 132 */         } catch (java.lang.NumberFormatException e) {
/* 133 */           project_isNull_23 = true;
/* 134 */         }
/* 135 */       }
/* 136 */       boolean project_value_21 = true;
/* 137 */
/* 138 */       if (!project_isNull_23) {
/* 139 */         boolean project_isNull_26 = scan_isNull_2;
/* 140 */         double project_value_26 = -1.0;
/* 141 */         if (!scan_isNull_2) {
/* 142 */           try {
/* 143 */             project_value_26 = Double.valueOf(scan_value_2.toString());
/* 144 */           } catch (java.lang.NumberFormatException e) {
/* 145 */             project_isNull_26 = true;
/* 146 */           }
/* 147 */         }
/* 148 */         project_value_21 = project_isNull_26;
/* 149 */       }
/* 150 */       boolean project_isNull_20 = false;
/* 151 */       UTF8String project_value_20 = null;
/* 152 */       if (!false && project_value_21) {
/* 153 */         project_isNull_20 = true;
/* 154 */         project_value_20 = ((UTF8String)null);
/* 155 */       } else {
/* 156 */         boolean project_isNull_30 = scan_isNull_3;
/* 157 */         double project_value_30 = -1.0;
/* 158 */         if (!scan_isNull_3) {
/* 159 */           try {
/* 160 */             project_value_30 = Double.valueOf(scan_value_3.toString());
/* 161 */           } catch (java.lang.NumberFormatException e) {
/* 162 */             project_isNull_30 = true;
/* 163 */           }
/* 164 */         }
/* 165 */         boolean project_isNull_32 = scan_isNull_2;
/* 166 */         double project_value_32 = -1.0;
/* 167 */         if (!scan_isNull_2) {
/* 168 */           try {
/* 169 */             project_value_32 = Double.valueOf(scan_value_2.toString());
/* 170 */           } catch (java.lang.NumberFormatException e) {
/* 171 */             project_isNull_32 = true;
/* 172 */           }
/* 173 */         }
/* 174 */         Object project_arg_4 = project_isNull_30 ? null : ((scala.Function1[]) references[12] /* converters */)[0].apply(project_value_30);
/* 175 */         Object project_arg_5 = project_isNull_32 ? null : ((scala.Function1[]) references[12] /* converters */)[1].apply(project_value_32);
/* 176 */
/* 177 */         UTF8String project_result_3 = null;
/* 178 */         try {
/* 179 */           project_result_3 = (UTF8String)((scala.Function1[]) references[12] /* converters */)[2].apply(((scala.Function2) references[14] /* udf */).apply(project_arg_4, project_arg_5));
/* 180 */         } catch (Exception e) {
/* 181 */           throw new org.apache.spark.SparkException(((java.lang.String) references[13] /* errMsg */), e);
/* 182 */         }
/* 183 */
/* 184 */         boolean project_isNull_29 = project_result_3 == null;
/* 185 */         UTF8String project_value_29 = null;
/* 186 */         if (!project_isNull_29) {
/* 187 */           project_value_29 = project_result_3;
/* 188 */         }
/* 189 */         project_isNull_20 = project_isNull_29;
/* 190 */         project_value_20 = project_value_29;
/* 191 */       }
/* 192 */       if (!project_isNull_20) {
/* 193 */         project_isNull_19 = false; // resultCode could change nullability.
/* 194 */         project_value_19 = project_value_20.replace(((UTF8String) references[15] /* literal */), ((UTF8String) references[16] /* literal */));
/* 195 */
/* 196 */       }
/* 197 */       boolean project_isNull_18 = project_isNull_19;
/* 198 */       double project_value_18 = -1.0;
/* 199 */       if (!project_isNull_19) {
/* 200 */         try {
/* 201 */           project_value_18 = Double.valueOf(project_value_19.toString());
/* 202 */         } catch (java.lang.NumberFormatException e) {
/* 203 */           project_isNull_18 = true;
/* 204 */         }
/* 205 */       }
/* 206 */       boolean project_value_16 = true;
/* 207 */
/* 208 */       if (!project_isNull_18) {
/* 209 */         UTF8String project_result_4 = null;
/* 210 */         try {
/* 211 */           project_result_4 = (UTF8String)((scala.Function1[]) references[17] /* converters */)[0].apply(((scala.Function0) references[19] /* udf */).apply());
/* 212 */         } catch (Exception e) {
/* 213 */           throw new org.apache.spark.SparkException(((java.lang.String) references[18] /* errMsg */), e);
/* 214 */         }
/* 215 */
/* 216 */         boolean project_isNull_38 = project_result_4 == null;
/* 217 */         UTF8String project_value_38 = null;
/* 218 */         if (!project_isNull_38) {
/* 219 */           project_value_38 = project_result_4;
/* 220 */         }
/* 221 */         boolean project_isNull_37 = project_isNull_38;
/* 222 */         int project_value_37 = -1;
/* 223 */         if (!project_isNull_38) {
/* 224 */           UTF8String.IntWrapper project_intWrapper_0 = new UTF8String.IntWrapper();
/* 225 */           if (project_value_38.toInt(project_intWrapper_0)) {
/* 226 */             project_value_37 = project_intWrapper_0.value;
/* 227 */           } else {
/* 228 */             project_isNull_37 = true;
/* 229 */           }
/* 230 */           project_intWrapper_0 = null;
/* 231 */         }
/* 232 */         project_value_16 = project_isNull_37;
/* 233 */       }
/* 234 */       boolean project_isNull_15 = false;
/* 235 */       UTF8String project_value_15 = null;
/* 236 */       if (!false && project_value_16) {
/* 237 */         project_isNull_15 = true;
/* 238 */         project_value_15 = ((UTF8String)null);
/* 239 */       } else {
/* 240 */         boolean project_isNull_42 = true;
/* 241 */         UTF8String project_value_42 = null;
/* 242 */         boolean project_isNull_46 = scan_isNull_3;
/* 243 */         double project_value_46 = -1.0;
/* 244 */         if (!scan_isNull_3) {
/* 245 */           try {
/* 246 */             project_value_46 = Double.valueOf(scan_value_3.toString());
/* 247 */           } catch (java.lang.NumberFormatException e) {
/* 248 */             project_isNull_46 = true;
/* 249 */           }
/* 250 */         }
/* 251 */         boolean project_value_44 = true;
/* 252 */
/* 253 */         if (!project_isNull_46) {
/* 254 */           boolean project_isNull_49 = scan_isNull_2;
/* 255 */           double project_value_49 = -1.0;
/* 256 */           if (!scan_isNull_2) {
/* 257 */             try {
/* 258 */               project_value_49 = Double.valueOf(scan_value_2.toString());
/* 259 */             } catch (java.lang.NumberFormatException e) {
/* 260 */               project_isNull_49 = true;
/* 261 */             }
/* 262 */           }
/* 263 */           project_value_44 = project_isNull_49;
/* 264 */         }
/* 265 */         boolean project_isNull_43 = false;
/* 266 */         UTF8String project_value_43 = null;
/* 267 */         if (!false && project_value_44) {
/* 268 */           project_isNull_43 = true;
/* 269 */           project_value_43 = ((UTF8String)null);
/* 270 */         } else {
/* 271 */           boolean project_isNull_53 = scan_isNull_3;
/* 272 */           double project_value_53 = -1.0;
/* 273 */           if (!scan_isNull_3) {
/* 274 */             try {
/* 275 */               project_value_53 = Double.valueOf(scan_value_3.toString());
/* 276 */             } catch (java.lang.NumberFormatException e) {
/* 277 */               project_isNull_53 = true;
/* 278 */             }
/* 279 */           }
/* 280 */           boolean project_isNull_55 = scan_isNull_2;
/* 281 */           double project_value_55 = -1.0;
/* 282 */           if (!scan_isNull_2) {
/* 283 */             try {
/* 284 */               project_value_55 = Double.valueOf(scan_value_2.toString());
/* 285 */             } catch (java.lang.NumberFormatException e) {
/* 286 */               project_isNull_55 = true;
/* 287 */             }
/* 288 */           }
/* 289 */           Object project_arg_6 = project_isNull_53 ? null : ((scala.Function1[]) references[22] /* converters */)[0].apply(project_value_53);
/* 290 */           Object project_arg_7 = project_isNull_55 ? null : ((scala.Function1[]) references[22] /* converters */)[1].apply(project_value_55);
/* 291 */
/* 292 */           UTF8String project_result_6 = null;
/* 293 */           try {
/* 294 */             project_result_6 = (UTF8String)((scala.Function1[]) references[22] /* converters */)[2].apply(((scala.Function2) references[24] /* udf */).apply(project_arg_6, project_arg_7));
/* 295 */           } catch (Exception e) {
/* 296 */             throw new org.apache.spark.SparkException(((java.lang.String) references[23] /* errMsg */), e);
/* 297 */           }
/* 298 */
/* 299 */           boolean project_isNull_52 = project_result_6 == null;
/* 300 */           UTF8String project_value_52 = null;
/* 301 */           if (!project_isNull_52) {
/* 302 */             project_value_52 = project_result_6;
/* 303 */           }
/* 304 */           project_isNull_43 = project_isNull_52;
/* 305 */           project_value_43 = project_value_52;
/* 306 */         }
/* 307 */         if (!project_isNull_43) {
/* 308 */           project_isNull_42 = false; // resultCode could change nullability.
/* 309 */           project_value_42 = project_value_43.replace(((UTF8String) references[25] /* literal */), ((UTF8String) references[26] /* literal */));
/* 310 */
/* 311 */         }
/* 312 */         boolean project_isNull_41 = project_isNull_42;
/* 313 */         double project_value_41 = -1.0;
/* 314 */         if (!project_isNull_42) {
/* 315 */           try {
/* 316 */             project_value_41 = Double.valueOf(project_value_42.toString());
/* 317 */           } catch (java.lang.NumberFormatException e) {
/* 318 */             project_isNull_41 = true;
/* 319 */           }
/* 320 */         }
/* 321 */         UTF8String project_result_7 = null;
/* 322 */         try {
/* 323 */           project_result_7 = (UTF8String)((scala.Function1[]) references[27] /* converters */)[0].apply(((scala.Function0) references[29] /* udf */).apply());
/* 324 */         } catch (Exception e) {
/* 325 */           throw new org.apache.spark.SparkException(((java.lang.String) references[28] /* errMsg */), e);
/* 326 */         }
/* 327 */
/* 328 */         boolean project_isNull_60 = project_result_7 == null;
/* 329 */         UTF8String project_value_60 = null;
/* 330 */         if (!project_isNull_60) {
/* 331 */           project_value_60 = project_result_7;
/* 332 */         }
/* 333 */         boolean project_isNull_59 = project_isNull_60;
/* 334 */         int project_value_59 = -1;
/* 335 */         if (!project_isNull_60) {
/* 336 */           UTF8String.IntWrapper project_intWrapper_1 = new UTF8String.IntWrapper();
/* 337 */           if (project_value_60.toInt(project_intWrapper_1)) {
/* 338 */             project_value_59 = project_intWrapper_1.value;
/* 339 */           } else {
/* 340 */             project_isNull_59 = true;
/* 341 */           }
/* 342 */           project_intWrapper_1 = null;
/* 343 */         }
/* 344 */         Object project_arg_8 = project_isNull_41 ? null : ((scala.Function1[]) references[20] /* converters */)[0].apply(project_value_41);
/* 345 */         Object project_arg_9 = project_isNull_59 ? null : ((scala.Function1[]) references[20] /* converters */)[1].apply(project_value_59);
/* 346 */
/* 347 */         UTF8String project_result_5 = null;
/* 348 */         try {
/* 349 */           project_result_5 = (UTF8String)((scala.Function1[]) references[20] /* converters */)[2].apply(((scala.Function2) references[30] /* udf */).apply(project_arg_8, project_arg_9));
/* 350 */         } catch (Exception e) {
/* 351 */           throw new org.apache.spark.SparkException(((java.lang.String) references[21] /* errMsg */), e);
/* 352 */         }
/* 353 */
/* 354 */         boolean project_isNull_40 = project_result_5 == null;
/* 355 */         UTF8String project_value_40 = null;
/* 356 */         if (!project_isNull_40) {
/* 357 */           project_value_40 = project_result_5;
/* 358 */         }
/* 359 */         project_isNull_15 = project_isNull_40;
/* 360 */         project_value_15 = project_value_40;
/* 361 */       }
/* 362 */       boolean project_isNull_64 = scan_isNull_3;
/* 363 */       double project_value_64 = -1.0;
/* 364 */       if (!scan_isNull_3) {
/* 365 */         try {
/* 366 */           project_value_64 = Double.valueOf(scan_value_3.toString());
/* 367 */         } catch (java.lang.NumberFormatException e) {
/* 368 */           project_isNull_64 = true;
/* 369 */         }
/* 370 */       }
/* 371 */       boolean project_value_62 = true;
/* 372 */
/* 373 */       if (!project_isNull_64) {
/* 374 */         boolean project_isNull_67 = scan_isNull_2;
/* 375 */         double project_value_67 = -1.0;
/* 376 */         if (!scan_isNull_2) {
/* 377 */           try {
/* 378 */             project_value_67 = Double.valueOf(scan_value_2.toString());
/* 379 */           } catch (java.lang.NumberFormatException e) {
/* 380 */             project_isNull_67 = true;
/* 381 */           }
/* 382 */         }
/* 383 */         project_value_62 = project_isNull_67;
/* 384 */       }
/* 385 */       boolean project_isNull_61 = false;
/* 386 */       UTF8String project_value_61 = null;
/* 387 */       if (!false && project_value_62) {
/* 388 */         project_isNull_61 = true;
/* 389 */         project_value_61 = ((UTF8String)null);
/* 390 */       } else {
/* 391 */         boolean project_isNull_71 = scan_isNull_3;
/* 392 */         double project_value_71 = -1.0;
/* 393 */         if (!scan_isNull_3) {
/* 394 */           try {
/* 395 */             project_value_71 = Double.valueOf(scan_value_3.toString());
/* 396 */           } catch (java.lang.NumberFormatException e) {
/* 397 */             project_isNull_71 = true;
/* 398 */           }
/* 399 */         }
/* 400 */         boolean project_isNull_73 = scan_isNull_2;
/* 401 */         double project_value_73 = -1.0;
/* 402 */         if (!scan_isNull_2) {
/* 403 */           try {
/* 404 */             project_value_73 = Double.valueOf(scan_value_2.toString());
/* 405 */           } catch (java.lang.NumberFormatException e) {
/* 406 */             project_isNull_73 = true;
/* 407 */           }
/* 408 */         }
/* 409 */         Object project_arg_10 = project_isNull_71 ? null : ((scala.Function1[]) references[31] /* converters */)[0].apply(project_value_71);
/* 410 */         Object project_arg_11 = project_isNull_73 ? null : ((scala.Function1[]) references[31] /* converters */)[1].apply(project_value_73);
/* 411 */
/* 412 */         UTF8String project_result_8 = null;
/* 413 */         try {
/* 414 */           project_result_8 = (UTF8String)((scala.Function1[]) references[31] /* converters */)[2].apply(((scala.Function2) references[33] /* udf */).apply(project_arg_10, project_arg_11));
/* 415 */         } catch (Exception e) {
/* 416 */           throw new org.apache.spark.SparkException(((java.lang.String) references[32] /* errMsg */), e);
/* 417 */         }
/* 418 */
/* 419 */         boolean project_isNull_70 = project_result_8 == null;
/* 420 */         UTF8String project_value_70 = null;
/* 421 */         if (!project_isNull_70) {
/* 422 */           project_value_70 = project_result_8;
/* 423 */         }
/* 424 */         project_isNull_61 = project_isNull_70;
/* 425 */         project_value_61 = project_value_70;
/* 426 */       }
/* 427 */       UTF8String project_result_9 = null;
/* 428 */       try {
/* 429 */         project_result_9 = (UTF8String)((scala.Function1[]) references[34] /* converters */)[0].apply(((scala.Function0) references[36] /* udf */).apply());
/* 430 */       } catch (Exception e) {
/* 431 */         throw new org.apache.spark.SparkException(((java.lang.String) references[35] /* errMsg */), e);
/* 432 */       }
/* 433 */
/* 434 */       boolean project_isNull_75 = project_result_9 == null;
/* 435 */       UTF8String project_value_75 = null;
/* 436 */       if (!project_isNull_75) {
/* 437 */         project_value_75 = project_result_9;
/* 438 */       }
/* 439 */       UTF8String project_result_10 = null;
/* 440 */       try {
/* 441 */         project_result_10 = (UTF8String)((scala.Function1[]) references[37] /* converters */)[0].apply(((scala.Function0) references[39] /* udf */).apply());
/* 442 */       } catch (Exception e) {
/* 443 */         throw new org.apache.spark.SparkException(((java.lang.String) references[38] /* errMsg */), e);
/* 444 */       }
/* 445 */
/* 446 */       boolean project_isNull_76 = project_result_10 == null;
/* 447 */       UTF8String project_value_76 = null;
/* 448 */       if (!project_isNull_76) {
/* 449 */         project_value_76 = project_result_10;
/* 450 */       }
/* 451 */       project_mutableStateArray_0[0].reset();
/* 452 */
/* 453 */       project_mutableStateArray_0[0].zeroOutNullBytes();
/* 454 */
/* 455 */       if (project_isNull_0) {
/* 456 */         project_mutableStateArray_0[0].setNullAt(0);
/* 457 */       } else {
/* 458 */         project_mutableStateArray_0[0].write(0, project_value_0);
/* 459 */       }
/* 460 */
/* 461 */       if (project_isNull_6) {
/* 462 */         project_mutableStateArray_0[0].setNullAt(1);
/* 463 */       } else {
/* 464 */         project_mutableStateArray_0[0].write(1, project_value_6);
/* 465 */       }
/* 466 */
/* 467 */       if (project_isNull_12) {
/* 468 */         project_mutableStateArray_0[0].setNullAt(2);
/* 469 */       } else {
/* 470 */         project_mutableStateArray_0[0].write(2, project_value_12);
/* 471 */       }
/* 472 */
/* 473 */       if (project_isNull_15) {
/* 474 */         project_mutableStateArray_0[0].setNullAt(3);
/* 475 */       } else {
/* 476 */         project_mutableStateArray_0[0].write(3, project_value_15);
/* 477 */       }
/* 478 */
/* 479 */       if (project_isNull_61) {
/* 480 */         project_mutableStateArray_0[0].setNullAt(4);
/* 481 */       } else {
/* 482 */         project_mutableStateArray_0[0].write(4, project_value_61);
/* 483 */       }
/* 484 */
/* 485 */       if (project_isNull_75) {
/* 486 */         project_mutableStateArray_0[0].setNullAt(5);
/* 487 */       } else {
/* 488 */         project_mutableStateArray_0[0].write(5, project_value_75);
/* 489 */       }
/* 490 */
/* 491 */       if (project_isNull_76) {
/* 492 */         project_mutableStateArray_0[0].setNullAt(6);
/* 493 */       } else {
/* 494 */         project_mutableStateArray_0[0].write(6, project_value_76);
/* 495 */       }
/* 496 */       append((project_mutableStateArray_0[0].getRow()));
/* 497 */       if (shouldStop()) return;
/* 498 */     }
/* 499 */   }
/* 500 */
/* 501 */ }

Cleaning accumulator 40
Cleaned accumulator 40
Got cleaning task CleanAccum(61)
Cleaning accumulator 61
Cleaned accumulator 61
Got cleaning task CleanAccum(45)
Cleaning accumulator 45
Cleaned accumulator 45
Got cleaning task CleanAccum(52)
Cleaning accumulator 52
Cleaned accumulator 52
Got cleaning task CleanAccum(64)
Cleaning accumulator 64
Cleaned accumulator 64
Got cleaning task CleanAccum(58)
Cleaning accumulator 58
Cleaned accumulator 58
Got cleaning task CleanAccum(36)
Cleaning accumulator 36
Cleaned accumulator 36
Got cleaning task CleanAccum(42)
Cleaning accumulator 42
Cleaned accumulator 42
Got cleaning task CleanBroadcast(3)
Cleaning broadcast 3
Unpersisting TorrentBroadcast 3
Block broadcast_5 stored as values in memory (estimated size 242.9 KB, free 1987.0 MB)
removing broadcast 3
Removing broadcast 3
Removing block broadcast_3_piece0
Block broadcast_3_piece0 of size 20482 dropped from memory (free 2083502210)
Put block broadcast_5 locally took  11 ms
Putting block broadcast_5 without replication took  11 ms
Removed broadcast_3_piece0 on 192.168.1.13:10964 in memory (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_3_piece0
Told master about block broadcast_3_piece0
Removing block broadcast_3
Block broadcast_3 of size 248760 dropped from memory (free 2083750970)
Done removing broadcast 3, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 3
Got cleaning task CleanAccum(53)
Cleaning accumulator 53
Cleaned accumulator 53
Got cleaning task CleanAccum(65)
Cleaning accumulator 65
Cleaned accumulator 65
Got cleaning task CleanAccum(56)
Cleaning accumulator 56
Cleaned accumulator 56
Got cleaning task CleanAccum(60)
Cleaning accumulator 60
Cleaned accumulator 60
Got cleaning task CleanBroadcast(4)
Cleaning broadcast 4
Unpersisting TorrentBroadcast 4
removing broadcast 4
Removing broadcast 4
Removing block broadcast_4_piece0
Block broadcast_4_piece0 of size 12294 dropped from memory (free 2083763264)
Removed broadcast_4_piece0 on 192.168.1.13:10964 in memory (size: 12.0 KB, free: 1987.5 MB)
Updated info of block broadcast_4_piece0
Told master about block broadcast_4_piece0
Removing block broadcast_4
Block broadcast_4 of size 32776 dropped from memory (free 2083796040)
Done removing broadcast 4, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 4
Got cleaning task CleanAccum(39)
Cleaning accumulator 39
Cleaned accumulator 39
Got cleaning task CleanAccum(43)
Cleaning accumulator 43
Cleaned accumulator 43
Got cleaning task CleanAccum(47)
Cleaning accumulator 47
Cleaned accumulator 47
Got cleaning task CleanAccum(41)
Cleaning accumulator 41
Cleaned accumulator 41
Got cleaning task CleanAccum(57)
Cleaning accumulator 57
Cleaned accumulator 57
Got cleaning task CleanAccum(66)
Cleaning accumulator 66
Cleaned accumulator 66
Got cleaning task CleanAccum(62)
Cleaning accumulator 62
Cleaned accumulator 62
Got cleaning task CleanAccum(46)
Cleaning accumulator 46
Cleaned accumulator 46
Got cleaning task CleanAccum(48)
Cleaning accumulator 48
Cleaned accumulator 48
Got cleaning task CleanAccum(44)
Cleaning accumulator 44
Cleaned accumulator 44
Got cleaning task CleanAccum(38)
Cleaning accumulator 38
Cleaned accumulator 38
Got cleaning task CleanAccum(63)
Cleaning accumulator 63
Cleaned accumulator 63
Got cleaning task CleanAccum(49)
Cleaning accumulator 49
Cleaned accumulator 49
Got cleaning task CleanAccum(50)
Cleaning accumulator 50
Cleaned accumulator 50
Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1987.2 MB)
Added broadcast_5_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.5 MB)
Updated info of block broadcast_5_piece0
Told master about block broadcast_5_piece0
Put block broadcast_5_piece0 locally took  2 ms
Putting block broadcast_5_piece0 without replication took  2 ms
Created broadcast 5 from csv at SparkUtiles.scala:37
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$write$15
 +++ Lambda closure ($anonfun$write$15) is now cleaned +++
Starting job: csv at SparkUtiles.scala:37
Registering RDD 15 (csv at SparkUtiles.scala:37)
Got job 2 (csv at SparkUtiles.scala:37) with 1 output partitions
Final stage: ResultStage 3 (csv at SparkUtiles.scala:37)
Parents of final stage: List(ShuffleMapStage 2)
Missing parents: List(ShuffleMapStage 2)
submitStage(ResultStage 3)
missing: List(ShuffleMapStage 2)
submitStage(ShuffleMapStage 2)
missing: List()
Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ShuffleMapStage 2)
Block broadcast_6 stored as values in memory (estimated size 33.0 KB, free 1987.2 MB)
Put block broadcast_6 locally took  1 ms
Putting block broadcast_6 without replication took  1 ms
Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.8 KB, free 1987.2 MB)
Added broadcast_6_piece0 in memory on 192.168.1.13:10964 (size: 12.8 KB, free: 1987.5 MB)
Updated info of block broadcast_6_piece0
Told master about block broadcast_6_piece0
Put block broadcast_6_piece0 locally took  2 ms
Putting block broadcast_6_piece0 without replication took  2 ms
Created broadcast 6 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 2.0 with 3 tasks
Epoch for TaskSet 2.0: 0
Valid locality levels for TaskSet 2.0: NO_PREF, ANY
parentName: , name: TaskSet_2.0, runningTasks: 0
Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7820 bytes)
Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7819 bytes)
Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 7817 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 2.0 (TID 2)
Running task 2.0 in stage 2.0 (TID 4)
Running task 1.0 in stage 2.0 (TID 3)
Getting local block broadcast_6
Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_5
Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Finished task 2.0 in stage 2.0 (TID 4). 1440 bytes result sent to driver
Finished task 0.0 in stage 2.0 (TID 2). 1397 bytes result sent to driver
parentName: , name: TaskSet_2.0, runningTasks: 2
parentName: , name: TaskSet_2.0, runningTasks: 1
Finished task 2.0 in stage 2.0 (TID 4) in 337 ms on localhost (executor driver) (1/3)
Finished task 0.0 in stage 2.0 (TID 2) in 339 ms on localhost (executor driver) (2/3)
Finished task 1.0 in stage 2.0 (TID 3). 1397 bytes result sent to driver
parentName: , name: TaskSet_2.0, runningTasks: 0
ShuffleMapTask finished on driver
Finished task 1.0 in stage 2.0 (TID 3) in 340 ms on localhost (executor driver) (3/3)
ShuffleMapTask finished on driver
Removed TaskSet 2.0, whose tasks have all completed, from pool 
ShuffleMapTask finished on driver
ShuffleMapStage 2 (csv at SparkUtiles.scala:37) finished in 0.361 s
looking for newly runnable stages
running: Set()
waiting: Set(ResultStage 3)
failed: Set()
Increasing epoch to 1
submitStage(ResultStage 3)
missing: List()
Submitting ResultStage 3 (ShuffledRowRDD[16] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ResultStage 3)
Block broadcast_7 stored as values in memory (estimated size 129.6 KB, free 1987.1 MB)
Put block broadcast_7 locally took  1 ms
Putting block broadcast_7 without replication took  1 ms
Block broadcast_7_piece0 stored as bytes in memory (estimated size 45.9 KB, free 1987.0 MB)
Added broadcast_7_piece0 in memory on 192.168.1.13:10964 (size: 45.9 KB, free: 1987.4 MB)
Updated info of block broadcast_7_piece0
Told master about block broadcast_7_piece0
Put block broadcast_7_piece0 locally took  1 ms
Putting block broadcast_7_piece0 without replication took  1 ms
Created broadcast 7 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 3 (ShuffledRowRDD[16] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0))
Adding task set 3.0 with 1 tasks
Epoch for TaskSet 3.0: 1
Valid locality levels for TaskSet 3.0: ANY
parentName: , name: TaskSet_3.0, runningTasks: 0
Starting task 0.0 in stage 3.0 (TID 5, localhost, executor driver, partition 0, ANY, 7246 bytes)
Running task 0.0 in stage 3.0 (TID 5)
Getting local block broadcast_7
Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
Fetching outputs for shuffle 0, partitions 0-1
Got cleaning task CleanBroadcast(6)
Cleaning broadcast 6
Unpersisting TorrentBroadcast 6
maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
removing broadcast 6
Removing broadcast 6
Removing block broadcast_6_piece0
Block broadcast_6_piece0 of size 13137 dropped from memory (free 2083561946)
Getting 3 non-empty blocks including 3 local blocks and 0 remote blocks
Removed broadcast_6_piece0 on 192.168.1.13:10964 in memory (size: 12.8 KB, free: 1987.4 MB)
Updated info of block broadcast_6_piece0
Told master about block broadcast_6_piece0
Removing block broadcast_6
Block broadcast_6 of size 33816 dropped from memory (free 2083595762)
Done removing broadcast 6, response is 0
Sent response: 0 to 192.168.1.13:10922
Started 0 remote fetches in 6 ms
Start fetching local blocks: shuffle_0_0_0, shuffle_0_1_0, shuffle_0_2_0
Cleaned broadcast 6
Got local blocks in  12 ms
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Commit allowed for stage=3.0, partition=0, task attempt 0
Saved output of task 'attempt_20190331201725_0003_m_000000_0' to file:/D:/p1/weather-simulator/src/main/resources/emulatedData/_temporary/0/task_20190331201725_0003_m_000000
attempt_20190331201725_0003_m_000000_0: Committed
Finished task 0.0 in stage 3.0 (TID 5). 2344 bytes result sent to driver
parentName: , name: TaskSet_3.0, runningTasks: 0
Finished task 0.0 in stage 3.0 (TID 5) in 339 ms on localhost (executor driver) (1/1)
Removed TaskSet 3.0, whose tasks have all completed, from pool 
ResultStage 3 (csv at SparkUtiles.scala:37) finished in 0.374 s
After removal of stage 2, remaining stages = 1
After removal of stage 3, remaining stages = 0
Job 2 finished: csv at SparkUtiles.scala:37, took 0.757580 s
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/emulatedData/_temporary/0/task_20190331201725_0003_m_000000; isDirectory=true; modification_time=1554023845522; access_time=1554023845522; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/emulatedData
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/emulatedData/_temporary/0/task_20190331201725_0003_m_000000/part-00000-13c0f4ee-2f07-496b-99a7-87addf2802aa-c000.csv; isDirectory=false; length=74854; replication=1; blocksize=33554432; modification_time=1554023845583; access_time=1554023845521; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/emulatedData/part-00000-13c0f4ee-2f07-496b-99a7-87addf2802aa-c000.csv
Committing files staged for absolute locations Map()
Write Job 696ace72-514b-4b10-a069-25069abbe838 committed.
Finished processing stats for write job 696ace72-514b-4b10-a069-25069abbe838.
Parsing command: emulated
Parsing command: 
SELECT bs.location,
       bs.monthday,
       bs.maxtemp,
       bs.mintemp,
       Replace(em.temperature, '+', '') AS tempra
FROM   bomstatis AS bs
       JOIN emulated AS em
         ON To_date(bs.monthday) = To_date(em.local_time)
            AND bs.location = em.location
      
Resolving 'bs.monthday to monthday#11
Resolving 'em.local_time to local_time#22
Resolving 'bs.location to location#10
Resolving 'em.location to location#20
Resolving 'bs.location to location#10
Resolving 'bs.monthday to monthday#11
Resolving 'bs.maxtemp to maxtemp#12
Resolving 'bs.mintemp to mintemp#13
Resolving 'em.temperature to temperature#24

=== Result of Batch Resolution ===
!'Project ['bs.location, 'bs.monthday, 'bs.maxtemp, 'bs.mintemp, 'Replace('em.temperature, +, ) AS tempra#76]   Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
!+- 'Join Inner, (('To_date('bs.monthday) = 'To_date('em.local_time)) && ('bs.location = 'em.location))         +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
!   :- 'SubqueryAlias `bs`                                                                                         :- SubqueryAlias `bs`
!   :  +- 'UnresolvedRelation `bomstatis`                                                                          :  +- SubqueryAlias `bomstatis`
!   +- 'SubqueryAlias `em`                                                                                         :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!      +- 'UnresolvedRelation `emulated`                                                                           +- SubqueryAlias `em`
!                                                                                                                     +- SubqueryAlias `emulated`
!                                                                                                                        +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!                                                                                                                           +- SubqueryAlias `outtab`
!                                                                                                                              +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!                                                                                                                                 +- SubqueryAlias `bomstatis`
!                                                                                                                                    +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
 +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                         +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
    :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                               :- SubqueryAlias `bs`
    :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                     :  +- SubqueryAlias `bomstatis`
    :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                    :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
    +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                               +- SubqueryAlias `em`
       +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                         +- SubqueryAlias `emulated`
          +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]            +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
             +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                           +- SubqueryAlias `outtab`
                +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                       +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
                   +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                        +- SubqueryAlias `bomstatis`
                      +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                          +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast(location#10 as string), None), unresolvedalias(cast(monthday#11 as string), None), unresolvedalias(cast(maxtemp#12 as string), None), unresolvedalias(cast(mintemp#13 as string), None), unresolvedalias(cast(tempra#76 as string), None)]                                                                                                                                                              Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]
 +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
    +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                            +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
       :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                  :- SubqueryAlias `bs`
       :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                        :  +- SubqueryAlias `bomstatis`
       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
       +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `em`
          +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                            +- SubqueryAlias `emulated`
             +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]               +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
                +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                              +- SubqueryAlias `outtab`
                   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                          +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
                      +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                           +- SubqueryAlias `bomstatis`
                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Cleanup ===
 Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]                                                                                                                                                                                                           Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]
 +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
    +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                            +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))
       :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                  :- SubqueryAlias `bs`
       :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                        :  +- SubqueryAlias `bomstatis`
       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                       :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
       +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                  +- SubqueryAlias `em`
          +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                            +- SubqueryAlias `emulated`
             +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]               +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
                +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                                              +- SubqueryAlias `outtab`
                   +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                          +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
                      +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                           +- SubqueryAlias `bomstatis`
                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                             +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Finish Analysis ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                               GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                             +- LocalLimit 21
    +- Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]                                                                                                                                                                                                              +- Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]
       +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                                     +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
!         +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                                  +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!            :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                        :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                              +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!            :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                                +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!            +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                              +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!               +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                   
!                  +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   
!                     +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                               
!                        +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                        
!                           +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!                              +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                         GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                                                                                                                                                       +- LocalLimit 21
!   +- Project [cast(location#10 as string) AS location#87, cast(monthday#11 as string) AS monthday#88, cast(maxtemp#12 as string) AS maxtemp#89, cast(mintemp#13 as string) AS mintemp#90, cast(tempra#76 as string) AS tempra#91]                                                                                                                                                                                                        +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]
!      +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                               +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                              :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!            :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                          :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!               +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!                  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                           
          

=== Result of Batch Infer Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                  GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                +- LocalLimit 21
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]                                                                                                                                                                                        +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :- Filter (isnotnull(monthday#11) && isnotnull(location#10))
!         :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]            :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   +- Filter (isnotnull(local_time#22) && isnotnull(location#20))
!                                                                                                                                                                                                                                                                                                            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!                                                                                                                                                                                                                                                                                                               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Operator Optimization after Inferring Filters ===
 GlobalLimit 21                                                                                                                                                                                                                                                                                     GlobalLimit 21
 +- LocalLimit 21                                                                                                                                                                                                                                                                                   +- LocalLimit 21
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]                                                                                                                                                                                           +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#91]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                          +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Filter (isnotnull(monthday#11) && isnotnull(location#10))                                                                                                                                                                                                                                       :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :  +- Filter (isnotnull(monthday#11) && isnotnull(location#10))
          :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Filter (isnotnull(local_time#22) && isnotnull(location#20))                                                                                                                                                                                                                                     +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]               +- Filter (isnotnull(UDF(monthday#11, location#10)) && isnotnull(split(UDF(location#10), [|])[0]))
                +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Pruning directories with: 
Post-Scan Filters: isnotnull(monthday#11),isnotnull(location#10)
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: IsNotNull(monthday),IsNotNull(location)
Pruning directories with: 
Post-Scan Filters: isnotnull(UDF(monthday#11, location#10)),isnotnull(split(UDF(location#10), [|])[0])
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, getcolumnbyordinal(1, StringType).toString, getcolumnbyordinal(2, StringType).toString, getcolumnbyordinal(3, StringType).toString, getcolumnbyordinal(4, StringType).toString, StructField(location,StringType,true), StructField(monthday,StringType,true), StructField(maxtemp,StringType,true), StructField(mintemp,StringType,true), StructField(tempra,StringType,true))), obj#97: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(location#87.toString, monthday#88.toString, maxtemp#89.toString, mintemp#90.toString, tempra#91.toString, StructField(location,StringType,true), StructField(monthday,StringType,true), StructField(maxtemp,StringType,true), StructField(mintemp,StringType,true), StructField(tempra,StringType,true)), obj#97: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [location#87, monthday#88, maxtemp#89, mintemp#90, tempra#91]                                                                                                                                                                                                                                                                                                                                                                                                                                       +- LocalRelation <empty>, [location#87, monthday#88, maxtemp#89, mintemp#90, tempra#91]
          
code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, input[3, string, true].toString, input[4, string, true].toString, StructField(location,StringType,true), StructField(monthday,StringType,true), StructField(maxtemp,StringType,true), StructField(mintemp,StringType,true), StructField(tempra,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[5];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 027 */     if (false) {
/* 028 */       mutableRow.setNullAt(0);
/* 029 */     } else {
/* 030 */
/* 031 */       mutableRow.update(0, value_0);
/* 032 */     }
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */
/* 037 */
/* 038 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 039 */
/* 040 */     boolean isNull_8 = i.isNullAt(3);
/* 041 */     UTF8String value_8 = isNull_8 ?
/* 042 */     null : (i.getUTF8String(3));
/* 043 */     boolean isNull_7 = true;
/* 044 */     java.lang.String value_7 = null;
/* 045 */     if (!isNull_8) {
/* 046 */
/* 047 */       isNull_7 = false;
/* 048 */       if (!isNull_7) {
/* 049 */
/* 050 */         Object funcResult_3 = null;
/* 051 */         funcResult_3 = value_8.toString();
/* 052 */         value_7 = (java.lang.String) funcResult_3;
/* 053 */
/* 054 */       }
/* 055 */     }
/* 056 */     if (isNull_7) {
/* 057 */       values_0[3] = null;
/* 058 */     } else {
/* 059 */       values_0[3] = value_7;
/* 060 */     }
/* 061 */
/* 062 */     boolean isNull_10 = i.isNullAt(4);
/* 063 */     UTF8String value_10 = isNull_10 ?
/* 064 */     null : (i.getUTF8String(4));
/* 065 */     boolean isNull_9 = true;
/* 066 */     java.lang.String value_9 = null;
/* 067 */     if (!isNull_10) {
/* 068 */
/* 069 */       isNull_9 = false;
/* 070 */       if (!isNull_9) {
/* 071 */
/* 072 */         Object funcResult_4 = null;
/* 073 */         funcResult_4 = value_10.toString();
/* 074 */         value_9 = (java.lang.String) funcResult_4;
/* 075 */
/* 076 */       }
/* 077 */     }
/* 078 */     if (isNull_9) {
/* 079 */       values_0[4] = null;
/* 080 */     } else {
/* 081 */       values_0[4] = value_9;
/* 082 */     }
/* 083 */
/* 084 */   }
/* 085 */
/* 086 */
/* 087 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 088 */
/* 089 */     boolean isNull_2 = i.isNullAt(0);
/* 090 */     UTF8String value_2 = isNull_2 ?
/* 091 */     null : (i.getUTF8String(0));
/* 092 */     boolean isNull_1 = true;
/* 093 */     java.lang.String value_1 = null;
/* 094 */     if (!isNull_2) {
/* 095 */
/* 096 */       isNull_1 = false;
/* 097 */       if (!isNull_1) {
/* 098 */
/* 099 */         Object funcResult_0 = null;
/* 100 */         funcResult_0 = value_2.toString();
/* 101 */         value_1 = (java.lang.String) funcResult_0;
/* 102 */
/* 103 */       }
/* 104 */     }
/* 105 */     if (isNull_1) {
/* 106 */       values_0[0] = null;
/* 107 */     } else {
/* 108 */       values_0[0] = value_1;
/* 109 */     }
/* 110 */
/* 111 */     boolean isNull_4 = i.isNullAt(1);
/* 112 */     UTF8String value_4 = isNull_4 ?
/* 113 */     null : (i.getUTF8String(1));
/* 114 */     boolean isNull_3 = true;
/* 115 */     java.lang.String value_3 = null;
/* 116 */     if (!isNull_4) {
/* 117 */
/* 118 */       isNull_3 = false;
/* 119 */       if (!isNull_3) {
/* 120 */
/* 121 */         Object funcResult_1 = null;
/* 122 */         funcResult_1 = value_4.toString();
/* 123 */         value_3 = (java.lang.String) funcResult_1;
/* 124 */
/* 125 */       }
/* 126 */     }
/* 127 */     if (isNull_3) {
/* 128 */       values_0[1] = null;
/* 129 */     } else {
/* 130 */       values_0[1] = value_3;
/* 131 */     }
/* 132 */
/* 133 */     boolean isNull_6 = i.isNullAt(2);
/* 134 */     UTF8String value_6 = isNull_6 ?
/* 135 */     null : (i.getUTF8String(2));
/* 136 */     boolean isNull_5 = true;
/* 137 */     java.lang.String value_5 = null;
/* 138 */     if (!isNull_6) {
/* 139 */
/* 140 */       isNull_5 = false;
/* 141 */       if (!isNull_5) {
/* 142 */
/* 143 */         Object funcResult_2 = null;
/* 144 */         funcResult_2 = value_6.toString();
/* 145 */         value_5 = (java.lang.String) funcResult_2;
/* 146 */
/* 147 */       }
/* 148 */     }
/* 149 */     if (isNull_5) {
/* 150 */       values_0[2] = null;
/* 151 */     } else {
/* 152 */       values_0[2] = value_5;
/* 153 */     }
/* 154 */
/* 155 */   }
/* 156 */
/* 157 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[5];
/* 024 */     createExternalRow_0_0(i, values_0);
/* 025 */     createExternalRow_0_1(i, values_0);
/* 026 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 027 */     if (false) {
/* 028 */       mutableRow.setNullAt(0);
/* 029 */     } else {
/* 030 */
/* 031 */       mutableRow.update(0, value_0);
/* 032 */     }
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */
/* 037 */
/* 038 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {
/* 039 */
/* 040 */     boolean isNull_8 = i.isNullAt(3);
/* 041 */     UTF8String value_8 = isNull_8 ?
/* 042 */     null : (i.getUTF8String(3));
/* 043 */     boolean isNull_7 = true;
/* 044 */     java.lang.String value_7 = null;
/* 045 */     if (!isNull_8) {
/* 046 */
/* 047 */       isNull_7 = false;
/* 048 */       if (!isNull_7) {
/* 049 */
/* 050 */         Object funcResult_3 = null;
/* 051 */         funcResult_3 = value_8.toString();
/* 052 */         value_7 = (java.lang.String) funcResult_3;
/* 053 */
/* 054 */       }
/* 055 */     }
/* 056 */     if (isNull_7) {
/* 057 */       values_0[3] = null;
/* 058 */     } else {
/* 059 */       values_0[3] = value_7;
/* 060 */     }
/* 061 */
/* 062 */     boolean isNull_10 = i.isNullAt(4);
/* 063 */     UTF8String value_10 = isNull_10 ?
/* 064 */     null : (i.getUTF8String(4));
/* 065 */     boolean isNull_9 = true;
/* 066 */     java.lang.String value_9 = null;
/* 067 */     if (!isNull_10) {
/* 068 */
/* 069 */       isNull_9 = false;
/* 070 */       if (!isNull_9) {
/* 071 */
/* 072 */         Object funcResult_4 = null;
/* 073 */         funcResult_4 = value_10.toString();
/* 074 */         value_9 = (java.lang.String) funcResult_4;
/* 075 */
/* 076 */       }
/* 077 */     }
/* 078 */     if (isNull_9) {
/* 079 */       values_0[4] = null;
/* 080 */     } else {
/* 081 */       values_0[4] = value_9;
/* 082 */     }
/* 083 */
/* 084 */   }
/* 085 */
/* 086 */
/* 087 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {
/* 088 */
/* 089 */     boolean isNull_2 = i.isNullAt(0);
/* 090 */     UTF8String value_2 = isNull_2 ?
/* 091 */     null : (i.getUTF8String(0));
/* 092 */     boolean isNull_1 = true;
/* 093 */     java.lang.String value_1 = null;
/* 094 */     if (!isNull_2) {
/* 095 */
/* 096 */       isNull_1 = false;
/* 097 */       if (!isNull_1) {
/* 098 */
/* 099 */         Object funcResult_0 = null;
/* 100 */         funcResult_0 = value_2.toString();
/* 101 */         value_1 = (java.lang.String) funcResult_0;
/* 102 */
/* 103 */       }
/* 104 */     }
/* 105 */     if (isNull_1) {
/* 106 */       values_0[0] = null;
/* 107 */     } else {
/* 108 */       values_0[0] = value_1;
/* 109 */     }
/* 110 */
/* 111 */     boolean isNull_4 = i.isNullAt(1);
/* 112 */     UTF8String value_4 = isNull_4 ?
/* 113 */     null : (i.getUTF8String(1));
/* 114 */     boolean isNull_3 = true;
/* 115 */     java.lang.String value_3 = null;
/* 116 */     if (!isNull_4) {
/* 117 */
/* 118 */       isNull_3 = false;
/* 119 */       if (!isNull_3) {
/* 120 */
/* 121 */         Object funcResult_1 = null;
/* 122 */         funcResult_1 = value_4.toString();
/* 123 */         value_3 = (java.lang.String) funcResult_1;
/* 124 */
/* 125 */       }
/* 126 */     }
/* 127 */     if (isNull_3) {
/* 128 */       values_0[1] = null;
/* 129 */     } else {
/* 130 */       values_0[1] = value_3;
/* 131 */     }
/* 132 */
/* 133 */     boolean isNull_6 = i.isNullAt(2);
/* 134 */     UTF8String value_6 = isNull_6 ?
/* 135 */     null : (i.getUTF8String(2));
/* 136 */     boolean isNull_5 = true;
/* 137 */     java.lang.String value_5 = null;
/* 138 */     if (!isNull_6) {
/* 139 */
/* 140 */       isNull_5 = false;
/* 141 */       if (!isNull_5) {
/* 142 */
/* 143 */         Object funcResult_2 = null;
/* 144 */         funcResult_2 = value_6.toString();
/* 145 */         value_5 = (java.lang.String) funcResult_2;
/* 146 */
/* 147 */       }
/* 148 */     }
/* 149 */     if (isNull_5) {
/* 150 */       values_0[2] = null;
/* 151 */     } else {
/* 152 */       values_0[2] = value_5;
/* 153 */     }
/* 154 */
/* 155 */   }
/* 156 */
/* 157 */ }

Code generated in 9.285132 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 96);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 032 */         null : (scan_row_0.getUTF8String(0));
/* 033 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 034 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 035 */         null : (scan_row_0.getUTF8String(1));
/* 036 */
/* 037 */         Object filter_arg_0 = scan_isNull_1 ? null : ((scala.Function1[]) references[2] /* converters */)[0].apply(scan_value_1);
/* 038 */         Object filter_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[2] /* converters */)[1].apply(scan_value_0);
/* 039 */
/* 040 */         UTF8String filter_result_0 = null;
/* 041 */         try {
/* 042 */           filter_result_0 = (UTF8String)((scala.Function1[]) references[2] /* converters */)[2].apply(((scala.Function2) references[4] /* udf */).apply(filter_arg_0, filter_arg_1));
/* 043 */         } catch (Exception e) {
/* 044 */           throw new org.apache.spark.SparkException(((java.lang.String) references[3] /* errMsg */), e);
/* 045 */         }
/* 046 */
/* 047 */         boolean filter_isNull_1 = filter_result_0 == null;
/* 048 */         UTF8String filter_value_1 = null;
/* 049 */         if (!filter_isNull_1) {
/* 050 */           filter_value_1 = filter_result_0;
/* 051 */         }
/* 052 */         if (!(!filter_isNull_1)) continue;
/* 053 */         boolean filter_isNull_5 = true;
/* 054 */         UTF8String filter_value_5 = null;
/* 055 */         boolean filter_isNull_6 = true;
/* 056 */         ArrayData filter_value_6 = null;
/* 057 */         Object filter_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 058 */
/* 059 */         UTF8String filter_result_1 = null;
/* 060 */         try {
/* 061 */           filter_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(filter_arg_2));
/* 062 */         } catch (Exception e) {
/* 063 */           throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 064 */         }
/* 065 */
/* 066 */         boolean filter_isNull_7 = filter_result_1 == null;
/* 067 */         UTF8String filter_value_7 = null;
/* 068 */         if (!filter_isNull_7) {
/* 069 */           filter_value_7 = filter_result_1;
/* 070 */         }
/* 071 */         if (!filter_isNull_7) {
/* 072 */           filter_isNull_6 = false; // resultCode could change nullability.
/* 073 */           filter_value_6 = new org.apache.spark.sql.catalyst.util.GenericArrayData(filter_value_7.split(((UTF8String) references[8] /* literal */), -1));
/* 074 */
/* 075 */         }
/* 076 */         if (!filter_isNull_6) {
/* 077 */           filter_isNull_5 = false; // resultCode could change nullability.
/* 078 */
/* 079 */           final int filter_index_0 = (int) 0;
/* 080 */           if (filter_index_0 >= filter_value_6.numElements() || filter_index_0 < 0 || filter_value_6.isNullAt(filter_index_0)) {
/* 081 */             filter_isNull_5 = true;
/* 082 */           } else {
/* 083 */             filter_value_5 = filter_value_6.getUTF8String(filter_index_0);
/* 084 */           }
/* 085 */
/* 086 */         }
/* 087 */         if (!(!filter_isNull_5)) continue;
/* 088 */
/* 089 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 090 */
/* 091 */         boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 092 */         UTF8String scan_value_2 = scan_isNull_2 ?
/* 093 */         null : (scan_row_0.getUTF8String(2));
/* 094 */         boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 095 */         UTF8String scan_value_3 = scan_isNull_3 ?
/* 096 */         null : (scan_row_0.getUTF8String(3));
/* 097 */
/* 098 */         boolean project_isNull_0 = true;
/* 099 */         UTF8String project_value_0 = null;
/* 100 */         boolean project_isNull_1 = true;
/* 101 */         ArrayData project_value_1 = null;
/* 102 */         Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_0);
/* 103 */
/* 104 */         UTF8String project_result_0 = null;
/* 105 */         try {
/* 106 */           project_result_0 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[1].apply(((scala.Function1) references[11] /* udf */).apply(project_arg_0));
/* 107 */         } catch (Exception e) {
/* 108 */           throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 109 */         }
/* 110 */
/* 111 */         boolean project_isNull_2 = project_result_0 == null;
/* 112 */         UTF8String project_value_2 = null;
/* 113 */         if (!project_isNull_2) {
/* 114 */           project_value_2 = project_result_0;
/* 115 */         }
/* 116 */         if (!project_isNull_2) {
/* 117 */           project_isNull_1 = false; // resultCode could change nullability.
/* 118 */           project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[12] /* literal */), -1));
/* 119 */
/* 120 */         }
/* 121 */         if (!project_isNull_1) {
/* 122 */           project_isNull_0 = false; // resultCode could change nullability.
/* 123 */
/* 124 */           final int project_index_0 = (int) 0;
/* 125 */           if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 126 */             project_isNull_0 = true;
/* 127 */           } else {
/* 128 */             project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 129 */           }
/* 130 */
/* 131 */         }
/* 132 */         Object project_arg_1 = scan_isNull_1 ? null : ((scala.Function1[]) references[13] /* converters */)[0].apply(scan_value_1);
/* 133 */         Object project_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[13] /* converters */)[1].apply(scan_value_0);
/* 134 */
/* 135 */         UTF8String project_result_1 = null;
/* 136 */         try {
/* 137 */           project_result_1 = (UTF8String)((scala.Function1[]) references[13] /* converters */)[2].apply(((scala.Function2) references[15] /* udf */).apply(project_arg_1, project_arg_2));
/* 138 */         } catch (Exception e) {
/* 139 */           throw new org.apache.spark.SparkException(((java.lang.String) references[14] /* errMsg */), e);
/* 140 */         }
/* 141 */
/* 142 */         boolean project_isNull_6 = project_result_1 == null;
/* 143 */         UTF8String project_value_6 = null;
/* 144 */         if (!project_isNull_6) {
/* 145 */           project_value_6 = project_result_1;
/* 146 */         }
/* 147 */         boolean project_isNull_12 = scan_isNull_3;
/* 148 */         double project_value_12 = -1.0;
/* 149 */         if (!scan_isNull_3) {
/* 150 */           try {
/* 151 */             project_value_12 = Double.valueOf(scan_value_3.toString());
/* 152 */           } catch (java.lang.NumberFormatException e) {
/* 153 */             project_isNull_12 = true;
/* 154 */           }
/* 155 */         }
/* 156 */         boolean project_value_10 = true;
/* 157 */
/* 158 */         if (!project_isNull_12) {
/* 159 */           boolean project_isNull_15 = scan_isNull_2;
/* 160 */           double project_value_15 = -1.0;
/* 161 */           if (!scan_isNull_2) {
/* 162 */             try {
/* 163 */               project_value_15 = Double.valueOf(scan_value_2.toString());
/* 164 */             } catch (java.lang.NumberFormatException e) {
/* 165 */               project_isNull_15 = true;
/* 166 */             }
/* 167 */           }
/* 168 */           project_value_10 = project_isNull_15;
/* 169 */         }
/* 170 */         boolean project_isNull_9 = false;
/* 171 */         UTF8String project_value_9 = null;
/* 172 */         if (!false && project_value_10) {
/* 173 */           project_isNull_9 = true;
/* 174 */           project_value_9 = ((UTF8String)null);
/* 175 */         } else {
/* 176 */           boolean project_isNull_19 = scan_isNull_3;
/* 177 */           double project_value_19 = -1.0;
/* 178 */           if (!scan_isNull_3) {
/* 179 */             try {
/* 180 */               project_value_19 = Double.valueOf(scan_value_3.toString());
/* 181 */             } catch (java.lang.NumberFormatException e) {
/* 182 */               project_isNull_19 = true;
/* 183 */             }
/* 184 */           }
/* 185 */           boolean project_isNull_21 = scan_isNull_2;
/* 186 */           double project_value_21 = -1.0;
/* 187 */           if (!scan_isNull_2) {
/* 188 */             try {
/* 189 */               project_value_21 = Double.valueOf(scan_value_2.toString());
/* 190 */             } catch (java.lang.NumberFormatException e) {
/* 191 */               project_isNull_21 = true;
/* 192 */             }
/* 193 */           }
/* 194 */           Object project_arg_3 = project_isNull_19 ? null : ((scala.Function1[]) references[16] /* converters */)[0].apply(project_value_19);
/* 195 */           Object project_arg_4 = project_isNull_21 ? null : ((scala.Function1[]) references[16] /* converters */)[1].apply(project_value_21);
/* 196 */
/* 197 */           UTF8String project_result_2 = null;
/* 198 */           try {
/* 199 */             project_result_2 = (UTF8String)((scala.Function1[]) references[16] /* converters */)[2].apply(((scala.Function2) references[18] /* udf */).apply(project_arg_3, project_arg_4));
/* 200 */           } catch (Exception e) {
/* 201 */             throw new org.apache.spark.SparkException(((java.lang.String) references[17] /* errMsg */), e);
/* 202 */           }
/* 203 */
/* 204 */           boolean project_isNull_18 = project_result_2 == null;
/* 205 */           UTF8String project_value_18 = null;
/* 206 */           if (!project_isNull_18) {
/* 207 */             project_value_18 = project_result_2;
/* 208 */           }
/* 209 */           project_isNull_9 = project_isNull_18;
/* 210 */           project_value_9 = project_value_18;
/* 211 */         }
/* 212 */         filter_mutableStateArray_0[1].reset();
/* 213 */
/* 214 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 215 */
/* 216 */         if (project_isNull_0) {
/* 217 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 218 */         } else {
/* 219 */           filter_mutableStateArray_0[1].write(0, project_value_0);
/* 220 */         }
/* 221 */
/* 222 */         if (project_isNull_6) {
/* 223 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 224 */         } else {
/* 225 */           filter_mutableStateArray_0[1].write(1, project_value_6);
/* 226 */         }
/* 227 */
/* 228 */         if (project_isNull_9) {
/* 229 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 230 */         } else {
/* 231 */           filter_mutableStateArray_0[1].write(2, project_value_9);
/* 232 */         }
/* 233 */         append((filter_mutableStateArray_0[1].getRow()));
/* 234 */
/* 235 */       } while(false);
/* 236 */       if (shouldStop()) return;
/* 237 */     }
/* 238 */   }
/* 239 */
/* 240 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 96);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 032 */         null : (scan_row_0.getUTF8String(0));
/* 033 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 034 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 035 */         null : (scan_row_0.getUTF8String(1));
/* 036 */
/* 037 */         Object filter_arg_0 = scan_isNull_1 ? null : ((scala.Function1[]) references[2] /* converters */)[0].apply(scan_value_1);
/* 038 */         Object filter_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[2] /* converters */)[1].apply(scan_value_0);
/* 039 */
/* 040 */         UTF8String filter_result_0 = null;
/* 041 */         try {
/* 042 */           filter_result_0 = (UTF8String)((scala.Function1[]) references[2] /* converters */)[2].apply(((scala.Function2) references[4] /* udf */).apply(filter_arg_0, filter_arg_1));
/* 043 */         } catch (Exception e) {
/* 044 */           throw new org.apache.spark.SparkException(((java.lang.String) references[3] /* errMsg */), e);
/* 045 */         }
/* 046 */
/* 047 */         boolean filter_isNull_1 = filter_result_0 == null;
/* 048 */         UTF8String filter_value_1 = null;
/* 049 */         if (!filter_isNull_1) {
/* 050 */           filter_value_1 = filter_result_0;
/* 051 */         }
/* 052 */         if (!(!filter_isNull_1)) continue;
/* 053 */         boolean filter_isNull_5 = true;
/* 054 */         UTF8String filter_value_5 = null;
/* 055 */         boolean filter_isNull_6 = true;
/* 056 */         ArrayData filter_value_6 = null;
/* 057 */         Object filter_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 058 */
/* 059 */         UTF8String filter_result_1 = null;
/* 060 */         try {
/* 061 */           filter_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(filter_arg_2));
/* 062 */         } catch (Exception e) {
/* 063 */           throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 064 */         }
/* 065 */
/* 066 */         boolean filter_isNull_7 = filter_result_1 == null;
/* 067 */         UTF8String filter_value_7 = null;
/* 068 */         if (!filter_isNull_7) {
/* 069 */           filter_value_7 = filter_result_1;
/* 070 */         }
/* 071 */         if (!filter_isNull_7) {
/* 072 */           filter_isNull_6 = false; // resultCode could change nullability.
/* 073 */           filter_value_6 = new org.apache.spark.sql.catalyst.util.GenericArrayData(filter_value_7.split(((UTF8String) references[8] /* literal */), -1));
/* 074 */
/* 075 */         }
/* 076 */         if (!filter_isNull_6) {
/* 077 */           filter_isNull_5 = false; // resultCode could change nullability.
/* 078 */
/* 079 */           final int filter_index_0 = (int) 0;
/* 080 */           if (filter_index_0 >= filter_value_6.numElements() || filter_index_0 < 0 || filter_value_6.isNullAt(filter_index_0)) {
/* 081 */             filter_isNull_5 = true;
/* 082 */           } else {
/* 083 */             filter_value_5 = filter_value_6.getUTF8String(filter_index_0);
/* 084 */           }
/* 085 */
/* 086 */         }
/* 087 */         if (!(!filter_isNull_5)) continue;
/* 088 */
/* 089 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 090 */
/* 091 */         boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 092 */         UTF8String scan_value_2 = scan_isNull_2 ?
/* 093 */         null : (scan_row_0.getUTF8String(2));
/* 094 */         boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 095 */         UTF8String scan_value_3 = scan_isNull_3 ?
/* 096 */         null : (scan_row_0.getUTF8String(3));
/* 097 */
/* 098 */         boolean project_isNull_0 = true;
/* 099 */         UTF8String project_value_0 = null;
/* 100 */         boolean project_isNull_1 = true;
/* 101 */         ArrayData project_value_1 = null;
/* 102 */         Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_0);
/* 103 */
/* 104 */         UTF8String project_result_0 = null;
/* 105 */         try {
/* 106 */           project_result_0 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[1].apply(((scala.Function1) references[11] /* udf */).apply(project_arg_0));
/* 107 */         } catch (Exception e) {
/* 108 */           throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 109 */         }
/* 110 */
/* 111 */         boolean project_isNull_2 = project_result_0 == null;
/* 112 */         UTF8String project_value_2 = null;
/* 113 */         if (!project_isNull_2) {
/* 114 */           project_value_2 = project_result_0;
/* 115 */         }
/* 116 */         if (!project_isNull_2) {
/* 117 */           project_isNull_1 = false; // resultCode could change nullability.
/* 118 */           project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[12] /* literal */), -1));
/* 119 */
/* 120 */         }
/* 121 */         if (!project_isNull_1) {
/* 122 */           project_isNull_0 = false; // resultCode could change nullability.
/* 123 */
/* 124 */           final int project_index_0 = (int) 0;
/* 125 */           if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 126 */             project_isNull_0 = true;
/* 127 */           } else {
/* 128 */             project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 129 */           }
/* 130 */
/* 131 */         }
/* 132 */         Object project_arg_1 = scan_isNull_1 ? null : ((scala.Function1[]) references[13] /* converters */)[0].apply(scan_value_1);
/* 133 */         Object project_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[13] /* converters */)[1].apply(scan_value_0);
/* 134 */
/* 135 */         UTF8String project_result_1 = null;
/* 136 */         try {
/* 137 */           project_result_1 = (UTF8String)((scala.Function1[]) references[13] /* converters */)[2].apply(((scala.Function2) references[15] /* udf */).apply(project_arg_1, project_arg_2));
/* 138 */         } catch (Exception e) {
/* 139 */           throw new org.apache.spark.SparkException(((java.lang.String) references[14] /* errMsg */), e);
/* 140 */         }
/* 141 */
/* 142 */         boolean project_isNull_6 = project_result_1 == null;
/* 143 */         UTF8String project_value_6 = null;
/* 144 */         if (!project_isNull_6) {
/* 145 */           project_value_6 = project_result_1;
/* 146 */         }
/* 147 */         boolean project_isNull_12 = scan_isNull_3;
/* 148 */         double project_value_12 = -1.0;
/* 149 */         if (!scan_isNull_3) {
/* 150 */           try {
/* 151 */             project_value_12 = Double.valueOf(scan_value_3.toString());
/* 152 */           } catch (java.lang.NumberFormatException e) {
/* 153 */             project_isNull_12 = true;
/* 154 */           }
/* 155 */         }
/* 156 */         boolean project_value_10 = true;
/* 157 */
/* 158 */         if (!project_isNull_12) {
/* 159 */           boolean project_isNull_15 = scan_isNull_2;
/* 160 */           double project_value_15 = -1.0;
/* 161 */           if (!scan_isNull_2) {
/* 162 */             try {
/* 163 */               project_value_15 = Double.valueOf(scan_value_2.toString());
/* 164 */             } catch (java.lang.NumberFormatException e) {
/* 165 */               project_isNull_15 = true;
/* 166 */             }
/* 167 */           }
/* 168 */           project_value_10 = project_isNull_15;
/* 169 */         }
/* 170 */         boolean project_isNull_9 = false;
/* 171 */         UTF8String project_value_9 = null;
/* 172 */         if (!false && project_value_10) {
/* 173 */           project_isNull_9 = true;
/* 174 */           project_value_9 = ((UTF8String)null);
/* 175 */         } else {
/* 176 */           boolean project_isNull_19 = scan_isNull_3;
/* 177 */           double project_value_19 = -1.0;
/* 178 */           if (!scan_isNull_3) {
/* 179 */             try {
/* 180 */               project_value_19 = Double.valueOf(scan_value_3.toString());
/* 181 */             } catch (java.lang.NumberFormatException e) {
/* 182 */               project_isNull_19 = true;
/* 183 */             }
/* 184 */           }
/* 185 */           boolean project_isNull_21 = scan_isNull_2;
/* 186 */           double project_value_21 = -1.0;
/* 187 */           if (!scan_isNull_2) {
/* 188 */             try {
/* 189 */               project_value_21 = Double.valueOf(scan_value_2.toString());
/* 190 */             } catch (java.lang.NumberFormatException e) {
/* 191 */               project_isNull_21 = true;
/* 192 */             }
/* 193 */           }
/* 194 */           Object project_arg_3 = project_isNull_19 ? null : ((scala.Function1[]) references[16] /* converters */)[0].apply(project_value_19);
/* 195 */           Object project_arg_4 = project_isNull_21 ? null : ((scala.Function1[]) references[16] /* converters */)[1].apply(project_value_21);
/* 196 */
/* 197 */           UTF8String project_result_2 = null;
/* 198 */           try {
/* 199 */             project_result_2 = (UTF8String)((scala.Function1[]) references[16] /* converters */)[2].apply(((scala.Function2) references[18] /* udf */).apply(project_arg_3, project_arg_4));
/* 200 */           } catch (Exception e) {
/* 201 */             throw new org.apache.spark.SparkException(((java.lang.String) references[17] /* errMsg */), e);
/* 202 */           }
/* 203 */
/* 204 */           boolean project_isNull_18 = project_result_2 == null;
/* 205 */           UTF8String project_value_18 = null;
/* 206 */           if (!project_isNull_18) {
/* 207 */             project_value_18 = project_result_2;
/* 208 */           }
/* 209 */           project_isNull_9 = project_isNull_18;
/* 210 */           project_value_9 = project_value_18;
/* 211 */         }
/* 212 */         filter_mutableStateArray_0[1].reset();
/* 213 */
/* 214 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 215 */
/* 216 */         if (project_isNull_0) {
/* 217 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 218 */         } else {
/* 219 */           filter_mutableStateArray_0[1].write(0, project_value_0);
/* 220 */         }
/* 221 */
/* 222 */         if (project_isNull_6) {
/* 223 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 224 */         } else {
/* 225 */           filter_mutableStateArray_0[1].write(1, project_value_6);
/* 226 */         }
/* 227 */
/* 228 */         if (project_isNull_9) {
/* 229 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 230 */         } else {
/* 231 */           filter_mutableStateArray_0[1].write(2, project_value_9);
/* 232 */         }
/* 233 */         append((filter_mutableStateArray_0[1].getRow()));
/* 234 */
/* 235 */       } while(false);
/* 236 */       if (shouldStop()) return;
/* 237 */     }
/* 238 */   }
/* 239 */
/* 240 */ }

Code generated in 28.099149 ms
Block broadcast_8 stored as values in memory (estimated size 242.9 KB, free 1986.8 MB)
Put block broadcast_8 locally took  3 ms
Putting block broadcast_8 without replication took  3 ms
Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1986.8 MB)
Added broadcast_8_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_8_piece0
Told master about block broadcast_8_piece0
Put block broadcast_8_piece0 locally took  2 ms
Putting block broadcast_8_piece0 without replication took  2 ms
Created broadcast 8 from run at ThreadPoolExecutor.java:1149
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$collect$2
 +++ Lambda closure ($anonfun$collect$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: run at ThreadPoolExecutor.java:1149
Got job 3 (run at ThreadPoolExecutor.java:1149) with 3 output partitions
Final stage: ResultStage 4 (run at ThreadPoolExecutor.java:1149)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 4)
missing: List()
Submitting ResultStage 4 (MapPartitionsRDD[20] at run at ThreadPoolExecutor.java:1149), which has no missing parents
submitMissingTasks(ResultStage 4)
Block broadcast_9 stored as values in memory (estimated size 22.5 KB, free 1986.8 MB)
Put block broadcast_9 locally took  1 ms
Putting block broadcast_9 without replication took  1 ms
Block broadcast_9_piece0 stored as bytes in memory (estimated size 9.8 KB, free 1986.8 MB)
Added broadcast_9_piece0 in memory on 192.168.1.13:10964 (size: 9.8 KB, free: 1987.4 MB)
Updated info of block broadcast_9_piece0
Told master about block broadcast_9_piece0
Put block broadcast_9_piece0 locally took  2 ms
Putting block broadcast_9_piece0 without replication took  2 ms
Created broadcast 9 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 4.0 with 3 tasks
Epoch for TaskSet 4.0: 1
Valid locality levels for TaskSet 4.0: NO_PREF, ANY
parentName: , name: TaskSet_4.0, runningTasks: 0
Starting task 0.0 in stage 4.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
Starting task 1.0 in stage 4.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 7830 bytes)
Starting task 2.0 in stage 4.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 7828 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 2.0 in stage 4.0 (TID 8)
Running task 1.0 in stage 4.0 (TID 7)
Running task 0.0 in stage 4.0 (TID 6)
Getting local block broadcast_9
Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_8
Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 2.0 in stage 4.0 (TID 8). 7134 bytes result sent to driver
Finished task 0.0 in stage 4.0 (TID 6). 7395 bytes result sent to driver
Got cleaning task CleanAccum(71)
Cleaning accumulator 71
Cleaned accumulator 71
Got cleaning task CleanAccum(86)
Cleaning accumulator 86
Cleaned accumulator 86
Got cleaning task CleanAccum(105)
Cleaning accumulator 105
Cleaned accumulator 105
Got cleaning task CleanAccum(82)
Cleaning accumulator 82
Cleaned accumulator 82
Got cleaning task CleanAccum(97)
Cleaning accumulator 97
parentName: , name: TaskSet_4.0, runningTasks: 2
Cleaned accumulator 97
Got cleaning task CleanAccum(103)
Cleaning accumulator 103
Cleaned accumulator 103
Got cleaning task CleanAccum(100)
Cleaning accumulator 100
Cleaned accumulator 100
Got cleaning task CleanAccum(109)
Cleaning accumulator 109
Cleaned accumulator 109
Got cleaning task CleanAccum(108)
Cleaning accumulator 108
Cleaned accumulator 108
Got cleaning task CleanAccum(125)
Cleaning accumulator 125
Cleaned accumulator 125
Got cleaning task CleanAccum(116)
Cleaning accumulator 116
Cleaned accumulator 116
Got cleaning task CleanAccum(69)
Cleaning accumulator 69
Cleaned accumulator 69
Got cleaning task CleanAccum(106)
Cleaning accumulator 106
Cleaned accumulator 106
Got cleaning task CleanAccum(127)
Cleaning accumulator 127
Cleaned accumulator 127
Got cleaning task CleanAccum(118)
Cleaning accumulator 118
Cleaned accumulator 118
Got cleaning task CleanAccum(126)
Cleaning accumulator 126
Cleaned accumulator 126
Got cleaning task CleanAccum(99)
parentName: , name: TaskSet_4.0, runningTasks: 1
Cleaning accumulator 99
Cleaned accumulator 99
Got cleaning task CleanAccum(112)
Cleaning accumulator 112
Cleaned accumulator 112
Got cleaning task CleanAccum(95)
Cleaning accumulator 95
Cleaned accumulator 95
Got cleaning task CleanAccum(93)
Cleaning accumulator 93
Cleaned accumulator 93
Got cleaning task CleanAccum(81)
Cleaning accumulator 81
Cleaned accumulator 81
Got cleaning task CleanBroadcast(5)
Cleaning broadcast 5
Unpersisting TorrentBroadcast 5
Finished task 0.0 in stage 4.0 (TID 6) in 172 ms on localhost (executor driver) (1/3)
Finished task 2.0 in stage 4.0 (TID 8) in 171 ms on localhost (executor driver) (2/3)
removing broadcast 5
Removing broadcast 5
Removing block broadcast_5
Block broadcast_5 of size 248760 dropped from memory (free 2083542229)
Removing block broadcast_5_piece0
Block broadcast_5_piece0 of size 20482 dropped from memory (free 2083562711)
Removed broadcast_5_piece0 on 192.168.1.13:10964 in memory (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_5_piece0
Told master about block broadcast_5_piece0
Done removing broadcast 5, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 5
Got cleaning task CleanAccum(92)
Cleaning accumulator 92
Cleaned accumulator 92
Got cleaning task CleanAccum(78)
Cleaning accumulator 78
Cleaned accumulator 78
Got cleaning task CleanAccum(111)
Cleaning accumulator 111
Cleaned accumulator 111
Got cleaning task CleanAccum(83)
Cleaning accumulator 83
Cleaned accumulator 83
Got cleaning task CleanAccum(75)
Cleaning accumulator 75
Cleaned accumulator 75
Got cleaning task CleanAccum(110)
Cleaning accumulator 110
Cleaned accumulator 110
Got cleaning task CleanAccum(73)
Cleaning accumulator 73
Cleaned accumulator 73
Got cleaning task CleanAccum(124)
Cleaning accumulator 124
Cleaned accumulator 124
Got cleaning task CleanAccum(91)
Cleaning accumulator 91
Cleaned accumulator 91
Got cleaning task CleanAccum(117)
Cleaning accumulator 117
Cleaned accumulator 117
Got cleaning task CleanAccum(120)
Cleaning accumulator 120
Cleaned accumulator 120
Got cleaning task CleanShuffle(0)
Cleaning shuffle 0
removing shuffle 0
Cleaned shuffle 0
Got cleaning task CleanAccum(115)
Cleaning accumulator 115
Cleaned accumulator 115
Got cleaning task CleanAccum(102)
Cleaning accumulator 102
Cleaned accumulator 102
Got cleaning task CleanAccum(123)
Cleaning accumulator 123
Cleaned accumulator 123
Got cleaning task CleanAccum(89)
Cleaning accumulator 89
Cleaned accumulator 89
Got cleaning task CleanAccum(68)
Cleaning accumulator 68
Cleaned accumulator 68
Got cleaning task CleanAccum(87)
Cleaning accumulator 87
Cleaned accumulator 87
Got cleaning task CleanAccum(94)
Cleaning accumulator 94
Cleaned accumulator 94
Got cleaning task CleanAccum(80)
Cleaning accumulator 80
Cleaned accumulator 80
Got cleaning task CleanAccum(76)
Cleaning accumulator 76
Cleaned accumulator 76
Got cleaning task CleanAccum(104)
Cleaning accumulator 104
Cleaned accumulator 104
Got cleaning task CleanAccum(85)
Cleaning accumulator 85
Cleaned accumulator 85
Got cleaning task CleanAccum(84)
Cleaning accumulator 84
Cleaned accumulator 84
Got cleaning task CleanAccum(79)
Cleaning accumulator 79
Cleaned accumulator 79
Got cleaning task CleanAccum(122)
Cleaning accumulator 122
Cleaned accumulator 122
Got cleaning task CleanAccum(114)
Cleaning accumulator 114
Cleaned accumulator 114
Got cleaning task CleanAccum(72)
Cleaning accumulator 72
Cleaned accumulator 72
Got cleaning task CleanAccum(113)
Cleaning accumulator 113
Cleaned accumulator 113
Got cleaning task CleanAccum(119)
Cleaning accumulator 119
Cleaned accumulator 119
Got cleaning task CleanAccum(101)
Cleaning accumulator 101
Cleaned accumulator 101
Got cleaning task CleanAccum(67)
Cleaning accumulator 67
Cleaned accumulator 67
Got cleaning task CleanAccum(88)
Cleaning accumulator 88
Cleaned accumulator 88
Got cleaning task CleanBroadcast(7)
Cleaning broadcast 7
Unpersisting TorrentBroadcast 7
removing broadcast 7
Removing broadcast 7
Removing block broadcast_7
Block broadcast_7 of size 132760 dropped from memory (free 2083695471)
Removing block broadcast_7_piece0
Block broadcast_7_piece0 of size 47036 dropped from memory (free 2083742507)
Removed broadcast_7_piece0 on 192.168.1.13:10964 in memory (size: 45.9 KB, free: 1987.5 MB)
Updated info of block broadcast_7_piece0
Told master about block broadcast_7_piece0
Done removing broadcast 7, response is 0
Sent response: 0 to 192.168.1.13:10922
Done removing shuffle 0, response is true
Sent response: true to 192.168.1.13:10922
Cleaned broadcast 7
Got cleaning task CleanAccum(70)
Cleaning accumulator 70
Cleaned accumulator 70
Got cleaning task CleanAccum(121)
Cleaning accumulator 121
Cleaned accumulator 121
Got cleaning task CleanAccum(90)
Cleaning accumulator 90
Cleaned accumulator 90
Got cleaning task CleanAccum(74)
Cleaning accumulator 74
Cleaned accumulator 74
Got cleaning task CleanAccum(96)
Cleaning accumulator 96
Cleaned accumulator 96
Got cleaning task CleanAccum(107)
Cleaning accumulator 107
Cleaned accumulator 107
Got cleaning task CleanAccum(98)
Cleaning accumulator 98
Cleaned accumulator 98
Got cleaning task CleanAccum(77)
Cleaning accumulator 77
Cleaned accumulator 77
Finished task 1.0 in stage 4.0 (TID 7). 7294 bytes result sent to driver
parentName: , name: TaskSet_4.0, runningTasks: 0
Finished task 1.0 in stage 4.0 (TID 7) in 203 ms on localhost (executor driver) (3/3)
Removed TaskSet 4.0, whose tasks have all completed, from pool 
ResultStage 4 (run at ThreadPoolExecutor.java:1149) finished in 0.211 s
After removal of stage 4, remaining stages = 0
Job 3 finished: run at ThreadPoolExecutor.java:1149, took 0.213048 s
Task 0 acquired 32.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@25aaa9b
code for cast(input[1, string, true] as date),input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(1);
/* 032 */     UTF8String value_1 = isNull_1 ?
/* 033 */     null : (i.getUTF8String(1));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     int value_0 = -1;
/* 036 */     if (!isNull_1) {
/* 037 */       scala.Option<Integer> intOpt_0 =
/* 038 */       org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(value_1);
/* 039 */       if (intOpt_0.isDefined()) {
/* 040 */         value_0 = ((Integer) intOpt_0.get()).intValue();
/* 041 */       } else {
/* 042 */         isNull_0 = true;
/* 043 */       }
/* 044 */     }
/* 045 */     if (isNull_0) {
/* 046 */       mutableStateArray_0[0].setNullAt(0);
/* 047 */     } else {
/* 048 */       mutableStateArray_0[0].write(0, value_0);
/* 049 */     }
/* 050 */
/* 051 */     boolean isNull_2 = i.isNullAt(0);
/* 052 */     UTF8String value_2 = isNull_2 ?
/* 053 */     null : (i.getUTF8String(0));
/* 054 */     if (isNull_2) {
/* 055 */       mutableStateArray_0[0].setNullAt(1);
/* 056 */     } else {
/* 057 */       mutableStateArray_0[0].write(1, value_2);
/* 058 */     }
/* 059 */     return (mutableStateArray_0[0].getRow());
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(1);
/* 032 */     UTF8String value_1 = isNull_1 ?
/* 033 */     null : (i.getUTF8String(1));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     int value_0 = -1;
/* 036 */     if (!isNull_1) {
/* 037 */       scala.Option<Integer> intOpt_0 =
/* 038 */       org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(value_1);
/* 039 */       if (intOpt_0.isDefined()) {
/* 040 */         value_0 = ((Integer) intOpt_0.get()).intValue();
/* 041 */       } else {
/* 042 */         isNull_0 = true;
/* 043 */       }
/* 044 */     }
/* 045 */     if (isNull_0) {
/* 046 */       mutableStateArray_0[0].setNullAt(0);
/* 047 */     } else {
/* 048 */       mutableStateArray_0[0].write(0, value_0);
/* 049 */     }
/* 050 */
/* 051 */     boolean isNull_2 = i.isNullAt(0);
/* 052 */     UTF8String value_2 = isNull_2 ?
/* 053 */     null : (i.getUTF8String(0));
/* 054 */     if (isNull_2) {
/* 055 */       mutableStateArray_0[0].setNullAt(1);
/* 056 */     } else {
/* 057 */       mutableStateArray_0[0].write(1, value_2);
/* 058 */     }
/* 059 */     return (mutableStateArray_0[0].getRow());
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

Code generated in 14.774908 ms
Task 0 acquired 8.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@25aaa9b
Task 0 acquired 64.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@25aaa9b
Task 0 release 32.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@25aaa9b
Block broadcast_10 stored as values in memory (estimated size 8.1 MB, free 1979.1 MB)
Put block broadcast_10 locally took  1 ms
Putting block broadcast_10 without replication took  2 ms
Block broadcast_10_piece0 stored as bytes in memory (estimated size 22.7 KB, free 1979.1 MB)
Added broadcast_10_piece0 in memory on 192.168.1.13:10964 (size: 22.7 KB, free: 1987.4 MB)
Updated info of block broadcast_10_piece0
Told master about block broadcast_10_piece0
Put block broadcast_10_piece0 locally took  2 ms
Putting block broadcast_10_piece0 without replication took  2 ms
Created broadcast 10 from run at ThreadPoolExecutor.java:1149
Getting local block broadcast_10
Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 011 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     wholestagecodegen_init_0_0();
/* 021 */     wholestagecodegen_init_0_1();
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   private void wholestagecodegen_init_0_1() {
/* 026 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(5, 160);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   protected void processNext() throws java.io.IOException {
/* 031 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 032 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 033 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 034 */       do {
/* 035 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 036 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 037 */         null : (scan_row_0.getUTF8String(1));
/* 038 */
/* 039 */         if (!(!scan_isNull_1)) continue;
/* 040 */
/* 041 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 042 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 043 */         null : (scan_row_0.getUTF8String(0));
/* 044 */
/* 045 */         if (!(!scan_isNull_0)) continue;
/* 046 */
/* 047 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 048 */
/* 049 */         // generate join key for stream side
/* 050 */         filter_mutableStateArray_0[2].reset();
/* 051 */
/* 052 */         filter_mutableStateArray_0[2].zeroOutNullBytes();
/* 053 */
/* 054 */         boolean bhj_isNull_0 = false;
/* 055 */         int bhj_value_0 = -1;
/* 056 */         if (!false) {
/* 057 */           scala.Option<Integer> bhj_intOpt_0 =
/* 058 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(scan_value_1);
/* 059 */           if (bhj_intOpt_0.isDefined()) {
/* 060 */             bhj_value_0 = ((Integer) bhj_intOpt_0.get()).intValue();
/* 061 */           } else {
/* 062 */             bhj_isNull_0 = true;
/* 063 */           }
/* 064 */         }
/* 065 */         if (bhj_isNull_0) {
/* 066 */           filter_mutableStateArray_0[2].setNullAt(0);
/* 067 */         } else {
/* 068 */           filter_mutableStateArray_0[2].write(0, bhj_value_0);
/* 069 */         }
/* 070 */
/* 071 */         if (false) {
/* 072 */           filter_mutableStateArray_0[2].setNullAt(1);
/* 073 */         } else {
/* 074 */           filter_mutableStateArray_0[2].write(1, scan_value_0);
/* 075 */         }
/* 076 */         // find matches from HashedRelation
/* 077 */         UnsafeRow bhj_matched_0 = (filter_mutableStateArray_0[2].getRow()).anyNull() ? null: (UnsafeRow)bhj_relation_0.getValue((filter_mutableStateArray_0[2].getRow()));
/* 078 */         if (bhj_matched_0 != null) {
/* 079 */           {
/* 080 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 081 */
/* 082 */             boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 083 */             UTF8String scan_value_2 = scan_isNull_2 ?
/* 084 */             null : (scan_row_0.getUTF8String(2));
/* 085 */             boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 086 */             UTF8String scan_value_3 = scan_isNull_3 ?
/* 087 */             null : (scan_row_0.getUTF8String(3));
/* 088 */             boolean project_isNull_12 = true;
/* 089 */             UTF8String project_value_12 = null;
/* 090 */             boolean bhj_isNull_5 = bhj_matched_0.isNullAt(2);
/* 091 */             UTF8String bhj_value_5 = bhj_isNull_5 ?
/* 092 */             null : (bhj_matched_0.getUTF8String(2));
/* 093 */             if (!bhj_isNull_5) {
/* 094 */               project_isNull_12 = false; // resultCode could change nullability.
/* 095 */               project_value_12 = bhj_value_5.replace(((UTF8String) references[5] /* literal */), ((UTF8String) references[6] /* literal */));
/* 096 */
/* 097 */             }
/* 098 */             filter_mutableStateArray_0[4].reset();
/* 099 */
/* 100 */             filter_mutableStateArray_0[4].zeroOutNullBytes();
/* 101 */
/* 102 */             if (false) {
/* 103 */               filter_mutableStateArray_0[4].setNullAt(0);
/* 104 */             } else {
/* 105 */               filter_mutableStateArray_0[4].write(0, scan_value_0);
/* 106 */             }
/* 107 */
/* 108 */             if (false) {
/* 109 */               filter_mutableStateArray_0[4].setNullAt(1);
/* 110 */             } else {
/* 111 */               filter_mutableStateArray_0[4].write(1, scan_value_1);
/* 112 */             }
/* 113 */
/* 114 */             if (scan_isNull_2) {
/* 115 */               filter_mutableStateArray_0[4].setNullAt(2);
/* 116 */             } else {
/* 117 */               filter_mutableStateArray_0[4].write(2, scan_value_2);
/* 118 */             }
/* 119 */
/* 120 */             if (scan_isNull_3) {
/* 121 */               filter_mutableStateArray_0[4].setNullAt(3);
/* 122 */             } else {
/* 123 */               filter_mutableStateArray_0[4].write(3, scan_value_3);
/* 124 */             }
/* 125 */
/* 126 */             if (project_isNull_12) {
/* 127 */               filter_mutableStateArray_0[4].setNullAt(4);
/* 128 */             } else {
/* 129 */               filter_mutableStateArray_0[4].write(4, project_value_12);
/* 130 */             }
/* 131 */             append((filter_mutableStateArray_0[4].getRow()));
/* 132 */
/* 133 */           }
/* 134 */         }
/* 135 */
/* 136 */       } while(false);
/* 137 */       if (shouldStop()) return;
/* 138 */     }
/* 139 */   }
/* 140 */
/* 141 */   private void wholestagecodegen_init_0_0() {
/* 142 */     scan_mutableStateArray_0[0] = inputs[0];
/* 143 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 144 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 145 */
/* 146 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[2] /* broadcast */).value()).asReadOnlyCopy();
/* 147 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 148 */
/* 149 */     org.apache.spark.TaskContext$.MODULE$.get().addTaskCompletionListener(new org.apache.spark.util.TaskCompletionListener() {
/* 150 */         @Override
/* 151 */         public void onTaskCompletion(org.apache.spark.TaskContext context) {
/* 152 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */).set(bhj_relation_0.getAverageProbesPerLookup());
/* 153 */         }
/* 154 */       });
/* 155 */
/* 156 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 157 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 158 */
/* 159 */   }
/* 160 */
/* 161 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 011 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     wholestagecodegen_init_0_0();
/* 021 */     wholestagecodegen_init_0_1();
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   private void wholestagecodegen_init_0_1() {
/* 026 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(5, 160);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   protected void processNext() throws java.io.IOException {
/* 031 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 032 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 033 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 034 */       do {
/* 035 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 036 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 037 */         null : (scan_row_0.getUTF8String(1));
/* 038 */
/* 039 */         if (!(!scan_isNull_1)) continue;
/* 040 */
/* 041 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 042 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 043 */         null : (scan_row_0.getUTF8String(0));
/* 044 */
/* 045 */         if (!(!scan_isNull_0)) continue;
/* 046 */
/* 047 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 048 */
/* 049 */         // generate join key for stream side
/* 050 */         filter_mutableStateArray_0[2].reset();
/* 051 */
/* 052 */         filter_mutableStateArray_0[2].zeroOutNullBytes();
/* 053 */
/* 054 */         boolean bhj_isNull_0 = false;
/* 055 */         int bhj_value_0 = -1;
/* 056 */         if (!false) {
/* 057 */           scala.Option<Integer> bhj_intOpt_0 =
/* 058 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(scan_value_1);
/* 059 */           if (bhj_intOpt_0.isDefined()) {
/* 060 */             bhj_value_0 = ((Integer) bhj_intOpt_0.get()).intValue();
/* 061 */           } else {
/* 062 */             bhj_isNull_0 = true;
/* 063 */           }
/* 064 */         }
/* 065 */         if (bhj_isNull_0) {
/* 066 */           filter_mutableStateArray_0[2].setNullAt(0);
/* 067 */         } else {
/* 068 */           filter_mutableStateArray_0[2].write(0, bhj_value_0);
/* 069 */         }
/* 070 */
/* 071 */         if (false) {
/* 072 */           filter_mutableStateArray_0[2].setNullAt(1);
/* 073 */         } else {
/* 074 */           filter_mutableStateArray_0[2].write(1, scan_value_0);
/* 075 */         }
/* 076 */         // find matches from HashedRelation
/* 077 */         UnsafeRow bhj_matched_0 = (filter_mutableStateArray_0[2].getRow()).anyNull() ? null: (UnsafeRow)bhj_relation_0.getValue((filter_mutableStateArray_0[2].getRow()));
/* 078 */         if (bhj_matched_0 != null) {
/* 079 */           {
/* 080 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 081 */
/* 082 */             boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 083 */             UTF8String scan_value_2 = scan_isNull_2 ?
/* 084 */             null : (scan_row_0.getUTF8String(2));
/* 085 */             boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 086 */             UTF8String scan_value_3 = scan_isNull_3 ?
/* 087 */             null : (scan_row_0.getUTF8String(3));
/* 088 */             boolean project_isNull_12 = true;
/* 089 */             UTF8String project_value_12 = null;
/* 090 */             boolean bhj_isNull_5 = bhj_matched_0.isNullAt(2);
/* 091 */             UTF8String bhj_value_5 = bhj_isNull_5 ?
/* 092 */             null : (bhj_matched_0.getUTF8String(2));
/* 093 */             if (!bhj_isNull_5) {
/* 094 */               project_isNull_12 = false; // resultCode could change nullability.
/* 095 */               project_value_12 = bhj_value_5.replace(((UTF8String) references[5] /* literal */), ((UTF8String) references[6] /* literal */));
/* 096 */
/* 097 */             }
/* 098 */             filter_mutableStateArray_0[4].reset();
/* 099 */
/* 100 */             filter_mutableStateArray_0[4].zeroOutNullBytes();
/* 101 */
/* 102 */             if (false) {
/* 103 */               filter_mutableStateArray_0[4].setNullAt(0);
/* 104 */             } else {
/* 105 */               filter_mutableStateArray_0[4].write(0, scan_value_0);
/* 106 */             }
/* 107 */
/* 108 */             if (false) {
/* 109 */               filter_mutableStateArray_0[4].setNullAt(1);
/* 110 */             } else {
/* 111 */               filter_mutableStateArray_0[4].write(1, scan_value_1);
/* 112 */             }
/* 113 */
/* 114 */             if (scan_isNull_2) {
/* 115 */               filter_mutableStateArray_0[4].setNullAt(2);
/* 116 */             } else {
/* 117 */               filter_mutableStateArray_0[4].write(2, scan_value_2);
/* 118 */             }
/* 119 */
/* 120 */             if (scan_isNull_3) {
/* 121 */               filter_mutableStateArray_0[4].setNullAt(3);
/* 122 */             } else {
/* 123 */               filter_mutableStateArray_0[4].write(3, scan_value_3);
/* 124 */             }
/* 125 */
/* 126 */             if (project_isNull_12) {
/* 127 */               filter_mutableStateArray_0[4].setNullAt(4);
/* 128 */             } else {
/* 129 */               filter_mutableStateArray_0[4].write(4, project_value_12);
/* 130 */             }
/* 131 */             append((filter_mutableStateArray_0[4].getRow()));
/* 132 */
/* 133 */           }
/* 134 */         }
/* 135 */
/* 136 */       } while(false);
/* 137 */       if (shouldStop()) return;
/* 138 */     }
/* 139 */   }
/* 140 */
/* 141 */   private void wholestagecodegen_init_0_0() {
/* 142 */     scan_mutableStateArray_0[0] = inputs[0];
/* 143 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 144 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 145 */
/* 146 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[2] /* broadcast */).value()).asReadOnlyCopy();
/* 147 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 148 */
/* 149 */     org.apache.spark.TaskContext$.MODULE$.get().addTaskCompletionListener(new org.apache.spark.util.TaskCompletionListener() {
/* 150 */         @Override
/* 151 */         public void onTaskCompletion(org.apache.spark.TaskContext context) {
/* 152 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */).set(bhj_relation_0.getAverageProbesPerLookup());
/* 153 */         }
/* 154 */       });
/* 155 */
/* 156 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 157 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 158 */
/* 159 */   }
/* 160 */
/* 161 */ }

Code generated in 26.706557 ms
Block broadcast_11 stored as values in memory (estimated size 242.9 KB, free 1978.9 MB)
Put block broadcast_11 locally took  2 ms
Putting block broadcast_11 without replication took  2 ms
Block broadcast_11_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1978.9 MB)
Added broadcast_11_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_11_piece0
Told master about block broadcast_11_piece0
Put block broadcast_11_piece0 locally took  2 ms
Putting block broadcast_11_piece0 without replication took  2 ms
Created broadcast 11 from show at Run.scala:66
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$1
 +++ Lambda closure ($anonfun$executeTake$1) is now cleaned +++
Cleaning lambda: $anonfun$executeTake$2
 +++ Lambda closure ($anonfun$executeTake$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: show at Run.scala:66
Got job 4 (show at Run.scala:66) with 1 output partitions
Final stage: ResultStage 5 (show at Run.scala:66)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 5)
missing: List()
Submitting ResultStage 5 (MapPartitionsRDD[24] at show at Run.scala:66), which has no missing parents
submitMissingTasks(ResultStage 5)
Block broadcast_12 stored as values in memory (estimated size 17.6 KB, free 1978.9 MB)
Put block broadcast_12 locally took  1 ms
Putting block broadcast_12 without replication took  1 ms
Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.8 KB, free 1978.8 MB)
Added broadcast_12_piece0 in memory on 192.168.1.13:10964 (size: 8.8 KB, free: 1987.4 MB)
Updated info of block broadcast_12_piece0
Told master about block broadcast_12_piece0
Put block broadcast_12_piece0 locally took  1 ms
Putting block broadcast_12_piece0 without replication took  1 ms
Created broadcast 12 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at show at Run.scala:66) (first 15 tasks are for partitions Vector(0))
Adding task set 5.0 with 1 tasks
Epoch for TaskSet 5.0: 1
Valid locality levels for TaskSet 5.0: NO_PREF, ANY
parentName: , name: TaskSet_5.0, runningTasks: 0
Starting task 0.0 in stage 5.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 5.0 (TID 9)
Getting local block broadcast_12
Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_11
Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
Finished task 0.0 in stage 5.0 (TID 9). 1848 bytes result sent to driver
parentName: , name: TaskSet_5.0, runningTasks: 0
Finished task 0.0 in stage 5.0 (TID 9) in 23 ms on localhost (executor driver) (1/1)
Removed TaskSet 5.0, whose tasks have all completed, from pool 
ResultStage 5 (show at Run.scala:66) finished in 0.029 s
After removal of stage 5, remaining stages = 0
Job 4 finished: show at Run.scala:66, took 0.031636 s
Writing CSV files at src/main/resources/verify with saveMode=Overwrite

=== Result of Batch Finish Analysis ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                                                                                                                                                                       InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                                    +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                                  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
!      +- Join Inner, ((to_date(monthday#11, None) = to_date(local_time#22, None)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                               +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- SubqueryAlias `bs`                                                                                                                                                                                                                                                                                                                                                                                                                     :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         :  +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                                           +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]
!         :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                             +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]
!         +- SubqueryAlias `em`                                                                                                                                                                                                                                                                                                                                                                                                                           +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- SubqueryAlias `emulated`                                                                                                                                                                                                                                                                                                                                                                                                   
!               +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]   
!                  +- SubqueryAlias `outtab`                                                                                                                                                                                                                                                                                                                                                                                               
!                     +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                        
!                        +- SubqueryAlias `bomstatis`                                                                                                                                                                                                                                                                                                                                                                                      
!                           +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                     
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                                                                                                                                                                 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                                                                                                                                                              +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                                                                                                                                                            +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                                                                                                                                                           +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                          :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         +- Project [split(station#27, [|])[0] AS location#20, split(station#27, [|])[1] AS position#21, whole_time#28 AS local_time#22, if ((isnull(cast(replace(temprature#29, +, ) as double)) || isnull(cast(humidy#31 as int)))) null else UDF(cast(replace(temprature#29, +, ) as double), cast(humidy#31 as int)) AS conditions#23, temprature#29 AS temperature#24, pressure#30 AS pressure#25, humidy#31 AS humidity#26]            :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Project [UDF(location#10) AS station#27, UDF(monthday#11, location#10) AS whole_time#28, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temprature#29, UDF() AS pressure#30, UDF() AS humidy#31]                                                                                                                    +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                                                                                                                                                       +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Infer Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                             InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                          +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                        +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :- Filter (isnotnull(monthday#11) && isnotnull(location#10))
!         :  +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]            :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!            +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   +- Filter (isnotnull(local_time#22) && isnotnull(location#20))
!                                                                                                                                                                                                                                                                                                            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!                                                                                                                                                                                                                                                                                                               +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          

=== Result of Batch Operator Optimization after Inferring Filters ===
 InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]                                                InsertIntoHadoopFsRelationCommand file:/D:/p1/weather-simulator/src/main/resources/verify, false, CSV, Map(delimiter -> |, emptyValue -> , quote -> , path -> src/main/resources/verify), Overwrite, [location, monthday, maxtemp, mintemp, tempra]
 +- Repartition 1, true                                                                                                                                                                                                                                                                             +- Repartition 1, true
    +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]                                                                                                                                                                                           +- Project [location#10, monthday#11, maxtemp#12, mintemp#13, replace(temperature#24, +, ) AS tempra#76]
       +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))                                                                                                                                                                                          +- Join Inner, ((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20))
!         :- Filter (isnotnull(monthday#11) && isnotnull(location#10))                                                                                                                                                                                                                                       :- Project [location#10, monthday#11, maxtemp#12, mintemp#13]
!         :  +- Project [location#10, monthday#11, maxtemp#12, mintemp#13]                                                                                                                                                                                                                                   :  +- Filter (isnotnull(monthday#11) && isnotnull(location#10))
          :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                   :     +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
!         +- Filter (isnotnull(local_time#22) && isnotnull(location#20))                                                                                                                                                                                                                                     +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]
!            +- Project [split(UDF(location#10), [|])[0] AS location#20, UDF(monthday#11, location#10) AS local_time#22, if ((isnull(cast(mintemp#13 as double)) || isnull(cast(maxtemp#12 as double)))) null else UDF(cast(mintemp#13 as double), cast(maxtemp#12 as double)) AS temperature#24]               +- Filter (isnotnull(UDF(monthday#11, location#10)) && isnotnull(split(UDF(location#10), [|])[0]))
                +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv                                                                                                                                                                                                                         +- Relation[location#10,monthday#11,maxtemp#12,mintemp#13,rainfall#14] csv
          
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Considering join on: Some(((cast(monthday#11 as date) = cast(local_time#22 as date)) && (location#10 = location#20)))
leftKeys:List(cast(monthday#11 as date), location#10) | rightKeys:List(cast(local_time#22 as date), location#20)
Pruning directories with: 
Post-Scan Filters: isnotnull(monthday#11),isnotnull(location#10)
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: IsNotNull(monthday),IsNotNull(location)
Pruning directories with: 
Post-Scan Filters: isnotnull(UDF(monthday#11, location#10)),isnotnull(split(UDF(location#10), [|])[0])
Output Data Schema: struct<location: string, monthday: string, maxtemp: string, mintemp: string ... 2 more fields>
Pushed Filters: 
Creating committer org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol; job d26247f7-eeb2-498b-9442-abadc3a119e9; output=file:/D:/p1/weather-simulator/src/main/resources/verify; dynamic=false
Using (String, String, Boolean) constructor
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 96);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 032 */         null : (scan_row_0.getUTF8String(0));
/* 033 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 034 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 035 */         null : (scan_row_0.getUTF8String(1));
/* 036 */
/* 037 */         Object filter_arg_0 = scan_isNull_1 ? null : ((scala.Function1[]) references[2] /* converters */)[0].apply(scan_value_1);
/* 038 */         Object filter_arg_1 = scan_isNull_0 ? null : ((scala.Function1[]) references[2] /* converters */)[1].apply(scan_value_0);
/* 039 */
/* 040 */         UTF8String filter_result_0 = null;
/* 041 */         try {
/* 042 */           filter_result_0 = (UTF8String)((scala.Function1[]) references[2] /* converters */)[2].apply(((scala.Function2) references[4] /* udf */).apply(filter_arg_0, filter_arg_1));
/* 043 */         } catch (Exception e) {
/* 044 */           throw new org.apache.spark.SparkException(((java.lang.String) references[3] /* errMsg */), e);
/* 045 */         }
/* 046 */
/* 047 */         boolean filter_isNull_1 = filter_result_0 == null;
/* 048 */         UTF8String filter_value_1 = null;
/* 049 */         if (!filter_isNull_1) {
/* 050 */           filter_value_1 = filter_result_0;
/* 051 */         }
/* 052 */         if (!(!filter_isNull_1)) continue;
/* 053 */         boolean filter_isNull_5 = true;
/* 054 */         UTF8String filter_value_5 = null;
/* 055 */         boolean filter_isNull_6 = true;
/* 056 */         ArrayData filter_value_6 = null;
/* 057 */         Object filter_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[5] /* converters */)[0].apply(scan_value_0);
/* 058 */
/* 059 */         UTF8String filter_result_1 = null;
/* 060 */         try {
/* 061 */           filter_result_1 = (UTF8String)((scala.Function1[]) references[5] /* converters */)[1].apply(((scala.Function1) references[7] /* udf */).apply(filter_arg_2));
/* 062 */         } catch (Exception e) {
/* 063 */           throw new org.apache.spark.SparkException(((java.lang.String) references[6] /* errMsg */), e);
/* 064 */         }
/* 065 */
/* 066 */         boolean filter_isNull_7 = filter_result_1 == null;
/* 067 */         UTF8String filter_value_7 = null;
/* 068 */         if (!filter_isNull_7) {
/* 069 */           filter_value_7 = filter_result_1;
/* 070 */         }
/* 071 */         if (!filter_isNull_7) {
/* 072 */           filter_isNull_6 = false; // resultCode could change nullability.
/* 073 */           filter_value_6 = new org.apache.spark.sql.catalyst.util.GenericArrayData(filter_value_7.split(((UTF8String) references[8] /* literal */), -1));
/* 074 */
/* 075 */         }
/* 076 */         if (!filter_isNull_6) {
/* 077 */           filter_isNull_5 = false; // resultCode could change nullability.
/* 078 */
/* 079 */           final int filter_index_0 = (int) 0;
/* 080 */           if (filter_index_0 >= filter_value_6.numElements() || filter_index_0 < 0 || filter_value_6.isNullAt(filter_index_0)) {
/* 081 */             filter_isNull_5 = true;
/* 082 */           } else {
/* 083 */             filter_value_5 = filter_value_6.getUTF8String(filter_index_0);
/* 084 */           }
/* 085 */
/* 086 */         }
/* 087 */         if (!(!filter_isNull_5)) continue;
/* 088 */
/* 089 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 090 */
/* 091 */         boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 092 */         UTF8String scan_value_2 = scan_isNull_2 ?
/* 093 */         null : (scan_row_0.getUTF8String(2));
/* 094 */         boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 095 */         UTF8String scan_value_3 = scan_isNull_3 ?
/* 096 */         null : (scan_row_0.getUTF8String(3));
/* 097 */
/* 098 */         boolean project_isNull_0 = true;
/* 099 */         UTF8String project_value_0 = null;
/* 100 */         boolean project_isNull_1 = true;
/* 101 */         ArrayData project_value_1 = null;
/* 102 */         Object project_arg_0 = scan_isNull_0 ? null : ((scala.Function1[]) references[9] /* converters */)[0].apply(scan_value_0);
/* 103 */
/* 104 */         UTF8String project_result_0 = null;
/* 105 */         try {
/* 106 */           project_result_0 = (UTF8String)((scala.Function1[]) references[9] /* converters */)[1].apply(((scala.Function1) references[11] /* udf */).apply(project_arg_0));
/* 107 */         } catch (Exception e) {
/* 108 */           throw new org.apache.spark.SparkException(((java.lang.String) references[10] /* errMsg */), e);
/* 109 */         }
/* 110 */
/* 111 */         boolean project_isNull_2 = project_result_0 == null;
/* 112 */         UTF8String project_value_2 = null;
/* 113 */         if (!project_isNull_2) {
/* 114 */           project_value_2 = project_result_0;
/* 115 */         }
/* 116 */         if (!project_isNull_2) {
/* 117 */           project_isNull_1 = false; // resultCode could change nullability.
/* 118 */           project_value_1 = new org.apache.spark.sql.catalyst.util.GenericArrayData(project_value_2.split(((UTF8String) references[12] /* literal */), -1));
/* 119 */
/* 120 */         }
/* 121 */         if (!project_isNull_1) {
/* 122 */           project_isNull_0 = false; // resultCode could change nullability.
/* 123 */
/* 124 */           final int project_index_0 = (int) 0;
/* 125 */           if (project_index_0 >= project_value_1.numElements() || project_index_0 < 0 || project_value_1.isNullAt(project_index_0)) {
/* 126 */             project_isNull_0 = true;
/* 127 */           } else {
/* 128 */             project_value_0 = project_value_1.getUTF8String(project_index_0);
/* 129 */           }
/* 130 */
/* 131 */         }
/* 132 */         Object project_arg_1 = scan_isNull_1 ? null : ((scala.Function1[]) references[13] /* converters */)[0].apply(scan_value_1);
/* 133 */         Object project_arg_2 = scan_isNull_0 ? null : ((scala.Function1[]) references[13] /* converters */)[1].apply(scan_value_0);
/* 134 */
/* 135 */         UTF8String project_result_1 = null;
/* 136 */         try {
/* 137 */           project_result_1 = (UTF8String)((scala.Function1[]) references[13] /* converters */)[2].apply(((scala.Function2) references[15] /* udf */).apply(project_arg_1, project_arg_2));
/* 138 */         } catch (Exception e) {
/* 139 */           throw new org.apache.spark.SparkException(((java.lang.String) references[14] /* errMsg */), e);
/* 140 */         }
/* 141 */
/* 142 */         boolean project_isNull_6 = project_result_1 == null;
/* 143 */         UTF8String project_value_6 = null;
/* 144 */         if (!project_isNull_6) {
/* 145 */           project_value_6 = project_result_1;
/* 146 */         }
/* 147 */         boolean project_isNull_12 = scan_isNull_3;
/* 148 */         double project_value_12 = -1.0;
/* 149 */         if (!scan_isNull_3) {
/* 150 */           try {
/* 151 */             project_value_12 = Double.valueOf(scan_value_3.toString());
/* 152 */           } catch (java.lang.NumberFormatException e) {
/* 153 */             project_isNull_12 = true;
/* 154 */           }
/* 155 */         }
/* 156 */         boolean project_value_10 = true;
/* 157 */
/* 158 */         if (!project_isNull_12) {
/* 159 */           boolean project_isNull_15 = scan_isNull_2;
/* 160 */           double project_value_15 = -1.0;
/* 161 */           if (!scan_isNull_2) {
/* 162 */             try {
/* 163 */               project_value_15 = Double.valueOf(scan_value_2.toString());
/* 164 */             } catch (java.lang.NumberFormatException e) {
/* 165 */               project_isNull_15 = true;
/* 166 */             }
/* 167 */           }
/* 168 */           project_value_10 = project_isNull_15;
/* 169 */         }
/* 170 */         boolean project_isNull_9 = false;
/* 171 */         UTF8String project_value_9 = null;
/* 172 */         if (!false && project_value_10) {
/* 173 */           project_isNull_9 = true;
/* 174 */           project_value_9 = ((UTF8String)null);
/* 175 */         } else {
/* 176 */           boolean project_isNull_19 = scan_isNull_3;
/* 177 */           double project_value_19 = -1.0;
/* 178 */           if (!scan_isNull_3) {
/* 179 */             try {
/* 180 */               project_value_19 = Double.valueOf(scan_value_3.toString());
/* 181 */             } catch (java.lang.NumberFormatException e) {
/* 182 */               project_isNull_19 = true;
/* 183 */             }
/* 184 */           }
/* 185 */           boolean project_isNull_21 = scan_isNull_2;
/* 186 */           double project_value_21 = -1.0;
/* 187 */           if (!scan_isNull_2) {
/* 188 */             try {
/* 189 */               project_value_21 = Double.valueOf(scan_value_2.toString());
/* 190 */             } catch (java.lang.NumberFormatException e) {
/* 191 */               project_isNull_21 = true;
/* 192 */             }
/* 193 */           }
/* 194 */           Object project_arg_3 = project_isNull_19 ? null : ((scala.Function1[]) references[16] /* converters */)[0].apply(project_value_19);
/* 195 */           Object project_arg_4 = project_isNull_21 ? null : ((scala.Function1[]) references[16] /* converters */)[1].apply(project_value_21);
/* 196 */
/* 197 */           UTF8String project_result_2 = null;
/* 198 */           try {
/* 199 */             project_result_2 = (UTF8String)((scala.Function1[]) references[16] /* converters */)[2].apply(((scala.Function2) references[18] /* udf */).apply(project_arg_3, project_arg_4));
/* 200 */           } catch (Exception e) {
/* 201 */             throw new org.apache.spark.SparkException(((java.lang.String) references[17] /* errMsg */), e);
/* 202 */           }
/* 203 */
/* 204 */           boolean project_isNull_18 = project_result_2 == null;
/* 205 */           UTF8String project_value_18 = null;
/* 206 */           if (!project_isNull_18) {
/* 207 */             project_value_18 = project_result_2;
/* 208 */           }
/* 209 */           project_isNull_9 = project_isNull_18;
/* 210 */           project_value_9 = project_value_18;
/* 211 */         }
/* 212 */         filter_mutableStateArray_0[1].reset();
/* 213 */
/* 214 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 215 */
/* 216 */         if (project_isNull_0) {
/* 217 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 218 */         } else {
/* 219 */           filter_mutableStateArray_0[1].write(0, project_value_0);
/* 220 */         }
/* 221 */
/* 222 */         if (project_isNull_6) {
/* 223 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 224 */         } else {
/* 225 */           filter_mutableStateArray_0[1].write(1, project_value_6);
/* 226 */         }
/* 227 */
/* 228 */         if (project_isNull_9) {
/* 229 */           filter_mutableStateArray_0[1].setNullAt(2);
/* 230 */         } else {
/* 231 */           filter_mutableStateArray_0[1].write(2, project_value_9);
/* 232 */         }
/* 233 */         append((filter_mutableStateArray_0[1].getRow()));
/* 234 */
/* 235 */       } while(false);
/* 236 */       if (shouldStop()) return;
/* 237 */     }
/* 238 */   }
/* 239 */
/* 240 */ }

Block broadcast_13 stored as values in memory (estimated size 242.9 KB, free 1978.6 MB)
Put block broadcast_13 locally took  4 ms
Putting block broadcast_13 without replication took  4 ms
Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1978.6 MB)
Added broadcast_13_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_13_piece0
Told master about block broadcast_13_piece0
Put block broadcast_13_piece0 locally took  1 ms
Putting block broadcast_13_piece0 without replication took  2 ms
Created broadcast 13 from run at ThreadPoolExecutor.java:1149
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$collect$2
 +++ Lambda closure ($anonfun$collect$2) is now cleaned +++
Cleaning lambda: $anonfun$runJob$5
 +++ Lambda closure ($anonfun$runJob$5) is now cleaned +++
Starting job: run at ThreadPoolExecutor.java:1149
Got job 5 (run at ThreadPoolExecutor.java:1149) with 3 output partitions
Final stage: ResultStage 6 (run at ThreadPoolExecutor.java:1149)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 6)
missing: List()
Submitting ResultStage 6 (MapPartitionsRDD[27] at run at ThreadPoolExecutor.java:1149), which has no missing parents
submitMissingTasks(ResultStage 6)
Block broadcast_14 stored as values in memory (estimated size 22.5 KB, free 1978.6 MB)
Put block broadcast_14 locally took  1 ms
Putting block broadcast_14 without replication took  1 ms
Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.8 KB, free 1978.6 MB)
Added broadcast_14_piece0 in memory on 192.168.1.13:10964 (size: 9.8 KB, free: 1987.4 MB)
Updated info of block broadcast_14_piece0
Told master about block broadcast_14_piece0
Put block broadcast_14_piece0 locally took  1 ms
Putting block broadcast_14_piece0 without replication took  1 ms
Created broadcast 14 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 6.0 with 3 tasks
Epoch for TaskSet 6.0: 1
Valid locality levels for TaskSet 6.0: NO_PREF, ANY
parentName: , name: TaskSet_6.0, runningTasks: 0
Starting task 0.0 in stage 6.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7831 bytes)
Starting task 1.0 in stage 6.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 7830 bytes)
Starting task 2.0 in stage 6.0 (TID 12, localhost, executor driver, partition 2, PROCESS_LOCAL, 7828 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 2.0 in stage 6.0 (TID 12)
Running task 0.0 in stage 6.0 (TID 10)
Running task 1.0 in stage 6.0 (TID 11)
Getting local block broadcast_14
Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_13
Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Got cleaning task CleanAccum(187)
Cleaning accumulator 187
Cleaned accumulator 187
Got cleaning task CleanAccum(195)
Cleaning accumulator 195
Cleaned accumulator 195
Got cleaning task CleanAccum(173)
Cleaning accumulator 173
Cleaned accumulator 173
Got cleaning task CleanAccum(172)
Cleaning accumulator 172
Cleaned accumulator 172
Got cleaning task CleanAccum(198)
Cleaning accumulator 198
Cleaned accumulator 198
Got cleaning task CleanAccum(196)
Cleaning accumulator 196
Cleaned accumulator 196
Got cleaning task CleanAccum(177)
Cleaning accumulator 177
Cleaned accumulator 177
Got cleaning task CleanAccum(180)
Cleaning accumulator 180
Cleaned accumulator 180
Got cleaning task CleanAccum(181)
Cleaning accumulator 181
Cleaned accumulator 181
Got cleaning task CleanAccum(186)
Cleaning accumulator 186
Cleaned accumulator 186
Got cleaning task CleanAccum(178)
Cleaning accumulator 178
Cleaned accumulator 178
Got cleaning task CleanAccum(185)
Cleaning accumulator 185
Cleaned accumulator 185
Got cleaning task CleanBroadcast(12)
Cleaning broadcast 12
Unpersisting TorrentBroadcast 12
removing broadcast 12
Removing broadcast 12
Removing block broadcast_12_piece0
Block broadcast_12_piece0 of size 8993 dropped from memory (free 2074675557)
Removed broadcast_12_piece0 on 192.168.1.13:10964 in memory (size: 8.8 KB, free: 1987.4 MB)
Updated info of block broadcast_12_piece0
Told master about block broadcast_12_piece0
Removing block broadcast_12
Block broadcast_12 of size 17976 dropped from memory (free 2074693533)
Finished task 2.0 in stage 6.0 (TID 12). 7130 bytes result sent to driver
parentName: , name: TaskSet_6.0, runningTasks: 2
Finished task 2.0 in stage 6.0 (TID 12) in 93 ms on localhost (executor driver) (1/3)
Done removing broadcast 12, response is 0
Sent response: 0 to 192.168.1.13:10922
Cleaned broadcast 12
Got cleaning task CleanAccum(194)
Cleaning accumulator 194
Cleaned accumulator 194
Got cleaning task CleanAccum(193)
Cleaning accumulator 193
Cleaned accumulator 193
Got cleaning task CleanAccum(184)
Cleaning accumulator 184
Cleaned accumulator 184
Got cleaning task CleanAccum(192)
Cleaning accumulator 192
Cleaned accumulator 192
Got cleaning task CleanAccum(175)
Cleaning accumulator 175
Cleaned accumulator 175
Got cleaning task CleanAccum(183)
Cleaning accumulator 183
Cleaned accumulator 183
Got cleaning task CleanAccum(190)
Cleaning accumulator 190
Cleaned accumulator 190
Got cleaning task CleanAccum(189)
Cleaning accumulator 189
Cleaned accumulator 189
Got cleaning task CleanAccum(176)
Cleaning accumulator 176
Cleaned accumulator 176
Got cleaning task CleanAccum(174)
Cleaning accumulator 174
Cleaned accumulator 174
Got cleaning task CleanAccum(188)
Cleaning accumulator 188
Cleaned accumulator 188
Got cleaning task CleanAccum(191)
Cleaning accumulator 191
Cleaned accumulator 191
Got cleaning task CleanAccum(171)
Cleaning accumulator 171
Cleaned accumulator 171
Got cleaning task CleanAccum(182)
Cleaning accumulator 182
Cleaned accumulator 182
Got cleaning task CleanAccum(179)
Cleaning accumulator 179
Cleaned accumulator 179
Finished task 1.0 in stage 6.0 (TID 11). 7243 bytes result sent to driver
parentName: , name: TaskSet_6.0, runningTasks: 1
Finished task 1.0 in stage 6.0 (TID 11) in 118 ms on localhost (executor driver) (2/3)
Finished task 0.0 in stage 6.0 (TID 10). 7272 bytes result sent to driver
parentName: , name: TaskSet_6.0, runningTasks: 0
Finished task 0.0 in stage 6.0 (TID 10) in 121 ms on localhost (executor driver) (3/3)
Removed TaskSet 6.0, whose tasks have all completed, from pool 
ResultStage 6 (run at ThreadPoolExecutor.java:1149) finished in 0.127 s
After removal of stage 6, remaining stages = 0
Job 5 finished: run at ThreadPoolExecutor.java:1149, took 0.129780 s
Task 0 acquired 32.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4763f729
code for cast(input[1, string, true] as date),input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(1);
/* 032 */     UTF8String value_1 = isNull_1 ?
/* 033 */     null : (i.getUTF8String(1));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     int value_0 = -1;
/* 036 */     if (!isNull_1) {
/* 037 */       scala.Option<Integer> intOpt_0 =
/* 038 */       org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(value_1);
/* 039 */       if (intOpt_0.isDefined()) {
/* 040 */         value_0 = ((Integer) intOpt_0.get()).intValue();
/* 041 */       } else {
/* 042 */         isNull_0 = true;
/* 043 */       }
/* 044 */     }
/* 045 */     if (isNull_0) {
/* 046 */       mutableStateArray_0[0].setNullAt(0);
/* 047 */     } else {
/* 048 */       mutableStateArray_0[0].write(0, value_0);
/* 049 */     }
/* 050 */
/* 051 */     boolean isNull_2 = i.isNullAt(0);
/* 052 */     UTF8String value_2 = isNull_2 ?
/* 053 */     null : (i.getUTF8String(0));
/* 054 */     if (isNull_2) {
/* 055 */       mutableStateArray_0[0].setNullAt(1);
/* 056 */     } else {
/* 057 */       mutableStateArray_0[0].write(1, value_2);
/* 058 */     }
/* 059 */     return (mutableStateArray_0[0].getRow());
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

Task 0 acquired 8.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@4763f729
Task 0 acquired 64.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4763f729
Task 0 release 32.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4763f729
Block broadcast_15 stored as values in memory (estimated size 8.1 MB, free 1970.5 MB)
Put block broadcast_15 locally took  1 ms
Putting block broadcast_15 without replication took  1 ms
Block broadcast_15_piece0 stored as bytes in memory (estimated size 22.5 KB, free 1970.5 MB)
Added broadcast_15_piece0 in memory on 192.168.1.13:10964 (size: 22.5 KB, free: 1987.4 MB)
Updated info of block broadcast_15_piece0
Told master about block broadcast_15_piece0
Put block broadcast_15_piece0 locally took  1 ms
Putting block broadcast_15_piece0 without replication took  1 ms
Created broadcast 15 from run at ThreadPoolExecutor.java:1149
Getting local block broadcast_15
Level for block broadcast_15 is StorageLevel(disk, memory, deserialized, 1 replicas)

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[5];
/* 011 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     wholestagecodegen_init_0_0();
/* 021 */     wholestagecodegen_init_0_1();
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   private void wholestagecodegen_init_0_1() {
/* 026 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(5, 160);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   protected void processNext() throws java.io.IOException {
/* 031 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 032 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 033 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 034 */       do {
/* 035 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 036 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 037 */         null : (scan_row_0.getUTF8String(1));
/* 038 */
/* 039 */         if (!(!scan_isNull_1)) continue;
/* 040 */
/* 041 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 042 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 043 */         null : (scan_row_0.getUTF8String(0));
/* 044 */
/* 045 */         if (!(!scan_isNull_0)) continue;
/* 046 */
/* 047 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 048 */
/* 049 */         // generate join key for stream side
/* 050 */         filter_mutableStateArray_0[2].reset();
/* 051 */
/* 052 */         filter_mutableStateArray_0[2].zeroOutNullBytes();
/* 053 */
/* 054 */         boolean bhj_isNull_0 = false;
/* 055 */         int bhj_value_0 = -1;
/* 056 */         if (!false) {
/* 057 */           scala.Option<Integer> bhj_intOpt_0 =
/* 058 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(scan_value_1);
/* 059 */           if (bhj_intOpt_0.isDefined()) {
/* 060 */             bhj_value_0 = ((Integer) bhj_intOpt_0.get()).intValue();
/* 061 */           } else {
/* 062 */             bhj_isNull_0 = true;
/* 063 */           }
/* 064 */         }
/* 065 */         if (bhj_isNull_0) {
/* 066 */           filter_mutableStateArray_0[2].setNullAt(0);
/* 067 */         } else {
/* 068 */           filter_mutableStateArray_0[2].write(0, bhj_value_0);
/* 069 */         }
/* 070 */
/* 071 */         if (false) {
/* 072 */           filter_mutableStateArray_0[2].setNullAt(1);
/* 073 */         } else {
/* 074 */           filter_mutableStateArray_0[2].write(1, scan_value_0);
/* 075 */         }
/* 076 */         // find matches from HashedRelation
/* 077 */         UnsafeRow bhj_matched_0 = (filter_mutableStateArray_0[2].getRow()).anyNull() ? null: (UnsafeRow)bhj_relation_0.getValue((filter_mutableStateArray_0[2].getRow()));
/* 078 */         if (bhj_matched_0 != null) {
/* 079 */           {
/* 080 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 081 */
/* 082 */             boolean scan_isNull_2 = scan_row_0.isNullAt(2);
/* 083 */             UTF8String scan_value_2 = scan_isNull_2 ?
/* 084 */             null : (scan_row_0.getUTF8String(2));
/* 085 */             boolean scan_isNull_3 = scan_row_0.isNullAt(3);
/* 086 */             UTF8String scan_value_3 = scan_isNull_3 ?
/* 087 */             null : (scan_row_0.getUTF8String(3));
/* 088 */             boolean project_isNull_12 = true;
/* 089 */             UTF8String project_value_12 = null;
/* 090 */             boolean bhj_isNull_5 = bhj_matched_0.isNullAt(2);
/* 091 */             UTF8String bhj_value_5 = bhj_isNull_5 ?
/* 092 */             null : (bhj_matched_0.getUTF8String(2));
/* 093 */             if (!bhj_isNull_5) {
/* 094 */               project_isNull_12 = false; // resultCode could change nullability.
/* 095 */               project_value_12 = bhj_value_5.replace(((UTF8String) references[5] /* literal */), ((UTF8String) references[6] /* literal */));
/* 096 */
/* 097 */             }
/* 098 */             filter_mutableStateArray_0[4].reset();
/* 099 */
/* 100 */             filter_mutableStateArray_0[4].zeroOutNullBytes();
/* 101 */
/* 102 */             if (false) {
/* 103 */               filter_mutableStateArray_0[4].setNullAt(0);
/* 104 */             } else {
/* 105 */               filter_mutableStateArray_0[4].write(0, scan_value_0);
/* 106 */             }
/* 107 */
/* 108 */             if (false) {
/* 109 */               filter_mutableStateArray_0[4].setNullAt(1);
/* 110 */             } else {
/* 111 */               filter_mutableStateArray_0[4].write(1, scan_value_1);
/* 112 */             }
/* 113 */
/* 114 */             if (scan_isNull_2) {
/* 115 */               filter_mutableStateArray_0[4].setNullAt(2);
/* 116 */             } else {
/* 117 */               filter_mutableStateArray_0[4].write(2, scan_value_2);
/* 118 */             }
/* 119 */
/* 120 */             if (scan_isNull_3) {
/* 121 */               filter_mutableStateArray_0[4].setNullAt(3);
/* 122 */             } else {
/* 123 */               filter_mutableStateArray_0[4].write(3, scan_value_3);
/* 124 */             }
/* 125 */
/* 126 */             if (project_isNull_12) {
/* 127 */               filter_mutableStateArray_0[4].setNullAt(4);
/* 128 */             } else {
/* 129 */               filter_mutableStateArray_0[4].write(4, project_value_12);
/* 130 */             }
/* 131 */             append((filter_mutableStateArray_0[4].getRow()));
/* 132 */
/* 133 */           }
/* 134 */         }
/* 135 */
/* 136 */       } while(false);
/* 137 */       if (shouldStop()) return;
/* 138 */     }
/* 139 */   }
/* 140 */
/* 141 */   private void wholestagecodegen_init_0_0() {
/* 142 */     scan_mutableStateArray_0[0] = inputs[0];
/* 143 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 144 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 145 */
/* 146 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[2] /* broadcast */).value()).asReadOnlyCopy();
/* 147 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 148 */
/* 149 */     org.apache.spark.TaskContext$.MODULE$.get().addTaskCompletionListener(new org.apache.spark.util.TaskCompletionListener() {
/* 150 */         @Override
/* 151 */         public void onTaskCompletion(org.apache.spark.TaskContext context) {
/* 152 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */).set(bhj_relation_0.getAverageProbesPerLookup());
/* 153 */         }
/* 154 */       });
/* 155 */
/* 156 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 157 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(7, 224);
/* 158 */
/* 159 */   }
/* 160 */
/* 161 */ }

Block broadcast_16 stored as values in memory (estimated size 242.9 KB, free 1970.3 MB)
Put block broadcast_16 locally took  3 ms
Putting block broadcast_16 without replication took  3 ms
Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.0 KB, free 1970.2 MB)
Added broadcast_16_piece0 in memory on 192.168.1.13:10964 (size: 20.0 KB, free: 1987.4 MB)
Updated info of block broadcast_16_piece0
Told master about block broadcast_16_piece0
Put block broadcast_16_piece0 locally took  1 ms
Putting block broadcast_16_piece0 without replication took  1 ms
Created broadcast 16 from csv at SparkUtiles.scala:37
Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
Cleaning lambda: $anonfun$doExecute$4$adapted
 +++ Lambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
Cleaning lambda: $anonfun$write$15
 +++ Lambda closure ($anonfun$write$15) is now cleaned +++
Starting job: csv at SparkUtiles.scala:37
Registering RDD 30 (csv at SparkUtiles.scala:37)
Got job 6 (csv at SparkUtiles.scala:37) with 1 output partitions
Final stage: ResultStage 8 (csv at SparkUtiles.scala:37)
Parents of final stage: List(ShuffleMapStage 7)
Missing parents: List(ShuffleMapStage 7)
submitStage(ResultStage 8)
missing: List(ShuffleMapStage 7)
submitStage(ShuffleMapStage 7)
missing: List()
Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ShuffleMapStage 7)
Block broadcast_17 stored as values in memory (estimated size 18.4 KB, free 1970.2 MB)
Put block broadcast_17 locally took  0 ms
Putting block broadcast_17 without replication took  0 ms
Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1970.2 MB)
Added broadcast_17_piece0 in memory on 192.168.1.13:10964 (size: 9.3 KB, free: 1987.3 MB)
Updated info of block broadcast_17_piece0
Told master about block broadcast_17_piece0
Put block broadcast_17_piece0 locally took  1 ms
Putting block broadcast_17_piece0 without replication took  1 ms
Created broadcast 17 from broadcast at DAGScheduler.scala:1161
Submitting 3 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0, 1, 2))
Adding task set 7.0 with 3 tasks
Epoch for TaskSet 7.0: 1
Valid locality levels for TaskSet 7.0: NO_PREF, ANY
parentName: , name: TaskSet_7.0, runningTasks: 0
Starting task 0.0 in stage 7.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7820 bytes)
Starting task 1.0 in stage 7.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 7819 bytes)
Starting task 2.0 in stage 7.0 (TID 15, localhost, executor driver, partition 2, PROCESS_LOCAL, 7817 bytes)
No tasks for locality level NO_PREF, so moving to locality level ANY
Running task 0.0 in stage 7.0 (TID 13)
Running task 2.0 in stage 7.0 (TID 15)
Running task 1.0 in stage 7.0 (TID 14)
Getting local block broadcast_17
Level for block broadcast_17 is StorageLevel(disk, memory, deserialized, 1 replicas)
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Melbourne.csv, range: 0-12604, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Sydney.csv, range: 0-11637, partition values: [empty row]
Reading File path: file:///D:/p1/weather-simulator/src/main/resources/bomstatis/Adelaide.csv, range: 0-12320, partition values: [empty row]
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Getting local block broadcast_16
Level for block broadcast_16 is StorageLevel(disk, memory, deserialized, 1 replicas)
code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

code for input[0, string, true],input[1, string, true],input[2, string, true],input[3, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 128);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */
/* 058 */     boolean isNull_3 = i.isNullAt(3);
/* 059 */     UTF8String value_3 = isNull_3 ?
/* 060 */     null : (i.getUTF8String(3));
/* 061 */     if (isNull_3) {
/* 062 */       mutableStateArray_0[0].setNullAt(3);
/* 063 */     } else {
/* 064 */       mutableStateArray_0[0].write(3, value_3);
/* 065 */     }
/* 066 */     return (mutableStateArray_0[0].getRow());
/* 067 */   }
/* 068 */
/* 069 */
/* 070 */ }

Finished task 1.0 in stage 7.0 (TID 14). 1659 bytes result sent to driver
parentName: , name: TaskSet_7.0, runningTasks: 2
Finished task 1.0 in stage 7.0 (TID 14) in 127 ms on localhost (executor driver) (1/3)
ShuffleMapTask finished on driver
Finished task 2.0 in stage 7.0 (TID 15). 1616 bytes result sent to driver
parentName: , name: TaskSet_7.0, runningTasks: 1
Finished task 2.0 in stage 7.0 (TID 15) in 149 ms on localhost (executor driver) (2/3)
ShuffleMapTask finished on driver
Finished task 0.0 in stage 7.0 (TID 13). 1616 bytes result sent to driver
parentName: , name: TaskSet_7.0, runningTasks: 0
Finished task 0.0 in stage 7.0 (TID 13) in 153 ms on localhost (executor driver) (3/3)
Removed TaskSet 7.0, whose tasks have all completed, from pool 
ShuffleMapTask finished on driver
ShuffleMapStage 7 (csv at SparkUtiles.scala:37) finished in 0.159 s
looking for newly runnable stages
running: Set()
waiting: Set(ResultStage 8)
failed: Set()
Increasing epoch to 2
submitStage(ResultStage 8)
missing: List()
Submitting ResultStage 8 (ShuffledRowRDD[31] at csv at SparkUtiles.scala:37), which has no missing parents
submitMissingTasks(ResultStage 8)
Block broadcast_18 stored as values in memory (estimated size 129.5 KB, free 1970.1 MB)
Put block broadcast_18 locally took  1 ms
Putting block broadcast_18 without replication took  1 ms
Block broadcast_18_piece0 stored as bytes in memory (estimated size 45.8 KB, free 1970.0 MB)
Added broadcast_18_piece0 in memory on 192.168.1.13:10964 (size: 45.8 KB, free: 1987.3 MB)
Updated info of block broadcast_18_piece0
Told master about block broadcast_18_piece0
Put block broadcast_18_piece0 locally took  1 ms
Putting block broadcast_18_piece0 without replication took  1 ms
Created broadcast 18 from broadcast at DAGScheduler.scala:1161
Submitting 1 missing tasks from ResultStage 8 (ShuffledRowRDD[31] at csv at SparkUtiles.scala:37) (first 15 tasks are for partitions Vector(0))
Adding task set 8.0 with 1 tasks
Epoch for TaskSet 8.0: 2
Valid locality levels for TaskSet 8.0: ANY
parentName: , name: TaskSet_8.0, runningTasks: 0
Starting task 0.0 in stage 8.0 (TID 16, localhost, executor driver, partition 0, ANY, 7246 bytes)
Running task 0.0 in stage 8.0 (TID 16)
Getting local block broadcast_18
Level for block broadcast_18 is StorageLevel(disk, memory, deserialized, 1 replicas)
Fetching outputs for shuffle 1, partitions 0-1
maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
Getting 3 non-empty blocks including 3 local blocks and 0 remote blocks
Started 0 remote fetches in 0 ms
Start fetching local blocks: shuffle_1_0_0, shuffle_1_1_0, shuffle_1_2_0
Got local blocks in  1 ms
File Output Committer Algorithm version is 1
FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
Commit allowed for stage=8.0, partition=0, task attempt 0
Saved output of task 'attempt_20190331201726_0008_m_000000_0' to file:/D:/p1/weather-simulator/src/main/resources/verify/_temporary/0/task_20190331201726_0008_m_000000
attempt_20190331201726_0008_m_000000_0: Committed
Finished task 0.0 in stage 8.0 (TID 16). 2215 bytes result sent to driver
parentName: , name: TaskSet_8.0, runningTasks: 0
Finished task 0.0 in stage 8.0 (TID 16) in 42 ms on localhost (executor driver) (1/1)
Removed TaskSet 8.0, whose tasks have all completed, from pool 
ResultStage 8 (csv at SparkUtiles.scala:37) finished in 0.067 s
After removal of stage 8, remaining stages = 1
After removal of stage 7, remaining stages = 0
Job 6 finished: csv at SparkUtiles.scala:37, took 0.228484 s
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/verify/_temporary/0/task_20190331201726_0008_m_000000; isDirectory=true; modification_time=1554023846812; access_time=1554023846812; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/verify
Merging data from DeprecatedRawLocalFileStatus{path=file:/D:/p1/weather-simulator/src/main/resources/verify/_temporary/0/task_20190331201726_0008_m_000000/part-00000-d26247f7-eeb2-498b-9442-abadc3a119e9-c000.csv; isDirectory=false; length=38526; replication=1; blocksize=33554432; modification_time=1554023846831; access_time=1554023846811; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/D:/p1/weather-simulator/src/main/resources/verify/part-00000-d26247f7-eeb2-498b-9442-abadc3a119e9-c000.csv
Committing files staged for absolute locations Map()
Write Job 26b50ef7-c1d7-4919-b862-fa6d0ffa2bb1 committed.
Finished processing stats for write job 26b50ef7-c1d7-4919-b862-fa6d0ffa2bb1.
stopping org.spark_project.jetty.server.Server@4d098f9b
doStop org.spark_project.jetty.server.Server@4d098f9b
ran SparkUI-376-acceptor-0@267f474e-ServerConnector@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
Graceful shutdown org.spark_project.jetty.server.Server@4d098f9b by 
stopping Spark@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260
stopping org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4b5f022f on org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4b5f022f
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@194eae3e on org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@194eae3e
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@51034e4b produced null
Stopped org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@51034e4b produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@297ea53a id=3 keys=-1 selected=-1
stopping org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@2ab39942 on org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@2ab39942
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@64186f60 on org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@64186f60
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4ed4958c produced null
Stopped org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4ed4958c produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@132ddbab id=2 keys=-1 selected=-1
stopping org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@de40aa1 on org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@de40aa1
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@61b76a7d on org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@61b76a7d
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@297c8f86 produced null
Stopped org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@297c8f86 produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@4052274f id=1 keys=-1 selected=-1
stopping org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@57f89680 on org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@57f89680
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@70bc9070 on org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@70bc9070
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1dd8022d produced null
Stopped org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=-1 selected=-1
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@1dd8022d produce exit
STOPPED org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@482d776b id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@18f20260
stopping HttpConnectionFactory@58670130[HTTP/1.1]
STOPPED HttpConnectionFactory@58670130[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@3f28bd56
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@3f28bd56
Stopped Spark@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
STOPPED Spark@3276732{HTTP/1.1,[http/1.1]}{0.0.0.0:4542}
stopping org.spark_project.jetty.server.Server@4d098f9b
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@74cadd41[org.spark_project.jetty.server.handler.gzip.GzipHandler@592e843a, org.spark_project.jetty.server.handler.gzip.GzipHandler@226642a5, org.spark_project.jetty.server.handler.gzip.GzipHandler@89c10b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@1a1da881, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f058b8a, org.spark_project.jetty.server.handler.gzip.GzipHandler@64337702, org.spark_project.jetty.server.handler.gzip.GzipHandler@611df6e3, org.spark_project.jetty.server.handler.gzip.GzipHandler@52500920, org.spark_project.jetty.server.handler.gzip.GzipHandler@4b85880b, org.spark_project.jetty.server.handler.gzip.GzipHandler@76a36b71, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e2943ab, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac86ba5, org.spark_project.jetty.server.handler.gzip.GzipHandler@53ab0286, org.spark_project.jetty.server.handler.gzip.GzipHandler@5bda80bf, org.spark_project.jetty.server.handler.gzip.GzipHandler@fd46303, org.spark_project.jetty.server.handler.gzip.GzipHandler@60fa3495, org.spark_project.jetty.server.handler.gzip.GzipHandler@69c79f09, org.spark_project.jetty.server.handler.gzip.GzipHandler@89ff02e, org.spark_project.jetty.server.handler.gzip.GzipHandler@5b6813df, org.spark_project.jetty.server.handler.gzip.GzipHandler@33352f32, org.spark_project.jetty.server.handler.gzip.GzipHandler@35fe2125, org.spark_project.jetty.server.handler.gzip.GzipHandler@65e61854, org.spark_project.jetty.server.handler.gzip.GzipHandler@f9879ac, org.spark_project.jetty.server.handler.gzip.GzipHandler@4ef27d66, org.spark_project.jetty.server.handler.gzip.GzipHandler@674c583e, o.s.j.s.ServletContextHandler@2d140a7{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@701a32{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@27ead29e{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@2424686b{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4a1e3ac1{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@f2c488{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec
stopping org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@7fc44dec
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@4d098f9b
Stopped Spark web UI at http://192.168.1.13:4542
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\ywksu\AppData\Local\Temp\spark-9078433c-b5c7-49a0-a6a5-efd0b3250136
ShutdownHookManger complete shutdown.
